{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"C:\\\\Users\\\\norma\\\\OneDrive\\\\Desktop\\\\NOVICHOK\\\\novichok_356_cross_validation\\\\data\\\\csv\\\\dataset_no_imaginary.csv\",delimiter=\",\",encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создал функцию, которая проходит по директории и читает наши '.xyz'-файлы\n",
    "# Название каждого файла в моей директории отражено в датасете в столбце 'name' без расширения .xyz \n",
    "# Сконвертировал координаты в numpy-массив и закинул в новый столбец 'coordinates' в датасете\n",
    "\n",
    "coordinates_list = []\n",
    "\n",
    "def read_xyz_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()[2:]  \n",
    "        coordinates = []\n",
    "        for line in lines:\n",
    "            parts = line.split()\n",
    "            if len(parts) == 4:\n",
    "                coordinates.append([float(parts[1]), float(parts[2]), float(parts[3])])\n",
    "        return np.array(coordinates)\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "    file_name = str(row['name']) + \".xyz\"\n",
    "    file_path = os.path.join(\"C:\\\\Users\\\\norma\\\\OneDrive\\\\Desktop\\\\NOVICHOK\\\\novichok_356_cross_validation\\\\xyz\", file_name)\n",
    "    coordinates = read_xyz_file(file_path)\n",
    "    coordinates_list.append(coordinates)\n",
    "data['coordinates'] = coordinates_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>hf_gibbs_free_energy_ev</th>\n",
       "      <th>hf_electronic_energy_ev</th>\n",
       "      <th>hf_entropy_ev</th>\n",
       "      <th>hf_enthalpy_ev</th>\n",
       "      <th>hf_dipole_moment</th>\n",
       "      <th>hf_homo_ev</th>\n",
       "      <th>hf_lumo_ev</th>\n",
       "      <th>dft_gibbs_free_energy_ev</th>\n",
       "      <th>dft_electronic_energy_ev</th>\n",
       "      <th>dft_entropy_ev</th>\n",
       "      <th>dft_enthalpy_ev</th>\n",
       "      <th>dft_dipole_moment</th>\n",
       "      <th>dft_homo_ev</th>\n",
       "      <th>dft_lumo_ev</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>002-M-BA1-b</td>\n",
       "      <td>-27275.076351</td>\n",
       "      <td>-27281.888683</td>\n",
       "      <td>1.795316</td>\n",
       "      <td>-27273.281035</td>\n",
       "      <td>0.87236</td>\n",
       "      <td>-8.8130</td>\n",
       "      <td>4.0489</td>\n",
       "      <td>-27617.108248</td>\n",
       "      <td>-27623.000160</td>\n",
       "      <td>1.877779</td>\n",
       "      <td>-27615.230469</td>\n",
       "      <td>1.47466</td>\n",
       "      <td>-6.2925</td>\n",
       "      <td>-1.4983</td>\n",
       "      <td>[[-3.6610385002265, 6.93533048376608, -0.58345...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>002-M-BA1-pipi</td>\n",
       "      <td>-27275.128802</td>\n",
       "      <td>-27281.952769</td>\n",
       "      <td>1.772166</td>\n",
       "      <td>-27273.356635</td>\n",
       "      <td>1.19181</td>\n",
       "      <td>-9.2580</td>\n",
       "      <td>4.4306</td>\n",
       "      <td>-27617.107555</td>\n",
       "      <td>-27623.063060</td>\n",
       "      <td>1.822257</td>\n",
       "      <td>-27615.285298</td>\n",
       "      <td>1.69901</td>\n",
       "      <td>-6.7665</td>\n",
       "      <td>-1.3131</td>\n",
       "      <td>[[-3.24946263013423, 6.99473259895769, -1.4223...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>005-MEL-CA</td>\n",
       "      <td>-25599.449771</td>\n",
       "      <td>-25604.305425</td>\n",
       "      <td>1.564143</td>\n",
       "      <td>-25597.885628</td>\n",
       "      <td>0.93514</td>\n",
       "      <td>-8.9909</td>\n",
       "      <td>4.6443</td>\n",
       "      <td>-25917.872472</td>\n",
       "      <td>-25922.091294</td>\n",
       "      <td>1.641525</td>\n",
       "      <td>-25916.230947</td>\n",
       "      <td>0.85984</td>\n",
       "      <td>-6.4902</td>\n",
       "      <td>-0.8343</td>\n",
       "      <td>[[-5.415595, -7.691943, 0.824725], [-4.323509,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>006-MEL-UA</td>\n",
       "      <td>-29133.284441</td>\n",
       "      <td>-29138.979188</td>\n",
       "      <td>1.668533</td>\n",
       "      <td>-29131.615908</td>\n",
       "      <td>2.68196</td>\n",
       "      <td>-8.2371</td>\n",
       "      <td>3.9070</td>\n",
       "      <td>-29496.320185</td>\n",
       "      <td>-29501.224258</td>\n",
       "      <td>1.791889</td>\n",
       "      <td>-29494.528296</td>\n",
       "      <td>3.15832</td>\n",
       "      <td>-6.1902</td>\n",
       "      <td>-1.1975</td>\n",
       "      <td>[[-5.251705, -7.658659, 1.031666], [-4.20755, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>007-MEL-CR</td>\n",
       "      <td>-22635.215921</td>\n",
       "      <td>-22641.289493</td>\n",
       "      <td>1.651416</td>\n",
       "      <td>-22633.564505</td>\n",
       "      <td>6.85797</td>\n",
       "      <td>-8.6600</td>\n",
       "      <td>5.1451</td>\n",
       "      <td>-22922.502813</td>\n",
       "      <td>-22927.782911</td>\n",
       "      <td>1.687934</td>\n",
       "      <td>-22920.814880</td>\n",
       "      <td>6.66567</td>\n",
       "      <td>-6.3708</td>\n",
       "      <td>-0.2151</td>\n",
       "      <td>[[-5.271343, -7.699293, 0.886577], [-4.227247,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>dimer_006121</td>\n",
       "      <td>-19613.756532</td>\n",
       "      <td>-19622.869155</td>\n",
       "      <td>1.793542</td>\n",
       "      <td>-19611.962991</td>\n",
       "      <td>6.65332</td>\n",
       "      <td>-9.2198</td>\n",
       "      <td>6.4409</td>\n",
       "      <td>-19866.663508</td>\n",
       "      <td>-19874.318183</td>\n",
       "      <td>1.856166</td>\n",
       "      <td>-19864.807342</td>\n",
       "      <td>7.42245</td>\n",
       "      <td>-6.4218</td>\n",
       "      <td>0.1743</td>\n",
       "      <td>[[1.30646491596164, -0.57524990278906, -1.3873...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>dimer_006125</td>\n",
       "      <td>-20685.601738</td>\n",
       "      <td>-20693.928747</td>\n",
       "      <td>1.763538</td>\n",
       "      <td>-20683.838200</td>\n",
       "      <td>6.26955</td>\n",
       "      <td>-9.4013</td>\n",
       "      <td>4.9169</td>\n",
       "      <td>-20947.601629</td>\n",
       "      <td>-20954.521584</td>\n",
       "      <td>1.884566</td>\n",
       "      <td>-20945.717064</td>\n",
       "      <td>3.73848</td>\n",
       "      <td>-6.6824</td>\n",
       "      <td>-1.1960</td>\n",
       "      <td>[[0.72411350301662, -0.84318903552034, 1.47813...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>dimer_006130</td>\n",
       "      <td>-20747.583954</td>\n",
       "      <td>-20757.490597</td>\n",
       "      <td>1.733202</td>\n",
       "      <td>-20745.850752</td>\n",
       "      <td>7.75520</td>\n",
       "      <td>-9.8085</td>\n",
       "      <td>11.3969</td>\n",
       "      <td>-21011.664617</td>\n",
       "      <td>-21019.968290</td>\n",
       "      <td>1.833384</td>\n",
       "      <td>-21009.831233</td>\n",
       "      <td>6.57082</td>\n",
       "      <td>-6.5023</td>\n",
       "      <td>0.1869</td>\n",
       "      <td>[[-0.1568812460469, 1.12137289084067, -0.50992...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>dimer_006131</td>\n",
       "      <td>-22685.503101</td>\n",
       "      <td>-22693.815819</td>\n",
       "      <td>1.715946</td>\n",
       "      <td>-22683.787155</td>\n",
       "      <td>7.83449</td>\n",
       "      <td>-9.9891</td>\n",
       "      <td>11.2032</td>\n",
       "      <td>-22967.819716</td>\n",
       "      <td>-22974.854229</td>\n",
       "      <td>1.795052</td>\n",
       "      <td>-22966.024664</td>\n",
       "      <td>6.23344</td>\n",
       "      <td>-6.7157</td>\n",
       "      <td>0.1428</td>\n",
       "      <td>[[-0.06237487272243, 0.8137375865662, -0.11994...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>dimer_006132</td>\n",
       "      <td>-18809.304420</td>\n",
       "      <td>-18820.714966</td>\n",
       "      <td>1.794782</td>\n",
       "      <td>-18807.509638</td>\n",
       "      <td>3.19981</td>\n",
       "      <td>-10.3796</td>\n",
       "      <td>12.8019</td>\n",
       "      <td>-19055.389959</td>\n",
       "      <td>-19064.917052</td>\n",
       "      <td>1.887702</td>\n",
       "      <td>-19053.502257</td>\n",
       "      <td>2.70457</td>\n",
       "      <td>-6.9760</td>\n",
       "      <td>0.4067</td>\n",
       "      <td>[[-0.20955229645577, 1.17165843085321, 0.38015...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>158 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               name  hf_gibbs_free_energy_ev  hf_electronic_energy_ev  \\\n",
       "0       002-M-BA1-b            -27275.076351            -27281.888683   \n",
       "1    002-M-BA1-pipi            -27275.128802            -27281.952769   \n",
       "2        005-MEL-CA            -25599.449771            -25604.305425   \n",
       "3        006-MEL-UA            -29133.284441            -29138.979188   \n",
       "4        007-MEL-CR            -22635.215921            -22641.289493   \n",
       "..              ...                      ...                      ...   \n",
       "153    dimer_006121            -19613.756532            -19622.869155   \n",
       "154    dimer_006125            -20685.601738            -20693.928747   \n",
       "155    dimer_006130            -20747.583954            -20757.490597   \n",
       "156    dimer_006131            -22685.503101            -22693.815819   \n",
       "157    dimer_006132            -18809.304420            -18820.714966   \n",
       "\n",
       "     hf_entropy_ev  hf_enthalpy_ev  hf_dipole_moment  hf_homo_ev  hf_lumo_ev  \\\n",
       "0         1.795316   -27273.281035           0.87236     -8.8130      4.0489   \n",
       "1         1.772166   -27273.356635           1.19181     -9.2580      4.4306   \n",
       "2         1.564143   -25597.885628           0.93514     -8.9909      4.6443   \n",
       "3         1.668533   -29131.615908           2.68196     -8.2371      3.9070   \n",
       "4         1.651416   -22633.564505           6.85797     -8.6600      5.1451   \n",
       "..             ...             ...               ...         ...         ...   \n",
       "153       1.793542   -19611.962991           6.65332     -9.2198      6.4409   \n",
       "154       1.763538   -20683.838200           6.26955     -9.4013      4.9169   \n",
       "155       1.733202   -20745.850752           7.75520     -9.8085     11.3969   \n",
       "156       1.715946   -22683.787155           7.83449     -9.9891     11.2032   \n",
       "157       1.794782   -18807.509638           3.19981    -10.3796     12.8019   \n",
       "\n",
       "     dft_gibbs_free_energy_ev  dft_electronic_energy_ev  dft_entropy_ev  \\\n",
       "0               -27617.108248             -27623.000160        1.877779   \n",
       "1               -27617.107555             -27623.063060        1.822257   \n",
       "2               -25917.872472             -25922.091294        1.641525   \n",
       "3               -29496.320185             -29501.224258        1.791889   \n",
       "4               -22922.502813             -22927.782911        1.687934   \n",
       "..                        ...                       ...             ...   \n",
       "153             -19866.663508             -19874.318183        1.856166   \n",
       "154             -20947.601629             -20954.521584        1.884566   \n",
       "155             -21011.664617             -21019.968290        1.833384   \n",
       "156             -22967.819716             -22974.854229        1.795052   \n",
       "157             -19055.389959             -19064.917052        1.887702   \n",
       "\n",
       "     dft_enthalpy_ev  dft_dipole_moment  dft_homo_ev  dft_lumo_ev  \\\n",
       "0      -27615.230469            1.47466      -6.2925      -1.4983   \n",
       "1      -27615.285298            1.69901      -6.7665      -1.3131   \n",
       "2      -25916.230947            0.85984      -6.4902      -0.8343   \n",
       "3      -29494.528296            3.15832      -6.1902      -1.1975   \n",
       "4      -22920.814880            6.66567      -6.3708      -0.2151   \n",
       "..               ...                ...          ...          ...   \n",
       "153    -19864.807342            7.42245      -6.4218       0.1743   \n",
       "154    -20945.717064            3.73848      -6.6824      -1.1960   \n",
       "155    -21009.831233            6.57082      -6.5023       0.1869   \n",
       "156    -22966.024664            6.23344      -6.7157       0.1428   \n",
       "157    -19053.502257            2.70457      -6.9760       0.4067   \n",
       "\n",
       "                                           coordinates  \n",
       "0    [[-3.6610385002265, 6.93533048376608, -0.58345...  \n",
       "1    [[-3.24946263013423, 6.99473259895769, -1.4223...  \n",
       "2    [[-5.415595, -7.691943, 0.824725], [-4.323509,...  \n",
       "3    [[-5.251705, -7.658659, 1.031666], [-4.20755, ...  \n",
       "4    [[-5.271343, -7.699293, 0.886577], [-4.227247,...  \n",
       "..                                                 ...  \n",
       "153  [[1.30646491596164, -0.57524990278906, -1.3873...  \n",
       "154  [[0.72411350301662, -0.84318903552034, 1.47813...  \n",
       "155  [[-0.1568812460469, 1.12137289084067, -0.50992...  \n",
       "156  [[-0.06237487272243, 0.8137375865662, -0.11994...  \n",
       "157  [[-0.20955229645577, 1.17165843085321, 0.38015...  \n",
       "\n",
       "[158 rows x 16 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Для обучения использовал все дескрипторы, посчитанные на HF-3c уровне + столбец 'coordinates'  \n",
    "# Первые 56 строк в документе - реальный датасет\n",
    "\n",
    "features = ['hf_gibbs_free_energy_ev', 'hf_electronic_energy_ev', 'hf_entropy_ev',\n",
    "            'hf_enthalpy_ev', 'hf_dipole_moment', 'hf_homo_ev', 'hf_lumo_ev', 'coordinates']\n",
    "target = 'dft_lumo_ev'\n",
    "\n",
    "train_data = data.iloc[18:]  \n",
    "test_data = data.iloc[:18]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Скопировал сеты, т.к. предупреждение 'SettingWithCopyWarning' постоянно выскакивало при сглаживанни\n",
    "\n",
    "X_train = train_data[features].copy()\n",
    "y_train = train_data[target].copy()\n",
    "X_test = test_data[features].copy()\n",
    "y_test = test_data[target].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сглаживание numpy-массива с координатами\n",
    "\n",
    "X_train['coordinates'] = X_train['coordinates'].apply(np.ravel)\n",
    "X_test['coordinates'] = X_test['coordinates'].apply(np.ravel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определил максимальную длину сглаженных массивов для каждого сета\n",
    "# Эта информация пригодится для дополнения сглаженных массивов, чтобы они были одинаковой длины \n",
    "# Это нужно для совместимости массива с моделями из сайкит-лерн\n",
    "\n",
    "max_length_train = X_train['coordinates'].apply(len).max()\n",
    "max_length_test = X_test['coordinates'].apply(len).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['coordinates'] = X_train['coordinates'].apply(lambda x: np.pad(x, (0, max_length_train - len(x)), mode='constant'))\n",
    "X_test['coordinates'] = X_test['coordinates'].apply(lambda x: np.pad(x, (0, max_length_test - len(x)), mode='constant'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Конкатенирую полученные сглаженные массивы с остальными столбцами \n",
    "\n",
    "X_train_numeric = pd.concat([X_train.drop(columns='coordinates'),\n",
    "                             pd.DataFrame(np.vstack(X_train['coordinates']), \n",
    "                                          columns=[f'coord_{i}' for i in range(max_length_train)], \n",
    "                                          index=X_train.index)],\n",
    "                            axis=1)\n",
    "\n",
    "X_test_numeric = pd.concat([X_test.drop(columns='coordinates'),\n",
    "                            pd.DataFrame(np.vstack(X_test['coordinates']), \n",
    "                                         columns=[f'coord_{i}' for i in range(max_length_test)], \n",
    "                                         index=X_test.index)],\n",
    "                            axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numpy-массив у тестовой выборки (реальный датасет) короче, чем у тренировочной\n",
    "# Определил разницу в длинах массивов, а затем привел к общей длине\n",
    " \n",
    "max_columns = max(X_train_numeric.shape[1], X_test_numeric.shape[1])\n",
    "X_train_numeric = X_train_numeric.reindex(columns=X_train_numeric.columns.union(X_test_numeric.columns), fill_value=0)\n",
    "X_test_numeric = X_test_numeric.reindex(columns=X_train_numeric.columns, fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Нормализация тренировочного датасета\n",
    "# Процедуру применил ко всем дескрипторам, кроме координат\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "coord_columns = [col for col in X_train_numeric.columns if col.startswith('coord_')]\n",
    "non_coord_columns = [col for col in X_train_numeric.columns if col not in coord_columns]\n",
    "\n",
    "X_train_non_coord_scaled = scaler.fit_transform(X_train_numeric[non_coord_columns])\n",
    "X_train_numeric_scaled = pd.concat([pd.DataFrame(X_train_non_coord_scaled, columns=non_coord_columns, index=X_train_numeric.index),\n",
    "                                    X_train_numeric[coord_columns]], axis=1)\n",
    "\n",
    "X_test_non_coord_scaled = scaler.transform(X_test_numeric[non_coord_columns])\n",
    "X_test_numeric_scaled = pd.concat([pd.DataFrame(X_test_non_coord_scaled, columns=non_coord_columns, index=X_test_numeric.index),\n",
    "                                   X_test_numeric[coord_columns]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Нормализация таргета\n",
    "\n",
    "scaler_y = StandardScaler()\n",
    "\n",
    "y_train_scaled = scaler_y.fit_transform(y_train.values.reshape(-1, 1))\n",
    "y_test_scaled = scaler_y.transform(y_test.values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Задаю разные значения оптимайзеров, скоростей и функций активации для поиска наилучших комбинаций\n",
    "\n",
    "optimizers = ['adam', 'sgd', 'rmsprop', 'adagrad']\n",
    "activation_functions = ['relu', 'sigmoid', 'tanh', \"softmax\"]\n",
    "learning_rates = [0.0001, 0.001, 0.01, 0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer: adam, Activation Function: relu, Learning Rate: 0.0001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "  MSE: 0.9672, RMSE: 0.9834, R^2: -0.0583, MAE: 0.7501\n",
      "Optimizer: adam, Activation Function: relu, Learning Rate: 0.001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "  MSE: 1.2627, RMSE: 1.1237, R^2: -0.3817, MAE: 0.7783\n",
      "Optimizer: adam, Activation Function: relu, Learning Rate: 0.01\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "  MSE: 2.0887, RMSE: 1.4452, R^2: -1.2856, MAE: 0.9125\n",
      "Optimizer: adam, Activation Function: relu, Learning Rate: 0.1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "  MSE: 1.7735, RMSE: 1.3317, R^2: -0.9407, MAE: 0.9179\n",
      "Optimizer: adam, Activation Function: sigmoid, Learning Rate: 0.0001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "  MSE: 0.7939, RMSE: 0.8910, R^2: 0.1313, MAE: 0.5983\n",
      "Optimizer: adam, Activation Function: sigmoid, Learning Rate: 0.001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "  MSE: 1.0393, RMSE: 1.0195, R^2: -0.1373, MAE: 0.6750\n",
      "Optimizer: adam, Activation Function: sigmoid, Learning Rate: 0.01\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "  MSE: 0.7214, RMSE: 0.8494, R^2: 0.2105, MAE: 0.5549\n",
      "Optimizer: adam, Activation Function: sigmoid, Learning Rate: 0.1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "  MSE: 0.8067, RMSE: 0.8982, R^2: 0.1172, MAE: 0.5927\n",
      "Optimizer: adam, Activation Function: tanh, Learning Rate: 0.0001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "  MSE: 0.8362, RMSE: 0.9144, R^2: 0.0850, MAE: 0.6858\n",
      "Optimizer: adam, Activation Function: tanh, Learning Rate: 0.001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "  MSE: 0.7130, RMSE: 0.8444, R^2: 0.2197, MAE: 0.6021\n",
      "Optimizer: adam, Activation Function: tanh, Learning Rate: 0.01\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "  MSE: 1.0215, RMSE: 1.0107, R^2: -0.1178, MAE: 0.7571\n",
      "Optimizer: adam, Activation Function: tanh, Learning Rate: 0.1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "  MSE: 0.6143, RMSE: 0.7837, R^2: 0.3278, MAE: 0.6293\n",
      "Optimizer: adam, Activation Function: softmax, Learning Rate: 0.0001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "  MSE: 1.9243, RMSE: 1.3872, R^2: -1.1057, MAE: 1.1148\n",
      "Optimizer: adam, Activation Function: softmax, Learning Rate: 0.001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "  MSE: 1.9243, RMSE: 1.3872, R^2: -1.1057, MAE: 1.1148\n",
      "Optimizer: adam, Activation Function: softmax, Learning Rate: 0.01\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "  MSE: 1.9243, RMSE: 1.3872, R^2: -1.1057, MAE: 1.1148\n",
      "Optimizer: adam, Activation Function: softmax, Learning Rate: 0.1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "  MSE: 1.9243, RMSE: 1.3872, R^2: -1.1057, MAE: 1.1148\n",
      "Optimizer: sgd, Activation Function: relu, Learning Rate: 0.0001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "  MSE: 0.8548, RMSE: 0.9246, R^2: 0.0646, MAE: 0.6846\n",
      "Optimizer: sgd, Activation Function: relu, Learning Rate: 0.001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "  MSE: 0.9171, RMSE: 0.9576, R^2: -0.0035, MAE: 0.6982\n",
      "Optimizer: sgd, Activation Function: relu, Learning Rate: 0.01\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "  MSE: 0.9171, RMSE: 0.9576, R^2: -0.0035, MAE: 0.6982\n",
      "Optimizer: sgd, Activation Function: relu, Learning Rate: 0.1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "  MSE: 1.4969, RMSE: 1.2235, R^2: -0.6380, MAE: 0.7910\n",
      "Optimizer: sgd, Activation Function: sigmoid, Learning Rate: 0.0001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "  MSE: 0.8457, RMSE: 0.9196, R^2: 0.0746, MAE: 0.5875\n",
      "Optimizer: sgd, Activation Function: sigmoid, Learning Rate: 0.001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "  MSE: 0.7588, RMSE: 0.8711, R^2: 0.1697, MAE: 0.5848\n",
      "Optimizer: sgd, Activation Function: sigmoid, Learning Rate: 0.01\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "  MSE: 0.8645, RMSE: 0.9298, R^2: 0.0541, MAE: 0.6395\n",
      "Optimizer: sgd, Activation Function: sigmoid, Learning Rate: 0.1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "  MSE: 0.9503, RMSE: 0.9748, R^2: -0.0398, MAE: 0.6890\n",
      "Optimizer: sgd, Activation Function: tanh, Learning Rate: 0.0001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "  MSE: 0.7962, RMSE: 0.8923, R^2: 0.1287, MAE: 0.7252\n",
      "Optimizer: sgd, Activation Function: tanh, Learning Rate: 0.001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "  MSE: 0.8223, RMSE: 0.9068, R^2: 0.1002, MAE: 0.7626\n",
      "Optimizer: sgd, Activation Function: tanh, Learning Rate: 0.01\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "  MSE: 0.7110, RMSE: 0.8432, R^2: 0.2220, MAE: 0.6365\n",
      "Optimizer: sgd, Activation Function: tanh, Learning Rate: 0.1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "  MSE: 0.8353, RMSE: 0.9139, R^2: 0.0860, MAE: 0.6374\n",
      "Optimizer: sgd, Activation Function: softmax, Learning Rate: 0.0001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "  MSE: 1.9243, RMSE: 1.3872, R^2: -1.1057, MAE: 1.1148\n",
      "Optimizer: sgd, Activation Function: softmax, Learning Rate: 0.001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "  MSE: 1.9243, RMSE: 1.3872, R^2: -1.1057, MAE: 1.1148\n",
      "Optimizer: sgd, Activation Function: softmax, Learning Rate: 0.01\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "  MSE: 1.9243, RMSE: 1.3872, R^2: -1.1057, MAE: 1.1148\n",
      "Optimizer: sgd, Activation Function: softmax, Learning Rate: 0.1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "  MSE: 1.9243, RMSE: 1.3872, R^2: -1.1057, MAE: 1.1148\n",
      "Optimizer: rmsprop, Activation Function: relu, Learning Rate: 0.0001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "  MSE: 0.9358, RMSE: 0.9674, R^2: -0.0240, MAE: 0.7507\n",
      "Optimizer: rmsprop, Activation Function: relu, Learning Rate: 0.001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "  MSE: 1.2628, RMSE: 1.1238, R^2: -0.3819, MAE: 0.7884\n",
      "Optimizer: rmsprop, Activation Function: relu, Learning Rate: 0.01\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "  MSE: 1.2968, RMSE: 1.1388, R^2: -0.4191, MAE: 0.7952\n",
      "Optimizer: rmsprop, Activation Function: relu, Learning Rate: 0.1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "  MSE: 0.7332, RMSE: 0.8563, R^2: 0.1977, MAE: 0.6384\n",
      "Optimizer: rmsprop, Activation Function: sigmoid, Learning Rate: 0.0001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "  MSE: 0.7891, RMSE: 0.8883, R^2: 0.1365, MAE: 0.5694\n",
      "Optimizer: rmsprop, Activation Function: sigmoid, Learning Rate: 0.001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "  MSE: 0.8750, RMSE: 0.9354, R^2: 0.0425, MAE: 0.6222\n",
      "Optimizer: rmsprop, Activation Function: sigmoid, Learning Rate: 0.01\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "  MSE: 1.0653, RMSE: 1.0321, R^2: -0.1657, MAE: 0.6726\n",
      "Optimizer: rmsprop, Activation Function: sigmoid, Learning Rate: 0.1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "  MSE: 0.9509, RMSE: 0.9752, R^2: -0.0406, MAE: 0.6568\n",
      "Optimizer: rmsprop, Activation Function: tanh, Learning Rate: 0.0001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "  MSE: 0.7773, RMSE: 0.8816, R^2: 0.1495, MAE: 0.6643\n",
      "Optimizer: rmsprop, Activation Function: tanh, Learning Rate: 0.001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "  MSE: 0.5670, RMSE: 0.7530, R^2: 0.3795, MAE: 0.6082\n",
      "Optimizer: rmsprop, Activation Function: tanh, Learning Rate: 0.01\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "  MSE: 0.9121, RMSE: 0.9550, R^2: 0.0019, MAE: 0.7504\n",
      "Optimizer: rmsprop, Activation Function: tanh, Learning Rate: 0.1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "  MSE: 0.9040, RMSE: 0.9508, R^2: 0.0107, MAE: 0.6720\n",
      "Optimizer: rmsprop, Activation Function: softmax, Learning Rate: 0.0001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "  MSE: 1.9243, RMSE: 1.3872, R^2: -1.1057, MAE: 1.1148\n",
      "Optimizer: rmsprop, Activation Function: softmax, Learning Rate: 0.001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "  MSE: 1.9243, RMSE: 1.3872, R^2: -1.1057, MAE: 1.1148\n",
      "Optimizer: rmsprop, Activation Function: softmax, Learning Rate: 0.01\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "  MSE: 1.9243, RMSE: 1.3872, R^2: -1.1057, MAE: 1.1148\n",
      "Optimizer: rmsprop, Activation Function: softmax, Learning Rate: 0.1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "  MSE: 1.9243, RMSE: 1.3872, R^2: -1.1057, MAE: 1.1148\n",
      "Optimizer: adagrad, Activation Function: relu, Learning Rate: 0.0001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "  MSE: 1.5081, RMSE: 1.2280, R^2: -0.6502, MAE: 0.8248\n",
      "Optimizer: adagrad, Activation Function: relu, Learning Rate: 0.001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "  MSE: 1.6047, RMSE: 1.2667, R^2: -0.7559, MAE: 0.9500\n",
      "Optimizer: adagrad, Activation Function: relu, Learning Rate: 0.01\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "  MSE: 1.8854, RMSE: 1.3731, R^2: -1.0631, MAE: 0.9486\n",
      "Optimizer: adagrad, Activation Function: relu, Learning Rate: 0.1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "  MSE: 1.5016, RMSE: 1.2254, R^2: -0.6431, MAE: 0.8520\n",
      "Optimizer: adagrad, Activation Function: sigmoid, Learning Rate: 0.0001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "  MSE: 1.2448, RMSE: 1.1157, R^2: -0.3621, MAE: 0.9209\n",
      "Optimizer: adagrad, Activation Function: sigmoid, Learning Rate: 0.001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "  MSE: 0.9636, RMSE: 0.9816, R^2: -0.0544, MAE: 0.7186\n",
      "Optimizer: adagrad, Activation Function: sigmoid, Learning Rate: 0.01\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "  MSE: 1.0712, RMSE: 1.0350, R^2: -0.1722, MAE: 0.7044\n",
      "Optimizer: adagrad, Activation Function: sigmoid, Learning Rate: 0.1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "  MSE: 1.0166, RMSE: 1.0083, R^2: -0.1125, MAE: 0.6845\n",
      "Optimizer: adagrad, Activation Function: tanh, Learning Rate: 0.0001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "  MSE: 1.2309, RMSE: 1.1095, R^2: -0.3469, MAE: 0.8407\n",
      "Optimizer: adagrad, Activation Function: tanh, Learning Rate: 0.001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "  MSE: 0.8221, RMSE: 0.9067, R^2: 0.1004, MAE: 0.6573\n",
      "Optimizer: adagrad, Activation Function: tanh, Learning Rate: 0.01\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "  MSE: 1.3123, RMSE: 1.1456, R^2: -0.4360, MAE: 0.8820\n",
      "Optimizer: adagrad, Activation Function: tanh, Learning Rate: 0.1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "  MSE: 0.8196, RMSE: 0.9053, R^2: 0.1031, MAE: 0.7389\n",
      "Optimizer: adagrad, Activation Function: softmax, Learning Rate: 0.0001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "  MSE: 1.9243, RMSE: 1.3872, R^2: -1.1057, MAE: 1.1148\n",
      "Optimizer: adagrad, Activation Function: softmax, Learning Rate: 0.001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "  MSE: 1.9243, RMSE: 1.3872, R^2: -1.1057, MAE: 1.1148\n",
      "Optimizer: adagrad, Activation Function: softmax, Learning Rate: 0.01\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "  MSE: 1.9243, RMSE: 1.3872, R^2: -1.1057, MAE: 1.1148\n",
      "Optimizer: adagrad, Activation Function: softmax, Learning Rate: 0.1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "  MSE: 1.9243, RMSE: 1.3872, R^2: -1.1057, MAE: 1.1148\n",
      "Optimizer: adam, Activation Function: relu, Learning Rate: 0.0001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "  MSE: 3.2748, RMSE: 1.8096, R^2: -3.2932, MAE: 0.9607\n",
      "Optimizer: adam, Activation Function: relu, Learning Rate: 0.001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "  MSE: 1.3895, RMSE: 1.1788, R^2: -0.8216, MAE: 0.8114\n",
      "Optimizer: adam, Activation Function: relu, Learning Rate: 0.01\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "  MSE: 2.1650, RMSE: 1.4714, R^2: -1.8382, MAE: 0.9522\n",
      "Optimizer: adam, Activation Function: relu, Learning Rate: 0.1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "  MSE: 1.6798, RMSE: 1.2961, R^2: -1.2021, MAE: 0.9063\n",
      "Optimizer: adam, Activation Function: sigmoid, Learning Rate: 0.0001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "  MSE: 1.0533, RMSE: 1.0263, R^2: -0.3808, MAE: 0.6895\n",
      "Optimizer: adam, Activation Function: sigmoid, Learning Rate: 0.001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "  MSE: 1.0636, RMSE: 1.0313, R^2: -0.3943, MAE: 0.7063\n",
      "Optimizer: adam, Activation Function: sigmoid, Learning Rate: 0.01\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "  MSE: 0.9480, RMSE: 0.9736, R^2: -0.2427, MAE: 0.6651\n",
      "Optimizer: adam, Activation Function: sigmoid, Learning Rate: 0.1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "  MSE: 0.9594, RMSE: 0.9795, R^2: -0.2577, MAE: 0.6729\n",
      "Optimizer: adam, Activation Function: tanh, Learning Rate: 0.0001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "  MSE: 0.9286, RMSE: 0.9637, R^2: -0.2174, MAE: 0.7555\n",
      "Optimizer: adam, Activation Function: tanh, Learning Rate: 0.001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "  MSE: 0.8213, RMSE: 0.9063, R^2: -0.0767, MAE: 0.6986\n",
      "Optimizer: adam, Activation Function: tanh, Learning Rate: 0.01\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "  MSE: 0.6025, RMSE: 0.7762, R^2: 0.2101, MAE: 0.6341\n",
      "Optimizer: adam, Activation Function: tanh, Learning Rate: 0.1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "  MSE: 0.8662, RMSE: 0.9307, R^2: -0.1355, MAE: 0.7112\n",
      "Optimizer: adam, Activation Function: softmax, Learning Rate: 0.0001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "  MSE: 2.0929, RMSE: 1.4467, R^2: -1.7436, MAE: 1.1533\n",
      "Optimizer: adam, Activation Function: softmax, Learning Rate: 0.001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "  MSE: 2.0929, RMSE: 1.4467, R^2: -1.7436, MAE: 1.1533\n",
      "Optimizer: adam, Activation Function: softmax, Learning Rate: 0.01\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "  MSE: 2.0929, RMSE: 1.4467, R^2: -1.7436, MAE: 1.1533\n",
      "Optimizer: adam, Activation Function: softmax, Learning Rate: 0.1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "  MSE: 2.0929, RMSE: 1.4467, R^2: -1.7436, MAE: 1.1533\n",
      "Optimizer: sgd, Activation Function: relu, Learning Rate: 0.0001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "  MSE: 1.6737, RMSE: 1.2937, R^2: -1.1941, MAE: 0.8641\n",
      "Optimizer: sgd, Activation Function: relu, Learning Rate: 0.001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "  MSE: 3.0662, RMSE: 1.7510, R^2: -3.0196, MAE: 1.1271\n",
      "Optimizer: sgd, Activation Function: relu, Learning Rate: 0.01\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "  MSE: 1.4013, RMSE: 1.1837, R^2: -0.8370, MAE: 0.8490\n",
      "Optimizer: sgd, Activation Function: relu, Learning Rate: 0.1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "  MSE: 177.9844, RMSE: 13.3411, R^2: -232.3307, MAE: 4.8914\n",
      "Optimizer: sgd, Activation Function: sigmoid, Learning Rate: 0.0001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "  MSE: 0.8454, RMSE: 0.9194, R^2: -0.1082, MAE: 0.6471\n",
      "Optimizer: sgd, Activation Function: sigmoid, Learning Rate: 0.001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "  MSE: 0.9058, RMSE: 0.9518, R^2: -0.1875, MAE: 0.6709\n",
      "Optimizer: sgd, Activation Function: sigmoid, Learning Rate: 0.01\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "  MSE: 0.9622, RMSE: 0.9809, R^2: -0.2614, MAE: 0.7053\n",
      "Optimizer: sgd, Activation Function: sigmoid, Learning Rate: 0.1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "  MSE: 1.0281, RMSE: 1.0140, R^2: -0.3479, MAE: 0.6909\n",
      "Optimizer: sgd, Activation Function: tanh, Learning Rate: 0.0001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "  MSE: 1.1862, RMSE: 1.0891, R^2: -0.5550, MAE: 0.8248\n",
      "Optimizer: sgd, Activation Function: tanh, Learning Rate: 0.001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "  MSE: 0.8879, RMSE: 0.9423, R^2: -0.1640, MAE: 0.7419\n",
      "Optimizer: sgd, Activation Function: tanh, Learning Rate: 0.01\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "  MSE: 0.5130, RMSE: 0.7162, R^2: 0.3275, MAE: 0.5981\n",
      "Optimizer: sgd, Activation Function: tanh, Learning Rate: 0.1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "  MSE: 0.8641, RMSE: 0.9296, R^2: -0.1328, MAE: 0.6965\n",
      "Optimizer: sgd, Activation Function: softmax, Learning Rate: 0.0001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "  MSE: 2.0929, RMSE: 1.4467, R^2: -1.7436, MAE: 1.1533\n",
      "Optimizer: sgd, Activation Function: softmax, Learning Rate: 0.001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "  MSE: 2.0929, RMSE: 1.4467, R^2: -1.7436, MAE: 1.1533\n",
      "Optimizer: sgd, Activation Function: softmax, Learning Rate: 0.01\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "  MSE: 2.0929, RMSE: 1.4467, R^2: -1.7436, MAE: 1.1533\n",
      "Optimizer: sgd, Activation Function: softmax, Learning Rate: 0.1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "  MSE: 2.0929, RMSE: 1.4467, R^2: -1.7436, MAE: 1.1533\n",
      "Optimizer: rmsprop, Activation Function: relu, Learning Rate: 0.0001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "  MSE: 1.7556, RMSE: 1.3250, R^2: -1.3015, MAE: 0.8941\n",
      "Optimizer: rmsprop, Activation Function: relu, Learning Rate: 0.001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "  MSE: 0.9759, RMSE: 0.9879, R^2: -0.2794, MAE: 0.7661\n",
      "Optimizer: rmsprop, Activation Function: relu, Learning Rate: 0.01\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "  MSE: 1.4246, RMSE: 1.1936, R^2: -0.8676, MAE: 0.8111\n",
      "Optimizer: rmsprop, Activation Function: relu, Learning Rate: 0.1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "  MSE: 1.6228, RMSE: 1.2739, R^2: -1.1274, MAE: 0.8540\n",
      "Optimizer: rmsprop, Activation Function: sigmoid, Learning Rate: 0.0001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "  MSE: 0.9995, RMSE: 0.9998, R^2: -0.3103, MAE: 0.6582\n",
      "Optimizer: rmsprop, Activation Function: sigmoid, Learning Rate: 0.001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "  MSE: 0.9401, RMSE: 0.9696, R^2: -0.2324, MAE: 0.6383\n",
      "Optimizer: rmsprop, Activation Function: sigmoid, Learning Rate: 0.01\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "  MSE: 0.9200, RMSE: 0.9592, R^2: -0.2061, MAE: 0.6446\n",
      "Optimizer: rmsprop, Activation Function: sigmoid, Learning Rate: 0.1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "  MSE: 0.8880, RMSE: 0.9423, R^2: -0.1641, MAE: 0.6585\n",
      "Optimizer: rmsprop, Activation Function: tanh, Learning Rate: 0.0001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "  MSE: 1.0924, RMSE: 1.0452, R^2: -0.4320, MAE: 0.7307\n",
      "Optimizer: rmsprop, Activation Function: tanh, Learning Rate: 0.001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "  MSE: 1.2111, RMSE: 1.1005, R^2: -0.5877, MAE: 0.8641\n",
      "Optimizer: rmsprop, Activation Function: tanh, Learning Rate: 0.01\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "  MSE: 0.7633, RMSE: 0.8737, R^2: -0.0006, MAE: 0.7011\n",
      "Optimizer: rmsprop, Activation Function: tanh, Learning Rate: 0.1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "  MSE: 0.9904, RMSE: 0.9952, R^2: -0.2984, MAE: 0.7573\n",
      "Optimizer: rmsprop, Activation Function: softmax, Learning Rate: 0.0001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "  MSE: 2.0929, RMSE: 1.4467, R^2: -1.7436, MAE: 1.1533\n",
      "Optimizer: rmsprop, Activation Function: softmax, Learning Rate: 0.001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "  MSE: 2.0929, RMSE: 1.4467, R^2: -1.7436, MAE: 1.1533\n",
      "Optimizer: rmsprop, Activation Function: softmax, Learning Rate: 0.01\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "  MSE: 2.0929, RMSE: 1.4467, R^2: -1.7436, MAE: 1.1533\n",
      "Optimizer: rmsprop, Activation Function: softmax, Learning Rate: 0.1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "  MSE: 2.0929, RMSE: 1.4467, R^2: -1.7436, MAE: 1.1533\n",
      "Optimizer: adagrad, Activation Function: relu, Learning Rate: 0.0001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "  MSE: 2.8780, RMSE: 1.6965, R^2: -2.7730, MAE: 1.1062\n",
      "Optimizer: adagrad, Activation Function: relu, Learning Rate: 0.001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "  MSE: 1.5676, RMSE: 1.2520, R^2: -1.0551, MAE: 0.8585\n",
      "Optimizer: adagrad, Activation Function: relu, Learning Rate: 0.01\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "  MSE: 0.9796, RMSE: 0.9897, R^2: -0.2842, MAE: 0.7353\n",
      "Optimizer: adagrad, Activation Function: relu, Learning Rate: 0.1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "  MSE: 1.1774, RMSE: 1.0851, R^2: -0.5435, MAE: 0.7722\n",
      "Optimizer: adagrad, Activation Function: sigmoid, Learning Rate: 0.0001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "  MSE: 1.1714, RMSE: 1.0823, R^2: -0.5357, MAE: 0.7574\n",
      "Optimizer: adagrad, Activation Function: sigmoid, Learning Rate: 0.001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "  MSE: 1.0422, RMSE: 1.0209, R^2: -0.3663, MAE: 0.7392\n",
      "Optimizer: adagrad, Activation Function: sigmoid, Learning Rate: 0.01\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "  MSE: 1.2261, RMSE: 1.1073, R^2: -0.6073, MAE: 0.7857\n",
      "Optimizer: adagrad, Activation Function: sigmoid, Learning Rate: 0.1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "  MSE: 1.0306, RMSE: 1.0152, R^2: -0.3510, MAE: 0.6969\n",
      "Optimizer: adagrad, Activation Function: tanh, Learning Rate: 0.0001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "  MSE: 1.1683, RMSE: 1.0809, R^2: -0.5316, MAE: 0.8491\n",
      "Optimizer: adagrad, Activation Function: tanh, Learning Rate: 0.001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "  MSE: 1.5087, RMSE: 1.2283, R^2: -0.9779, MAE: 1.0767\n",
      "Optimizer: adagrad, Activation Function: tanh, Learning Rate: 0.01\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "  MSE: 0.9772, RMSE: 0.9885, R^2: -0.2811, MAE: 0.7901\n",
      "Optimizer: adagrad, Activation Function: tanh, Learning Rate: 0.1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "  MSE: 1.2719, RMSE: 1.1278, R^2: -0.6674, MAE: 0.8472\n",
      "Optimizer: adagrad, Activation Function: softmax, Learning Rate: 0.0001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "  MSE: 2.0929, RMSE: 1.4467, R^2: -1.7436, MAE: 1.1533\n",
      "Optimizer: adagrad, Activation Function: softmax, Learning Rate: 0.001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "  MSE: 2.0929, RMSE: 1.4467, R^2: -1.7436, MAE: 1.1533\n",
      "Optimizer: adagrad, Activation Function: softmax, Learning Rate: 0.01\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "  MSE: 2.0929, RMSE: 1.4467, R^2: -1.7436, MAE: 1.1533\n",
      "Optimizer: adagrad, Activation Function: softmax, Learning Rate: 0.1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "  MSE: 2.0929, RMSE: 1.4467, R^2: -1.7436, MAE: 1.1533\n",
      "Optimizer: adam, Activation Function: relu, Learning Rate: 0.0001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "  MSE: 2.2382, RMSE: 1.4961, R^2: -0.9941, MAE: 1.0272\n",
      "Optimizer: adam, Activation Function: relu, Learning Rate: 0.001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "  MSE: 0.9705, RMSE: 0.9851, R^2: 0.1354, MAE: 0.7961\n",
      "Optimizer: adam, Activation Function: relu, Learning Rate: 0.01\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "  MSE: 1.5457, RMSE: 1.2433, R^2: -0.3771, MAE: 0.9649\n",
      "Optimizer: adam, Activation Function: relu, Learning Rate: 0.1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "  MSE: 1.1681, RMSE: 1.0808, R^2: -0.0407, MAE: 0.9203\n",
      "Optimizer: adam, Activation Function: sigmoid, Learning Rate: 0.0001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "  MSE: 0.8662, RMSE: 0.9307, R^2: 0.2283, MAE: 0.6813\n",
      "Optimizer: adam, Activation Function: sigmoid, Learning Rate: 0.001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "  MSE: 0.9127, RMSE: 0.9554, R^2: 0.1868, MAE: 0.7499\n",
      "Optimizer: adam, Activation Function: sigmoid, Learning Rate: 0.01\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "  MSE: 0.8080, RMSE: 0.8989, R^2: 0.2801, MAE: 0.6439\n",
      "Optimizer: adam, Activation Function: sigmoid, Learning Rate: 0.1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "  MSE: 0.9125, RMSE: 0.9552, R^2: 0.1870, MAE: 0.7274\n",
      "Optimizer: adam, Activation Function: tanh, Learning Rate: 0.0001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "  MSE: 0.9529, RMSE: 0.9762, R^2: 0.1510, MAE: 0.7186\n",
      "Optimizer: adam, Activation Function: tanh, Learning Rate: 0.001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "  MSE: 0.9764, RMSE: 0.9882, R^2: 0.1300, MAE: 0.7333\n",
      "Optimizer: adam, Activation Function: tanh, Learning Rate: 0.01\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "  MSE: 0.8282, RMSE: 0.9100, R^2: 0.2621, MAE: 0.6822\n",
      "Optimizer: adam, Activation Function: tanh, Learning Rate: 0.1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "  MSE: 0.6541, RMSE: 0.8088, R^2: 0.4172, MAE: 0.6550\n",
      "Optimizer: adam, Activation Function: softmax, Learning Rate: 0.0001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "  MSE: 1.5855, RMSE: 1.2591, R^2: -0.4125, MAE: 0.9657\n",
      "Optimizer: adam, Activation Function: softmax, Learning Rate: 0.001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "  MSE: 1.5855, RMSE: 1.2591, R^2: -0.4125, MAE: 0.9657\n",
      "Optimizer: adam, Activation Function: softmax, Learning Rate: 0.01\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "  MSE: 1.5855, RMSE: 1.2591, R^2: -0.4125, MAE: 0.9657\n",
      "Optimizer: adam, Activation Function: softmax, Learning Rate: 0.1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "  MSE: 1.5855, RMSE: 1.2591, R^2: -0.4125, MAE: 0.9657\n",
      "Optimizer: sgd, Activation Function: relu, Learning Rate: 0.0001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "  MSE: 1.1941, RMSE: 1.0928, R^2: -0.0639, MAE: 0.8724\n",
      "Optimizer: sgd, Activation Function: relu, Learning Rate: 0.001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "  MSE: 28.7728, RMSE: 5.3640, R^2: -24.6350, MAE: 1.8041\n",
      "Optimizer: sgd, Activation Function: relu, Learning Rate: 0.01\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "  MSE: 1.1941, RMSE: 1.0928, R^2: -0.0639, MAE: 0.8724\n",
      "Optimizer: sgd, Activation Function: relu, Learning Rate: 0.1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "  MSE: 2.5978, RMSE: 1.6118, R^2: -1.3145, MAE: 1.1068\n",
      "Optimizer: sgd, Activation Function: sigmoid, Learning Rate: 0.0001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "  MSE: 0.9619, RMSE: 0.9807, R^2: 0.1430, MAE: 0.7508\n",
      "Optimizer: sgd, Activation Function: sigmoid, Learning Rate: 0.001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "  MSE: 0.8309, RMSE: 0.9116, R^2: 0.2597, MAE: 0.6879\n",
      "Optimizer: sgd, Activation Function: sigmoid, Learning Rate: 0.01\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "  MSE: 0.8182, RMSE: 0.9046, R^2: 0.2710, MAE: 0.6836\n",
      "Optimizer: sgd, Activation Function: sigmoid, Learning Rate: 0.1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "  MSE: 1.0534, RMSE: 1.0263, R^2: 0.0615, MAE: 0.7766\n",
      "Optimizer: sgd, Activation Function: tanh, Learning Rate: 0.0001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "  MSE: 0.6886, RMSE: 0.8298, R^2: 0.3865, MAE: 0.6480\n",
      "Optimizer: sgd, Activation Function: tanh, Learning Rate: 0.001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "  MSE: 0.9629, RMSE: 0.9813, R^2: 0.1421, MAE: 0.7377\n",
      "Optimizer: sgd, Activation Function: tanh, Learning Rate: 0.01\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "  MSE: 0.7650, RMSE: 0.8746, R^2: 0.3184, MAE: 0.7004\n",
      "Optimizer: sgd, Activation Function: tanh, Learning Rate: 0.1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "  MSE: 0.7500, RMSE: 0.8660, R^2: 0.3318, MAE: 0.6527\n",
      "Optimizer: sgd, Activation Function: softmax, Learning Rate: 0.0001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "  MSE: 1.5855, RMSE: 1.2591, R^2: -0.4125, MAE: 0.9657\n",
      "Optimizer: sgd, Activation Function: softmax, Learning Rate: 0.001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "  MSE: 1.5855, RMSE: 1.2591, R^2: -0.4125, MAE: 0.9657\n",
      "Optimizer: sgd, Activation Function: softmax, Learning Rate: 0.01\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "  MSE: 1.5855, RMSE: 1.2591, R^2: -0.4125, MAE: 0.9657\n",
      "Optimizer: sgd, Activation Function: softmax, Learning Rate: 0.1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "  MSE: 1.5855, RMSE: 1.2591, R^2: -0.4125, MAE: 0.9657\n",
      "Optimizer: rmsprop, Activation Function: relu, Learning Rate: 0.0001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "  MSE: 0.9579, RMSE: 0.9787, R^2: 0.1465, MAE: 0.7327\n",
      "Optimizer: rmsprop, Activation Function: relu, Learning Rate: 0.001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "  MSE: 1.4470, RMSE: 1.2029, R^2: -0.2892, MAE: 0.8935\n",
      "Optimizer: rmsprop, Activation Function: relu, Learning Rate: 0.01\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "  MSE: 1.1688, RMSE: 1.0811, R^2: -0.0414, MAE: 0.8647\n",
      "Optimizer: rmsprop, Activation Function: relu, Learning Rate: 0.1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "  MSE: 2.8408, RMSE: 1.6855, R^2: -1.5310, MAE: 0.9890\n",
      "Optimizer: rmsprop, Activation Function: sigmoid, Learning Rate: 0.0001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "  MSE: 0.8564, RMSE: 0.9254, R^2: 0.2370, MAE: 0.6831\n",
      "Optimizer: rmsprop, Activation Function: sigmoid, Learning Rate: 0.001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "  MSE: 0.8644, RMSE: 0.9298, R^2: 0.2298, MAE: 0.6720\n",
      "Optimizer: rmsprop, Activation Function: sigmoid, Learning Rate: 0.01\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "  MSE: 0.8858, RMSE: 0.9412, R^2: 0.2108, MAE: 0.7119\n",
      "Optimizer: rmsprop, Activation Function: sigmoid, Learning Rate: 0.1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "  MSE: 0.8856, RMSE: 0.9411, R^2: 0.2110, MAE: 0.7015\n",
      "Optimizer: rmsprop, Activation Function: tanh, Learning Rate: 0.0001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "  MSE: 0.6619, RMSE: 0.8136, R^2: 0.4103, MAE: 0.6275\n",
      "Optimizer: rmsprop, Activation Function: tanh, Learning Rate: 0.001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "  MSE: 1.0845, RMSE: 1.0414, R^2: 0.0337, MAE: 0.7776\n",
      "Optimizer: rmsprop, Activation Function: tanh, Learning Rate: 0.01\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "  MSE: 0.9804, RMSE: 0.9902, R^2: 0.1265, MAE: 0.6458\n",
      "Optimizer: rmsprop, Activation Function: tanh, Learning Rate: 0.1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "  MSE: 1.1606, RMSE: 1.0773, R^2: -0.0340, MAE: 0.8649\n",
      "Optimizer: rmsprop, Activation Function: softmax, Learning Rate: 0.0001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "  MSE: 1.5855, RMSE: 1.2591, R^2: -0.4125, MAE: 0.9657\n",
      "Optimizer: rmsprop, Activation Function: softmax, Learning Rate: 0.001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "  MSE: 1.5855, RMSE: 1.2591, R^2: -0.4125, MAE: 0.9657\n",
      "Optimizer: rmsprop, Activation Function: softmax, Learning Rate: 0.01\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "  MSE: 1.5855, RMSE: 1.2591, R^2: -0.4125, MAE: 0.9657\n",
      "Optimizer: rmsprop, Activation Function: softmax, Learning Rate: 0.1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "  MSE: 1.5855, RMSE: 1.2591, R^2: -0.4125, MAE: 0.9657\n",
      "Optimizer: adagrad, Activation Function: relu, Learning Rate: 0.0001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "  MSE: 0.8894, RMSE: 0.9431, R^2: 0.2076, MAE: 0.7712\n",
      "Optimizer: adagrad, Activation Function: relu, Learning Rate: 0.001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "  MSE: 2.6533, RMSE: 1.6289, R^2: -1.3639, MAE: 1.1077\n",
      "Optimizer: adagrad, Activation Function: relu, Learning Rate: 0.01\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "  MSE: 1.1618, RMSE: 1.0779, R^2: -0.0351, MAE: 0.8304\n",
      "Optimizer: adagrad, Activation Function: relu, Learning Rate: 0.1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "  MSE: 3.9568, RMSE: 1.9892, R^2: -2.5253, MAE: 1.1473\n",
      "Optimizer: adagrad, Activation Function: sigmoid, Learning Rate: 0.0001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "  MSE: 1.0263, RMSE: 1.0131, R^2: 0.0856, MAE: 0.7519\n",
      "Optimizer: adagrad, Activation Function: sigmoid, Learning Rate: 0.001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "  MSE: 1.0156, RMSE: 1.0078, R^2: 0.0951, MAE: 0.7557\n",
      "Optimizer: adagrad, Activation Function: sigmoid, Learning Rate: 0.01\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "  MSE: 0.9235, RMSE: 0.9610, R^2: 0.1772, MAE: 0.7304\n",
      "Optimizer: adagrad, Activation Function: sigmoid, Learning Rate: 0.1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "  MSE: 1.2490, RMSE: 1.1176, R^2: -0.1127, MAE: 0.8916\n",
      "Optimizer: adagrad, Activation Function: tanh, Learning Rate: 0.0001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "  MSE: 0.9463, RMSE: 0.9728, R^2: 0.1569, MAE: 0.7799\n",
      "Optimizer: adagrad, Activation Function: tanh, Learning Rate: 0.001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "  MSE: 1.0971, RMSE: 1.0474, R^2: 0.0225, MAE: 0.7767\n",
      "Optimizer: adagrad, Activation Function: tanh, Learning Rate: 0.01\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "  MSE: 2.0240, RMSE: 1.4227, R^2: -0.8033, MAE: 1.0665\n",
      "Optimizer: adagrad, Activation Function: tanh, Learning Rate: 0.1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "  MSE: 1.3312, RMSE: 1.1538, R^2: -0.1860, MAE: 0.8356\n",
      "Optimizer: adagrad, Activation Function: softmax, Learning Rate: 0.0001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "  MSE: 1.5855, RMSE: 1.2591, R^2: -0.4125, MAE: 0.9657\n",
      "Optimizer: adagrad, Activation Function: softmax, Learning Rate: 0.001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "  MSE: 1.5855, RMSE: 1.2591, R^2: -0.4125, MAE: 0.9657\n",
      "Optimizer: adagrad, Activation Function: softmax, Learning Rate: 0.01\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "  MSE: 1.5855, RMSE: 1.2591, R^2: -0.4125, MAE: 0.9657\n",
      "Optimizer: adagrad, Activation Function: softmax, Learning Rate: 0.1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "  MSE: 1.5855, RMSE: 1.2591, R^2: -0.4125, MAE: 0.9657\n",
      "Optimizer: adam, Activation Function: relu, Learning Rate: 0.0001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "  MSE: 0.7276, RMSE: 0.8530, R^2: -0.5731, MAE: 0.6162\n",
      "Optimizer: adam, Activation Function: relu, Learning Rate: 0.001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "  MSE: 0.7354, RMSE: 0.8576, R^2: -0.5900, MAE: 0.6084\n",
      "Optimizer: adam, Activation Function: relu, Learning Rate: 0.01\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "  MSE: 0.7158, RMSE: 0.8460, R^2: -0.5476, MAE: 0.5799\n",
      "Optimizer: adam, Activation Function: relu, Learning Rate: 0.1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "  MSE: 0.6994, RMSE: 0.8363, R^2: -0.5121, MAE: 0.6079\n",
      "Optimizer: adam, Activation Function: sigmoid, Learning Rate: 0.0001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "  MSE: 0.4444, RMSE: 0.6667, R^2: 0.0391, MAE: 0.4415\n",
      "Optimizer: adam, Activation Function: sigmoid, Learning Rate: 0.001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "  MSE: 0.6463, RMSE: 0.8039, R^2: -0.3973, MAE: 0.5509\n",
      "Optimizer: adam, Activation Function: sigmoid, Learning Rate: 0.01\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "  MSE: 0.5081, RMSE: 0.7128, R^2: -0.0986, MAE: 0.4473\n",
      "Optimizer: adam, Activation Function: sigmoid, Learning Rate: 0.1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "  MSE: 0.4802, RMSE: 0.6929, R^2: -0.0381, MAE: 0.4392\n",
      "Optimizer: adam, Activation Function: tanh, Learning Rate: 0.0001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "  MSE: 0.7595, RMSE: 0.8715, R^2: -0.6420, MAE: 0.6641\n",
      "Optimizer: adam, Activation Function: tanh, Learning Rate: 0.001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "  MSE: 0.9058, RMSE: 0.9517, R^2: -0.9583, MAE: 0.7587\n",
      "Optimizer: adam, Activation Function: tanh, Learning Rate: 0.01\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "  MSE: 0.6653, RMSE: 0.8157, R^2: -0.4385, MAE: 0.5998\n",
      "Optimizer: adam, Activation Function: tanh, Learning Rate: 0.1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "  MSE: 0.6949, RMSE: 0.8336, R^2: -0.5024, MAE: 0.6837\n",
      "Optimizer: adam, Activation Function: softmax, Learning Rate: 0.0001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "  MSE: 0.8437, RMSE: 0.9185, R^2: -0.8241, MAE: 0.7541\n",
      "Optimizer: adam, Activation Function: softmax, Learning Rate: 0.001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "  MSE: 0.8437, RMSE: 0.9185, R^2: -0.8241, MAE: 0.7541\n",
      "Optimizer: adam, Activation Function: softmax, Learning Rate: 0.01\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "  MSE: 0.8437, RMSE: 0.9185, R^2: -0.8241, MAE: 0.7541\n",
      "Optimizer: adam, Activation Function: softmax, Learning Rate: 0.1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "  MSE: 0.8437, RMSE: 0.9185, R^2: -0.8241, MAE: 0.7541\n",
      "Optimizer: sgd, Activation Function: relu, Learning Rate: 0.0001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "  MSE: 1279.3837, RMSE: 35.7685, R^2: -2765.0967, MAE: 7.2783\n",
      "Optimizer: sgd, Activation Function: relu, Learning Rate: 0.001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "  MSE: 5.6072, RMSE: 2.3680, R^2: -11.1232, MAE: 0.9418\n",
      "Optimizer: sgd, Activation Function: relu, Learning Rate: 0.01\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "  MSE: 4.4536, RMSE: 2.1103, R^2: -8.6288, MAE: 0.8966\n",
      "Optimizer: sgd, Activation Function: relu, Learning Rate: 0.1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "  MSE: 86.2174, RMSE: 9.2853, R^2: -185.4067, MAE: 2.2698\n",
      "Optimizer: sgd, Activation Function: sigmoid, Learning Rate: 0.0001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "  MSE: 0.3611, RMSE: 0.6009, R^2: 0.2192, MAE: 0.4175\n",
      "Optimizer: sgd, Activation Function: sigmoid, Learning Rate: 0.001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "  MSE: 0.4285, RMSE: 0.6546, R^2: 0.0735, MAE: 0.4786\n",
      "Optimizer: sgd, Activation Function: sigmoid, Learning Rate: 0.01\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "  MSE: 0.3704, RMSE: 0.6086, R^2: 0.1992, MAE: 0.4247\n",
      "Optimizer: sgd, Activation Function: sigmoid, Learning Rate: 0.1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "  MSE: 0.4535, RMSE: 0.6734, R^2: 0.0194, MAE: 0.4547\n",
      "Optimizer: sgd, Activation Function: tanh, Learning Rate: 0.0001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "  MSE: 0.8037, RMSE: 0.8965, R^2: -0.7377, MAE: 0.7041\n",
      "Optimizer: sgd, Activation Function: tanh, Learning Rate: 0.001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "  MSE: 0.9184, RMSE: 0.9583, R^2: -0.9855, MAE: 0.7568\n",
      "Optimizer: sgd, Activation Function: tanh, Learning Rate: 0.01\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "  MSE: 1.0944, RMSE: 1.0461, R^2: -1.3661, MAE: 0.7354\n",
      "Optimizer: sgd, Activation Function: tanh, Learning Rate: 0.1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "  MSE: 0.7161, RMSE: 0.8463, R^2: -0.5483, MAE: 0.6417\n",
      "Optimizer: sgd, Activation Function: softmax, Learning Rate: 0.0001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "  MSE: 0.8437, RMSE: 0.9185, R^2: -0.8241, MAE: 0.7541\n",
      "Optimizer: sgd, Activation Function: softmax, Learning Rate: 0.001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "  MSE: 0.8437, RMSE: 0.9185, R^2: -0.8241, MAE: 0.7541\n",
      "Optimizer: sgd, Activation Function: softmax, Learning Rate: 0.01\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "  MSE: 0.8437, RMSE: 0.9185, R^2: -0.8241, MAE: 0.7541\n",
      "Optimizer: sgd, Activation Function: softmax, Learning Rate: 0.1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "  MSE: 0.8437, RMSE: 0.9185, R^2: -0.8241, MAE: 0.7541\n",
      "Optimizer: rmsprop, Activation Function: relu, Learning Rate: 0.0001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "  MSE: 0.6077, RMSE: 0.7796, R^2: -0.3139, MAE: 0.6119\n",
      "Optimizer: rmsprop, Activation Function: relu, Learning Rate: 0.001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "  MSE: 0.5605, RMSE: 0.7486, R^2: -0.2118, MAE: 0.5571\n",
      "Optimizer: rmsprop, Activation Function: relu, Learning Rate: 0.01\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "  MSE: 0.6972, RMSE: 0.8350, R^2: -0.5074, MAE: 0.6265\n",
      "Optimizer: rmsprop, Activation Function: relu, Learning Rate: 0.1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "  MSE: 0.4603, RMSE: 0.6785, R^2: 0.0047, MAE: 0.5562\n",
      "Optimizer: rmsprop, Activation Function: sigmoid, Learning Rate: 0.0001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "  MSE: 0.3513, RMSE: 0.5927, R^2: 0.2404, MAE: 0.4209\n",
      "Optimizer: rmsprop, Activation Function: sigmoid, Learning Rate: 0.001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "  MSE: 0.4011, RMSE: 0.6333, R^2: 0.1328, MAE: 0.4385\n",
      "Optimizer: rmsprop, Activation Function: sigmoid, Learning Rate: 0.01\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "  MSE: 0.4703, RMSE: 0.6858, R^2: -0.0168, MAE: 0.4493\n",
      "Optimizer: rmsprop, Activation Function: sigmoid, Learning Rate: 0.1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "  MSE: 0.4184, RMSE: 0.6468, R^2: 0.0954, MAE: 0.4377\n",
      "Optimizer: rmsprop, Activation Function: tanh, Learning Rate: 0.0001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "  MSE: 0.5960, RMSE: 0.7720, R^2: -0.2885, MAE: 0.5815\n",
      "Optimizer: rmsprop, Activation Function: tanh, Learning Rate: 0.001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "  MSE: 0.7146, RMSE: 0.8454, R^2: -0.5451, MAE: 0.6684\n",
      "Optimizer: rmsprop, Activation Function: tanh, Learning Rate: 0.01\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "  MSE: 0.6415, RMSE: 0.8009, R^2: -0.3869, MAE: 0.5257\n",
      "Optimizer: rmsprop, Activation Function: tanh, Learning Rate: 0.1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "  MSE: 0.5472, RMSE: 0.7397, R^2: -0.1830, MAE: 0.6276\n",
      "Optimizer: rmsprop, Activation Function: softmax, Learning Rate: 0.0001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "  MSE: 0.8437, RMSE: 0.9185, R^2: -0.8241, MAE: 0.7541\n",
      "Optimizer: rmsprop, Activation Function: softmax, Learning Rate: 0.001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "  MSE: 0.8437, RMSE: 0.9185, R^2: -0.8241, MAE: 0.7541\n",
      "Optimizer: rmsprop, Activation Function: softmax, Learning Rate: 0.01\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "  MSE: 0.8437, RMSE: 0.9185, R^2: -0.8241, MAE: 0.7541\n",
      "Optimizer: rmsprop, Activation Function: softmax, Learning Rate: 0.1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "  MSE: 0.8437, RMSE: 0.9185, R^2: -0.8241, MAE: 0.7541\n",
      "Optimizer: adagrad, Activation Function: relu, Learning Rate: 0.0001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "  MSE: 0.9599, RMSE: 0.9798, R^2: -1.0754, MAE: 0.6533\n",
      "Optimizer: adagrad, Activation Function: relu, Learning Rate: 0.001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "  MSE: 0.5691, RMSE: 0.7544, R^2: -0.2305, MAE: 0.5709\n",
      "Optimizer: adagrad, Activation Function: relu, Learning Rate: 0.01\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "  MSE: 0.4084, RMSE: 0.6391, R^2: 0.1169, MAE: 0.4948\n",
      "Optimizer: adagrad, Activation Function: relu, Learning Rate: 0.1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "  MSE: 0.5609, RMSE: 0.7489, R^2: -0.2126, MAE: 0.5956\n",
      "Optimizer: adagrad, Activation Function: sigmoid, Learning Rate: 0.0001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "  MSE: 0.4839, RMSE: 0.6956, R^2: -0.0463, MAE: 0.4963\n",
      "Optimizer: adagrad, Activation Function: sigmoid, Learning Rate: 0.001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "  MSE: 0.5238, RMSE: 0.7237, R^2: -0.1324, MAE: 0.4975\n",
      "Optimizer: adagrad, Activation Function: sigmoid, Learning Rate: 0.01\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "  MSE: 0.5831, RMSE: 0.7636, R^2: -0.2607, MAE: 0.5307\n",
      "Optimizer: adagrad, Activation Function: sigmoid, Learning Rate: 0.1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "  MSE: 0.6592, RMSE: 0.8119, R^2: -0.4251, MAE: 0.5403\n",
      "Optimizer: adagrad, Activation Function: tanh, Learning Rate: 0.0001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "  MSE: 0.6340, RMSE: 0.7963, R^2: -0.3708, MAE: 0.6626\n",
      "Optimizer: adagrad, Activation Function: tanh, Learning Rate: 0.001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "  MSE: 1.1233, RMSE: 1.0599, R^2: -1.4286, MAE: 0.8026\n",
      "Optimizer: adagrad, Activation Function: tanh, Learning Rate: 0.01\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "  MSE: 0.8729, RMSE: 0.9343, R^2: -0.8873, MAE: 0.6960\n",
      "Optimizer: adagrad, Activation Function: tanh, Learning Rate: 0.1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "  MSE: 0.6482, RMSE: 0.8051, R^2: -0.4015, MAE: 0.6556\n",
      "Optimizer: adagrad, Activation Function: softmax, Learning Rate: 0.0001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "  MSE: 0.8437, RMSE: 0.9185, R^2: -0.8241, MAE: 0.7541\n",
      "Optimizer: adagrad, Activation Function: softmax, Learning Rate: 0.001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "  MSE: 0.8437, RMSE: 0.9185, R^2: -0.8241, MAE: 0.7541\n",
      "Optimizer: adagrad, Activation Function: softmax, Learning Rate: 0.01\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "  MSE: 0.8437, RMSE: 0.9185, R^2: -0.8241, MAE: 0.7541\n",
      "Optimizer: adagrad, Activation Function: softmax, Learning Rate: 0.1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "  MSE: 0.8437, RMSE: 0.9185, R^2: -0.8241, MAE: 0.7541\n",
      "Optimizer: adam, Activation Function: relu, Learning Rate: 0.0001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "  MSE: 2.4140, RMSE: 1.5537, R^2: -1.6976, MAE: 1.0216\n",
      "Optimizer: adam, Activation Function: relu, Learning Rate: 0.001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "  MSE: 3.7914, RMSE: 1.9471, R^2: -3.2367, MAE: 1.3840\n",
      "Optimizer: adam, Activation Function: relu, Learning Rate: 0.01\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "  MSE: 1.5584, RMSE: 1.2484, R^2: -0.7414, MAE: 0.9879\n",
      "Optimizer: adam, Activation Function: relu, Learning Rate: 0.1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "  MSE: 1.8884, RMSE: 1.3742, R^2: -1.1103, MAE: 1.0329\n",
      "Optimizer: adam, Activation Function: sigmoid, Learning Rate: 0.0001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "  MSE: 1.7253, RMSE: 1.3135, R^2: -0.9280, MAE: 1.0751\n",
      "Optimizer: adam, Activation Function: sigmoid, Learning Rate: 0.001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "  MSE: 1.2317, RMSE: 1.1098, R^2: -0.3763, MAE: 0.7394\n",
      "Optimizer: adam, Activation Function: sigmoid, Learning Rate: 0.01\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "  MSE: 1.4212, RMSE: 1.1922, R^2: -0.5882, MAE: 0.8381\n",
      "Optimizer: adam, Activation Function: sigmoid, Learning Rate: 0.1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "  MSE: 1.3464, RMSE: 1.1603, R^2: -0.5045, MAE: 0.8300\n",
      "Optimizer: adam, Activation Function: tanh, Learning Rate: 0.0001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "  MSE: 0.5102, RMSE: 0.7143, R^2: 0.4299, MAE: 0.5861\n",
      "Optimizer: adam, Activation Function: tanh, Learning Rate: 0.001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "  MSE: 1.0440, RMSE: 1.0218, R^2: -0.1667, MAE: 0.8008\n",
      "Optimizer: adam, Activation Function: tanh, Learning Rate: 0.01\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "  MSE: 1.2336, RMSE: 1.1107, R^2: -0.3785, MAE: 0.8812\n",
      "Optimizer: adam, Activation Function: tanh, Learning Rate: 0.1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "  MSE: 0.9733, RMSE: 0.9865, R^2: -0.0876, MAE: 0.7627\n",
      "Optimizer: adam, Activation Function: softmax, Learning Rate: 0.0001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "  MSE: 2.5466, RMSE: 1.5958, R^2: -1.8458, MAE: 1.2852\n",
      "Optimizer: adam, Activation Function: softmax, Learning Rate: 0.001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "  MSE: 2.5466, RMSE: 1.5958, R^2: -1.8458, MAE: 1.2852\n",
      "Optimizer: adam, Activation Function: softmax, Learning Rate: 0.01\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "  MSE: 2.5466, RMSE: 1.5958, R^2: -1.8458, MAE: 1.2852\n",
      "Optimizer: adam, Activation Function: softmax, Learning Rate: 0.1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "  MSE: 2.5466, RMSE: 1.5958, R^2: -1.8458, MAE: 1.2852\n",
      "Optimizer: sgd, Activation Function: relu, Learning Rate: 0.0001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "  MSE: 1.1859, RMSE: 1.0890, R^2: -0.3252, MAE: 0.8654\n",
      "Optimizer: sgd, Activation Function: relu, Learning Rate: 0.001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "  MSE: 34.3203, RMSE: 5.8583, R^2: -37.3519, MAE: 1.8357\n",
      "Optimizer: sgd, Activation Function: relu, Learning Rate: 0.01\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "  MSE: 36.8840, RMSE: 6.0732, R^2: -40.2168, MAE: 2.2386\n",
      "Optimizer: sgd, Activation Function: relu, Learning Rate: 0.1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "  MSE: 22857848.1885, RMSE: 4780.9882, R^2: -25543023.4494, MAE: 1186.9055\n",
      "Optimizer: sgd, Activation Function: sigmoid, Learning Rate: 0.0001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "  MSE: 1.1234, RMSE: 1.0599, R^2: -0.2553, MAE: 0.7868\n",
      "Optimizer: sgd, Activation Function: sigmoid, Learning Rate: 0.001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "  MSE: 1.3589, RMSE: 1.1657, R^2: -0.5185, MAE: 0.8560\n",
      "Optimizer: sgd, Activation Function: sigmoid, Learning Rate: 0.01\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "  MSE: 1.2728, RMSE: 1.1282, R^2: -0.4223, MAE: 0.8162\n",
      "Optimizer: sgd, Activation Function: sigmoid, Learning Rate: 0.1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "  MSE: 1.3572, RMSE: 1.1650, R^2: -0.5166, MAE: 0.8693\n",
      "Optimizer: sgd, Activation Function: tanh, Learning Rate: 0.0001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "  MSE: 0.8442, RMSE: 0.9188, R^2: 0.0567, MAE: 0.6863\n",
      "Optimizer: sgd, Activation Function: tanh, Learning Rate: 0.001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "  MSE: 0.6010, RMSE: 0.7753, R^2: 0.3284, MAE: 0.6257\n",
      "Optimizer: sgd, Activation Function: tanh, Learning Rate: 0.01\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "  MSE: 0.6660, RMSE: 0.8161, R^2: 0.2558, MAE: 0.6322\n",
      "Optimizer: sgd, Activation Function: tanh, Learning Rate: 0.1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "  MSE: 1.1909, RMSE: 1.0913, R^2: -0.3308, MAE: 0.8197\n",
      "Optimizer: sgd, Activation Function: softmax, Learning Rate: 0.0001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "  MSE: 2.5466, RMSE: 1.5958, R^2: -1.8458, MAE: 1.2852\n",
      "Optimizer: sgd, Activation Function: softmax, Learning Rate: 0.001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "  MSE: 2.5466, RMSE: 1.5958, R^2: -1.8458, MAE: 1.2852\n",
      "Optimizer: sgd, Activation Function: softmax, Learning Rate: 0.01\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "  MSE: 2.5466, RMSE: 1.5958, R^2: -1.8458, MAE: 1.2852\n",
      "Optimizer: sgd, Activation Function: softmax, Learning Rate: 0.1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "  MSE: 2.5466, RMSE: 1.5958, R^2: -1.8458, MAE: 1.2852\n",
      "Optimizer: rmsprop, Activation Function: relu, Learning Rate: 0.0001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "  MSE: 1.1245, RMSE: 1.0604, R^2: -0.2566, MAE: 0.8486\n",
      "Optimizer: rmsprop, Activation Function: relu, Learning Rate: 0.001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "  MSE: 1.8734, RMSE: 1.3687, R^2: -1.0935, MAE: 0.9160\n",
      "Optimizer: rmsprop, Activation Function: relu, Learning Rate: 0.01\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "  MSE: 1.6068, RMSE: 1.2676, R^2: -0.7955, MAE: 0.9435\n",
      "Optimizer: rmsprop, Activation Function: relu, Learning Rate: 0.1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "  MSE: 3.5143, RMSE: 1.8746, R^2: -2.9271, MAE: 1.3368\n",
      "Optimizer: rmsprop, Activation Function: sigmoid, Learning Rate: 0.0001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "  MSE: 1.3990, RMSE: 1.1828, R^2: -0.5633, MAE: 0.8223\n",
      "Optimizer: rmsprop, Activation Function: sigmoid, Learning Rate: 0.001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "  MSE: 1.3057, RMSE: 1.1427, R^2: -0.4591, MAE: 0.8515\n",
      "Optimizer: rmsprop, Activation Function: sigmoid, Learning Rate: 0.01\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "  MSE: 1.3460, RMSE: 1.1602, R^2: -0.5042, MAE: 0.8122\n",
      "Optimizer: rmsprop, Activation Function: sigmoid, Learning Rate: 0.1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "  MSE: 1.3759, RMSE: 1.1730, R^2: -0.5376, MAE: 0.7966\n",
      "Optimizer: rmsprop, Activation Function: tanh, Learning Rate: 0.0001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "  MSE: 1.0753, RMSE: 1.0370, R^2: -0.2016, MAE: 0.7855\n",
      "Optimizer: rmsprop, Activation Function: tanh, Learning Rate: 0.001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "  MSE: 0.8013, RMSE: 0.8952, R^2: 0.1045, MAE: 0.6848\n",
      "Optimizer: rmsprop, Activation Function: tanh, Learning Rate: 0.01\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "  MSE: 0.7598, RMSE: 0.8717, R^2: 0.1509, MAE: 0.6441\n",
      "Optimizer: rmsprop, Activation Function: tanh, Learning Rate: 0.1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "  MSE: 1.0160, RMSE: 1.0080, R^2: -0.1353, MAE: 0.7787\n",
      "Optimizer: rmsprop, Activation Function: softmax, Learning Rate: 0.0001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "  MSE: 2.5466, RMSE: 1.5958, R^2: -1.8458, MAE: 1.2852\n",
      "Optimizer: rmsprop, Activation Function: softmax, Learning Rate: 0.001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "  MSE: 2.5466, RMSE: 1.5958, R^2: -1.8458, MAE: 1.2852\n",
      "Optimizer: rmsprop, Activation Function: softmax, Learning Rate: 0.01\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "  MSE: 2.5466, RMSE: 1.5958, R^2: -1.8458, MAE: 1.2852\n",
      "Optimizer: rmsprop, Activation Function: softmax, Learning Rate: 0.1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "  MSE: 2.5466, RMSE: 1.5958, R^2: -1.8458, MAE: 1.2852\n",
      "Optimizer: adagrad, Activation Function: relu, Learning Rate: 0.0001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "  MSE: 3.0143, RMSE: 1.7362, R^2: -2.3684, MAE: 1.2507\n",
      "Optimizer: adagrad, Activation Function: relu, Learning Rate: 0.001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "  MSE: 1.2572, RMSE: 1.1213, R^2: -0.4049, MAE: 0.8560\n",
      "Optimizer: adagrad, Activation Function: relu, Learning Rate: 0.01\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "  MSE: 1.2515, RMSE: 1.1187, R^2: -0.3985, MAE: 0.9401\n",
      "Optimizer: adagrad, Activation Function: relu, Learning Rate: 0.1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "  MSE: 7.0205, RMSE: 2.6496, R^2: -6.8452, MAE: 1.6526\n",
      "Optimizer: adagrad, Activation Function: sigmoid, Learning Rate: 0.0001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "  MSE: 1.4065, RMSE: 1.1860, R^2: -0.5717, MAE: 0.7976\n",
      "Optimizer: adagrad, Activation Function: sigmoid, Learning Rate: 0.001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "  MSE: 1.1777, RMSE: 1.0852, R^2: -0.3160, MAE: 0.7837\n",
      "Optimizer: adagrad, Activation Function: sigmoid, Learning Rate: 0.01\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "  MSE: 1.5198, RMSE: 1.2328, R^2: -0.6984, MAE: 0.9058\n",
      "Optimizer: adagrad, Activation Function: sigmoid, Learning Rate: 0.1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "  MSE: 1.3821, RMSE: 1.1756, R^2: -0.5444, MAE: 0.8443\n",
      "Optimizer: adagrad, Activation Function: tanh, Learning Rate: 0.0001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "  MSE: 1.1622, RMSE: 1.0780, R^2: -0.2987, MAE: 0.8343\n",
      "Optimizer: adagrad, Activation Function: tanh, Learning Rate: 0.001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "  MSE: 1.5388, RMSE: 1.2405, R^2: -0.7196, MAE: 0.9540\n",
      "Optimizer: adagrad, Activation Function: tanh, Learning Rate: 0.01\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "  MSE: 1.3168, RMSE: 1.1475, R^2: -0.4715, MAE: 0.8818\n",
      "Optimizer: adagrad, Activation Function: tanh, Learning Rate: 0.1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "  MSE: 0.8066, RMSE: 0.8981, R^2: 0.0987, MAE: 0.7669\n",
      "Optimizer: adagrad, Activation Function: softmax, Learning Rate: 0.0001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "  MSE: 2.5466, RMSE: 1.5958, R^2: -1.8458, MAE: 1.2852\n",
      "Optimizer: adagrad, Activation Function: softmax, Learning Rate: 0.001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "  MSE: 2.5466, RMSE: 1.5958, R^2: -1.8458, MAE: 1.2852\n",
      "Optimizer: adagrad, Activation Function: softmax, Learning Rate: 0.01\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "  MSE: 2.5466, RMSE: 1.5958, R^2: -1.8458, MAE: 1.2852\n",
      "Optimizer: adagrad, Activation Function: softmax, Learning Rate: 0.1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "  MSE: 2.5466, RMSE: 1.5958, R^2: -1.8458, MAE: 1.2852\n"
     ]
    }
   ],
   "source": [
    "# Цикл перебирает различные комбинации оптимизаторов и функций активации, обучает модель для каждой комбинации, и оценивает ее точность с помощью 4-х метрик\n",
    "# Для каждой из 64 возможных комбинаций проводится 5-кратная кросс-валидация\n",
    "# Лист \"results\" содержит результаты кросс-валидации\n",
    "\n",
    "results = []\n",
    "\n",
    "############### 5-кратная кросс-валидация ############### \n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for train_index, test_index in kf.split(X_train_numeric_scaled):\n",
    "    X_train_cv, X_test_cv = X_train_numeric_scaled.iloc[train_index], X_train_numeric_scaled.iloc[test_index]\n",
    "    y_train_cv, y_test_cv = y_train_scaled[train_index], y_train_scaled[test_index]\n",
    "\n",
    "    for optimizer in optimizers:\n",
    "        for activation_function in activation_functions:\n",
    "            for learning_rate in learning_rates:\n",
    "                print(f\"Optimizer: {optimizer}, Activation Function: {activation_function}, Learning Rate: {learning_rate}\")\n",
    "                ############### Компилирую и обучаю SLP модель ############### \n",
    "                model = tf.keras.Sequential([tf.keras.layers.Dense(1, activation=activation_function)])\n",
    "                model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=['mae'])\n",
    "                history = model.fit(X_train_cv, y_train_cv, epochs=100, batch_size=32, validation_split=0.2, verbose=0)\n",
    "\n",
    "                ############### Оцениваю модель ############### \n",
    "                y_pred_scaled = model.predict(X_test_cv)\n",
    "                y_pred_inverse = scaler_y.inverse_transform(y_pred_scaled)\n",
    "                y_test_inverse = scaler_y.inverse_transform(y_test_cv)\n",
    "\n",
    "                mse = mean_squared_error(y_test_inverse, y_pred_inverse)\n",
    "                rmse = np.sqrt(mse)\n",
    "                r_squared = r2_score(y_test_inverse, y_pred_inverse)\n",
    "                mae = mean_absolute_error(y_test_inverse, y_pred_inverse)\n",
    "\n",
    "                print(f\"  MSE: {mse:.4f}, RMSE: {rmse:.4f}, R^2: {r_squared:.4f}, MAE: {mae:.4f}\")\n",
    "\n",
    "                results.append({\n",
    "                    'Optimizer': optimizer,\n",
    "                    'Activation Function': activation_function,\n",
    "                    'Learning Rate' : learning_rate,\n",
    "                    'MSE': mse,\n",
    "                    'RMSE': rmse,\n",
    "                    'R^2': r_squared,\n",
    "                    'MAE': mae\n",
    "                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m         Top 3 combinations for 'LUMO' descriptor:          \u001b[0m\n",
      "\n",
      "1. Optimizer: sgd, Activation Function: sigmoid, Learning Rate: 0.0001, MAE: 0.4175\n",
      "2. Optimizer: rmsprop, Activation Function: sigmoid, Learning Rate: 0.0001, MAE: 0.4209\n",
      "3. Optimizer: sgd, Activation Function: sigmoid, Learning Rate: 0.01, MAE: 0.4247\n"
     ]
    }
   ],
   "source": [
    "# ТОП-3 комбинаций из 64 возможных с лучшими MAE после 5-кратной кросс-валидации\n",
    "\n",
    "results_sorted = sorted(results, key=lambda x: x['MAE'])\n",
    "print(\"\\033[1m\" + \"Top 3 combinations for 'LUMO' descriptor:\".center(60) + \"\\033[0m\")\n",
    "print()\n",
    "for i, result in enumerate(results_sorted[:3], 1):\n",
    "   print(f\"{i}. Optimizer: {result['Optimizer']}, Activation Function: {result['Activation Function']}, Learning Rate: {result['Learning Rate']}, MAE: {result['MAE']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Повторно обучаю модель, но теперь на полном тренировочном датасете\n",
    "# Беру оптимальные значения гиперпараметров, найденные с помощью кросс-валидации\n",
    "\n",
    "best_combination = results_sorted[0]\n",
    "best_optimizer = best_combination['Optimizer']\n",
    "best_activation_function = best_combination['Activation Function']\n",
    "best_learning_rate = best_combination['Learning Rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 2.0190 - mae: 1.0500 - val_loss: 0.6823 - val_mae: 0.5652\n",
      "Epoch 2/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.8313 - mae: 0.9961 - val_loss: 0.6813 - val_mae: 0.5646\n",
      "Epoch 3/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.1094 - mae: 1.0848 - val_loss: 0.6804 - val_mae: 0.5640\n",
      "Epoch 4/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.8486 - mae: 0.9954 - val_loss: 0.6799 - val_mae: 0.5637\n",
      "Epoch 5/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.7426 - mae: 0.9496 - val_loss: 0.6795 - val_mae: 0.5634\n",
      "Epoch 6/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.8283 - mae: 0.9835 - val_loss: 0.6789 - val_mae: 0.5630\n",
      "Epoch 7/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.8225 - mae: 0.9813 - val_loss: 0.6784 - val_mae: 0.5627\n",
      "Epoch 8/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.6662 - mae: 0.9465 - val_loss: 0.6778 - val_mae: 0.5623\n",
      "Epoch 9/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.7961 - mae: 0.9686 - val_loss: 0.6773 - val_mae: 0.5620\n",
      "Epoch 10/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.9360 - mae: 1.0130 - val_loss: 0.6766 - val_mae: 0.5616\n",
      "Epoch 11/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.8285 - mae: 0.9721 - val_loss: 0.6761 - val_mae: 0.5612\n",
      "Epoch 12/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1.8851 - mae: 0.9884 - val_loss: 0.6755 - val_mae: 0.5609\n",
      "Epoch 13/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.7571 - mae: 0.9712 - val_loss: 0.6747 - val_mae: 0.5603\n",
      "Epoch 14/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.0733 - mae: 1.0642 - val_loss: 0.6740 - val_mae: 0.5599\n",
      "Epoch 15/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.7894 - mae: 0.9814 - val_loss: 0.6734 - val_mae: 0.5595\n",
      "Epoch 16/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.6957 - mae: 0.9364 - val_loss: 0.6727 - val_mae: 0.5591\n",
      "Epoch 17/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2.0446 - mae: 1.0533 - val_loss: 0.6718 - val_mae: 0.5585\n",
      "Epoch 18/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.8136 - mae: 1.0031 - val_loss: 0.6711 - val_mae: 0.5581\n",
      "Epoch 19/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.8879 - mae: 1.0008 - val_loss: 0.6704 - val_mae: 0.5576\n",
      "Epoch 20/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.9965 - mae: 1.0517 - val_loss: 0.6694 - val_mae: 0.5569\n",
      "Epoch 21/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.7042 - mae: 0.9193 - val_loss: 0.6688 - val_mae: 0.5566\n",
      "Epoch 22/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.7453 - mae: 0.9611 - val_loss: 0.6683 - val_mae: 0.5563\n",
      "Epoch 23/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.0008 - mae: 1.0517 - val_loss: 0.6674 - val_mae: 0.5557\n",
      "Epoch 24/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.8735 - mae: 1.0070 - val_loss: 0.6667 - val_mae: 0.5552\n",
      "Epoch 25/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.8960 - mae: 1.0183 - val_loss: 0.6662 - val_mae: 0.5549\n",
      "Epoch 26/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.7435 - mae: 0.9598 - val_loss: 0.6658 - val_mae: 0.5546\n",
      "Epoch 27/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.8341 - mae: 0.9886 - val_loss: 0.6652 - val_mae: 0.5542\n",
      "Epoch 28/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.7210 - mae: 0.9280 - val_loss: 0.6645 - val_mae: 0.5538\n",
      "Epoch 29/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.6580 - mae: 0.9248 - val_loss: 0.6637 - val_mae: 0.5532\n",
      "Epoch 30/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.9048 - mae: 1.0032 - val_loss: 0.6630 - val_mae: 0.5528\n",
      "Epoch 31/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.8943 - mae: 1.0093 - val_loss: 0.6625 - val_mae: 0.5524\n",
      "Epoch 32/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.9985 - mae: 1.0410 - val_loss: 0.6617 - val_mae: 0.5519\n",
      "Epoch 33/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.7140 - mae: 0.9414 - val_loss: 0.6610 - val_mae: 0.5514\n",
      "Epoch 34/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.9496 - mae: 1.0272 - val_loss: 0.6605 - val_mae: 0.5511\n",
      "Epoch 35/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.7039 - mae: 0.9272 - val_loss: 0.6598 - val_mae: 0.5507\n",
      "Epoch 36/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.7524 - mae: 0.9538 - val_loss: 0.6592 - val_mae: 0.5503\n",
      "Epoch 37/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.9689 - mae: 1.0346 - val_loss: 0.6585 - val_mae: 0.5498\n",
      "Epoch 38/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.8045 - mae: 0.9609 - val_loss: 0.6578 - val_mae: 0.5493\n",
      "Epoch 39/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.7355 - mae: 0.9533 - val_loss: 0.6573 - val_mae: 0.5490\n",
      "Epoch 40/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.7761 - mae: 0.9626 - val_loss: 0.6570 - val_mae: 0.5487\n",
      "Epoch 41/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.8330 - mae: 0.9814 - val_loss: 0.6563 - val_mae: 0.5483\n",
      "Epoch 42/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.7722 - mae: 0.9867 - val_loss: 0.6557 - val_mae: 0.5478\n",
      "Epoch 43/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.8364 - mae: 0.9780 - val_loss: 0.6550 - val_mae: 0.5474\n",
      "Epoch 44/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.6212 - mae: 0.9150 - val_loss: 0.6545 - val_mae: 0.5471\n",
      "Epoch 45/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.8010 - mae: 1.0016 - val_loss: 0.6536 - val_mae: 0.5464\n",
      "Epoch 46/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.9683 - mae: 1.0310 - val_loss: 0.6530 - val_mae: 0.5460\n",
      "Epoch 47/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.7707 - mae: 0.9647 - val_loss: 0.6525 - val_mae: 0.5457\n",
      "Epoch 48/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.7991 - mae: 0.9773 - val_loss: 0.6518 - val_mae: 0.5452\n",
      "Epoch 49/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.9553 - mae: 1.0615 - val_loss: 0.6511 - val_mae: 0.5447\n",
      "Epoch 50/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.8954 - mae: 1.0010 - val_loss: 0.6505 - val_mae: 0.5443\n",
      "Epoch 51/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.7248 - mae: 0.9291 - val_loss: 0.6496 - val_mae: 0.5437\n",
      "Epoch 52/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.7837 - mae: 0.9728 - val_loss: 0.6491 - val_mae: 0.5433\n",
      "Epoch 53/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.7118 - mae: 0.9407 - val_loss: 0.6486 - val_mae: 0.5430\n",
      "Epoch 54/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.6326 - mae: 0.8771 - val_loss: 0.6481 - val_mae: 0.5427\n",
      "Epoch 55/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.7247 - mae: 0.9418 - val_loss: 0.6476 - val_mae: 0.5423\n",
      "Epoch 56/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.9173 - mae: 1.0073 - val_loss: 0.6469 - val_mae: 0.5418\n",
      "Epoch 57/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.8233 - mae: 0.9886 - val_loss: 0.6466 - val_mae: 0.5416\n",
      "Epoch 58/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.7599 - mae: 0.9438 - val_loss: 0.6460 - val_mae: 0.5412\n",
      "Epoch 59/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.8433 - mae: 0.9863 - val_loss: 0.6453 - val_mae: 0.5407\n",
      "Epoch 60/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.8670 - mae: 0.9948 - val_loss: 0.6448 - val_mae: 0.5403\n",
      "Epoch 61/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.8650 - mae: 0.9984 - val_loss: 0.6444 - val_mae: 0.5400\n",
      "Epoch 62/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.8448 - mae: 0.9621 - val_loss: 0.6438 - val_mae: 0.5397\n",
      "Epoch 63/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.0349 - mae: 1.0690 - val_loss: 0.6432 - val_mae: 0.5392\n",
      "Epoch 64/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.9794 - mae: 1.0456 - val_loss: 0.6423 - val_mae: 0.5386\n",
      "Epoch 65/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.6392 - mae: 0.9205 - val_loss: 0.6416 - val_mae: 0.5381\n",
      "Epoch 66/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.6710 - mae: 0.9453 - val_loss: 0.6409 - val_mae: 0.5376\n",
      "Epoch 67/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.9430 - mae: 1.0141 - val_loss: 0.6403 - val_mae: 0.5372\n",
      "Epoch 68/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.7189 - mae: 0.9511 - val_loss: 0.6397 - val_mae: 0.5368\n",
      "Epoch 69/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.7676 - mae: 0.9634 - val_loss: 0.6391 - val_mae: 0.5364\n",
      "Epoch 70/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.7322 - mae: 0.9425 - val_loss: 0.6386 - val_mae: 0.5360\n",
      "Epoch 71/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.7163 - mae: 0.9418 - val_loss: 0.6382 - val_mae: 0.5357\n",
      "Epoch 72/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.8827 - mae: 1.0044 - val_loss: 0.6380 - val_mae: 0.5355\n",
      "Epoch 73/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.8100 - mae: 1.0031 - val_loss: 0.6375 - val_mae: 0.5352\n",
      "Epoch 74/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.8390 - mae: 0.9930 - val_loss: 0.6369 - val_mae: 0.5348\n",
      "Epoch 75/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.8962 - mae: 1.0389 - val_loss: 0.6364 - val_mae: 0.5344\n",
      "Epoch 76/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.8413 - mae: 1.0029 - val_loss: 0.6356 - val_mae: 0.5338\n",
      "Epoch 77/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.7653 - mae: 0.9716 - val_loss: 0.6353 - val_mae: 0.5336\n",
      "Epoch 78/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.9728 - mae: 1.0490 - val_loss: 0.6349 - val_mae: 0.5333\n",
      "Epoch 79/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.6538 - mae: 0.9264 - val_loss: 0.6344 - val_mae: 0.5329\n",
      "Epoch 80/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.6526 - mae: 0.9023 - val_loss: 0.6339 - val_mae: 0.5326\n",
      "Epoch 81/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.8264 - mae: 0.9923 - val_loss: 0.6334 - val_mae: 0.5322\n",
      "Epoch 82/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.7339 - mae: 0.9472 - val_loss: 0.6330 - val_mae: 0.5319\n",
      "Epoch 83/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.8189 - mae: 0.9717 - val_loss: 0.6325 - val_mae: 0.5315\n",
      "Epoch 84/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.9077 - mae: 1.0196 - val_loss: 0.6321 - val_mae: 0.5312\n",
      "Epoch 85/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.8919 - mae: 0.9995 - val_loss: 0.6316 - val_mae: 0.5309\n",
      "Epoch 86/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.7925 - mae: 1.0007 - val_loss: 0.6312 - val_mae: 0.5306\n",
      "Epoch 87/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.5927 - mae: 0.8855 - val_loss: 0.6310 - val_mae: 0.5304\n",
      "Epoch 88/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.8656 - mae: 0.9924 - val_loss: 0.6304 - val_mae: 0.5299\n",
      "Epoch 89/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.7379 - mae: 0.9645 - val_loss: 0.6299 - val_mae: 0.5296\n",
      "Epoch 90/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.7131 - mae: 0.9523 - val_loss: 0.6296 - val_mae: 0.5294\n",
      "Epoch 91/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.7695 - mae: 0.9424 - val_loss: 0.6291 - val_mae: 0.5290\n",
      "Epoch 92/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.9468 - mae: 1.0142 - val_loss: 0.6286 - val_mae: 0.5286\n",
      "Epoch 93/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.8874 - mae: 1.0196 - val_loss: 0.6279 - val_mae: 0.5281\n",
      "Epoch 94/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.8014 - mae: 0.9739 - val_loss: 0.6272 - val_mae: 0.5276\n",
      "Epoch 95/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.9038 - mae: 1.0102 - val_loss: 0.6270 - val_mae: 0.5274\n",
      "Epoch 96/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.0356 - mae: 1.0515 - val_loss: 0.6267 - val_mae: 0.5272\n",
      "Epoch 97/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.7730 - mae: 0.9565 - val_loss: 0.6261 - val_mae: 0.5267\n",
      "Epoch 98/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.8582 - mae: 0.9899 - val_loss: 0.6256 - val_mae: 0.5264\n",
      "Epoch 99/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.8165 - mae: 0.9876 - val_loss: 0.6250 - val_mae: 0.5259\n",
      "Epoch 100/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.7392 - mae: 0.9475 - val_loss: 0.6244 - val_mae: 0.5255\n",
      "Epoch 101/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.6577 - mae: 0.9260 - val_loss: 0.6237 - val_mae: 0.5250\n",
      "Epoch 102/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.8345 - mae: 0.9996 - val_loss: 0.6230 - val_mae: 0.5245\n",
      "Epoch 103/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.6342 - mae: 0.9445 - val_loss: 0.6226 - val_mae: 0.5242\n",
      "Epoch 104/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.6793 - mae: 0.9313 - val_loss: 0.6220 - val_mae: 0.5239\n",
      "Epoch 105/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.6742 - mae: 0.9302 - val_loss: 0.6215 - val_mae: 0.5235\n",
      "Epoch 106/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.7552 - mae: 0.9535 - val_loss: 0.6210 - val_mae: 0.5231\n",
      "Epoch 107/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.6574 - mae: 0.9371 - val_loss: 0.6203 - val_mae: 0.5227\n",
      "Epoch 108/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.7824 - mae: 0.9597 - val_loss: 0.6197 - val_mae: 0.5223\n",
      "Epoch 109/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.8431 - mae: 0.9857 - val_loss: 0.6195 - val_mae: 0.5221\n",
      "Epoch 110/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.7363 - mae: 0.9495 - val_loss: 0.6190 - val_mae: 0.5218\n",
      "Epoch 111/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.8146 - mae: 0.9912 - val_loss: 0.6184 - val_mae: 0.5214\n",
      "Epoch 112/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.5957 - mae: 0.9133 - val_loss: 0.6179 - val_mae: 0.5210\n",
      "Epoch 113/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.8086 - mae: 0.9769 - val_loss: 0.6173 - val_mae: 0.5207\n",
      "Epoch 114/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.8192 - mae: 0.9963 - val_loss: 0.6169 - val_mae: 0.5203\n",
      "Epoch 115/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.8246 - mae: 1.0161 - val_loss: 0.6165 - val_mae: 0.5201\n",
      "Epoch 116/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.6576 - mae: 0.9345 - val_loss: 0.6163 - val_mae: 0.5199\n",
      "Epoch 117/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.8961 - mae: 1.0180 - val_loss: 0.6158 - val_mae: 0.5195\n",
      "Epoch 118/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.7328 - mae: 0.9789 - val_loss: 0.6153 - val_mae: 0.5192\n",
      "Epoch 119/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.6614 - mae: 0.9249 - val_loss: 0.6147 - val_mae: 0.5188\n",
      "Epoch 120/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.7714 - mae: 0.9744 - val_loss: 0.6142 - val_mae: 0.5184\n",
      "Epoch 121/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.8225 - mae: 0.9758 - val_loss: 0.6134 - val_mae: 0.5179\n",
      "Epoch 122/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.7780 - mae: 0.9804 - val_loss: 0.6128 - val_mae: 0.5175\n",
      "Epoch 123/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.7988 - mae: 0.9804 - val_loss: 0.6124 - val_mae: 0.5172\n",
      "Epoch 124/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.9632 - mae: 1.0587 - val_loss: 0.6119 - val_mae: 0.5168\n",
      "Epoch 125/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.8383 - mae: 1.0203 - val_loss: 0.6113 - val_mae: 0.5164\n",
      "Epoch 126/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.8295 - mae: 0.9731 - val_loss: 0.6110 - val_mae: 0.5162\n",
      "Epoch 127/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.7668 - mae: 0.9722 - val_loss: 0.6103 - val_mae: 0.5157\n",
      "Epoch 128/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.8231 - mae: 0.9885 - val_loss: 0.6099 - val_mae: 0.5154\n",
      "Epoch 129/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.7176 - mae: 0.9629 - val_loss: 0.6093 - val_mae: 0.5150\n",
      "Epoch 130/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.8935 - mae: 1.0133 - val_loss: 0.6091 - val_mae: 0.5148\n",
      "Epoch 131/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.7876 - mae: 0.9789 - val_loss: 0.6086 - val_mae: 0.5145\n",
      "Epoch 132/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.6575 - mae: 0.9446 - val_loss: 0.6078 - val_mae: 0.5140\n",
      "Epoch 133/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.7682 - mae: 0.9643 - val_loss: 0.6073 - val_mae: 0.5136\n",
      "Epoch 134/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.8195 - mae: 1.0071 - val_loss: 0.6067 - val_mae: 0.5131\n",
      "Epoch 135/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.6308 - mae: 0.9176 - val_loss: 0.6062 - val_mae: 0.5128\n",
      "Epoch 136/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.7973 - mae: 0.9771 - val_loss: 0.6059 - val_mae: 0.5126\n",
      "Epoch 137/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.6885 - mae: 0.9174 - val_loss: 0.6054 - val_mae: 0.5122\n",
      "Epoch 138/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.6379 - mae: 0.9003 - val_loss: 0.6051 - val_mae: 0.5120\n",
      "Epoch 139/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.7731 - mae: 0.9914 - val_loss: 0.6047 - val_mae: 0.5117\n",
      "Epoch 140/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.7209 - mae: 0.9718 - val_loss: 0.6047 - val_mae: 0.5116\n",
      "Epoch 141/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.6093 - mae: 0.9341 - val_loss: 0.6041 - val_mae: 0.5112\n",
      "Epoch 142/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.8441 - mae: 0.9829 - val_loss: 0.6037 - val_mae: 0.5109\n",
      "Epoch 143/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.7689 - mae: 0.9616 - val_loss: 0.6035 - val_mae: 0.5108\n",
      "Epoch 144/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.7740 - mae: 0.9692 - val_loss: 0.6032 - val_mae: 0.5105\n",
      "Epoch 145/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.7568 - mae: 0.9732 - val_loss: 0.6030 - val_mae: 0.5104\n",
      "Epoch 146/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.8469 - mae: 1.0143 - val_loss: 0.6026 - val_mae: 0.5100\n",
      "Epoch 147/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.8121 - mae: 0.9836 - val_loss: 0.6019 - val_mae: 0.5095\n",
      "Epoch 148/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.8374 - mae: 0.9995 - val_loss: 0.6012 - val_mae: 0.5091\n",
      "Epoch 149/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.6777 - mae: 0.9352 - val_loss: 0.6007 - val_mae: 0.5087\n",
      "Epoch 150/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.5381 - mae: 0.8925 - val_loss: 0.6005 - val_mae: 0.5085\n",
      "Epoch 151/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.5714 - mae: 0.8917 - val_loss: 0.6003 - val_mae: 0.5084\n",
      "Epoch 152/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.7082 - mae: 0.9584 - val_loss: 0.5998 - val_mae: 0.5080\n",
      "Epoch 153/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.7168 - mae: 0.9677 - val_loss: 0.5995 - val_mae: 0.5077\n",
      "Epoch 154/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.8012 - mae: 0.9971 - val_loss: 0.5992 - val_mae: 0.5075\n",
      "Epoch 155/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.7808 - mae: 0.9831 - val_loss: 0.5988 - val_mae: 0.5073\n",
      "Epoch 156/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.8297 - mae: 0.9901 - val_loss: 0.5984 - val_mae: 0.5070\n",
      "Epoch 157/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.6555 - mae: 0.9386 - val_loss: 0.5981 - val_mae: 0.5068\n",
      "Epoch 158/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.7703 - mae: 0.9811 - val_loss: 0.5973 - val_mae: 0.5063\n",
      "Epoch 159/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.6563 - mae: 0.9501 - val_loss: 0.5967 - val_mae: 0.5059\n",
      "Epoch 160/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.8067 - mae: 0.9877 - val_loss: 0.5962 - val_mae: 0.5057\n",
      "Epoch 161/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.7453 - mae: 0.9451 - val_loss: 0.5958 - val_mae: 0.5054\n",
      "Epoch 162/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.7451 - mae: 0.9834 - val_loss: 0.5949 - val_mae: 0.5048\n",
      "Epoch 163/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.6709 - mae: 0.9391 - val_loss: 0.5946 - val_mae: 0.5046\n",
      "Epoch 164/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.7175 - mae: 0.9703 - val_loss: 0.5940 - val_mae: 0.5042\n",
      "Epoch 165/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.8040 - mae: 0.9984 - val_loss: 0.5935 - val_mae: 0.5039\n",
      "Epoch 166/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.6421 - mae: 0.9207 - val_loss: 0.5931 - val_mae: 0.5036\n",
      "Epoch 167/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.8876 - mae: 0.9954 - val_loss: 0.5923 - val_mae: 0.5033\n",
      "Epoch 168/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.7484 - mae: 0.9433 - val_loss: 0.5919 - val_mae: 0.5030\n",
      "Epoch 169/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.6822 - mae: 0.9616 - val_loss: 0.5914 - val_mae: 0.5027\n",
      "Epoch 170/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.7476 - mae: 0.9623 - val_loss: 0.5910 - val_mae: 0.5025\n",
      "Epoch 171/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.8553 - mae: 1.0010 - val_loss: 0.5901 - val_mae: 0.5021\n",
      "Epoch 172/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.6626 - mae: 0.9563 - val_loss: 0.5898 - val_mae: 0.5019\n",
      "Epoch 173/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.7894 - mae: 0.9850 - val_loss: 0.5894 - val_mae: 0.5016\n",
      "Epoch 174/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.6557 - mae: 0.9231 - val_loss: 0.5889 - val_mae: 0.5014\n",
      "Epoch 175/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.6951 - mae: 0.9638 - val_loss: 0.5886 - val_mae: 0.5012\n",
      "Epoch 176/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.6044 - mae: 0.9082 - val_loss: 0.5882 - val_mae: 0.5009\n",
      "Epoch 177/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.7543 - mae: 0.9832 - val_loss: 0.5879 - val_mae: 0.5008\n",
      "Epoch 178/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.7177 - mae: 0.9541 - val_loss: 0.5876 - val_mae: 0.5006\n",
      "Epoch 179/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.7887 - mae: 1.0136 - val_loss: 0.5876 - val_mae: 0.5006\n",
      "Epoch 180/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.6481 - mae: 0.9119 - val_loss: 0.5873 - val_mae: 0.5005\n",
      "Epoch 181/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.7524 - mae: 0.9793 - val_loss: 0.5871 - val_mae: 0.5005\n",
      "Epoch 182/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.7143 - mae: 0.9659 - val_loss: 0.5867 - val_mae: 0.5002\n",
      "Epoch 183/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.6275 - mae: 0.9175 - val_loss: 0.5861 - val_mae: 0.5000\n",
      "Epoch 184/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.8358 - mae: 1.0035 - val_loss: 0.5856 - val_mae: 0.4997\n",
      "Epoch 185/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.7828 - mae: 1.0026 - val_loss: 0.5851 - val_mae: 0.4995\n",
      "Epoch 186/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.7644 - mae: 0.9880 - val_loss: 0.5846 - val_mae: 0.4993\n",
      "Epoch 187/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.7609 - mae: 0.9656 - val_loss: 0.5840 - val_mae: 0.4990\n",
      "Epoch 188/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.6994 - mae: 0.9437 - val_loss: 0.5833 - val_mae: 0.4986\n",
      "Epoch 189/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.6855 - mae: 0.9457 - val_loss: 0.5825 - val_mae: 0.4982\n",
      "Epoch 190/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.6402 - mae: 0.9494 - val_loss: 0.5822 - val_mae: 0.4981\n",
      "Epoch 191/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.5138 - mae: 0.8667 - val_loss: 0.5815 - val_mae: 0.4977\n",
      "Epoch 192/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.6304 - mae: 0.8932 - val_loss: 0.5810 - val_mae: 0.4975\n",
      "Epoch 193/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.8797 - mae: 1.0453 - val_loss: 0.5805 - val_mae: 0.4972\n",
      "Epoch 194/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.7008 - mae: 0.9524 - val_loss: 0.5804 - val_mae: 0.4972\n",
      "Epoch 195/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.6244 - mae: 0.9126 - val_loss: 0.5797 - val_mae: 0.4969\n",
      "Epoch 196/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.6198 - mae: 0.9278 - val_loss: 0.5793 - val_mae: 0.4967\n",
      "Epoch 197/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.6907 - mae: 0.9557 - val_loss: 0.5784 - val_mae: 0.4962\n",
      "Epoch 198/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.4937 - mae: 0.8903 - val_loss: 0.5776 - val_mae: 0.4958\n",
      "Epoch 199/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.5704 - mae: 0.9121 - val_loss: 0.5769 - val_mae: 0.4954\n",
      "Epoch 200/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.7085 - mae: 0.9277 - val_loss: 0.5764 - val_mae: 0.4952\n",
      "Epoch 201/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.7717 - mae: 0.9796 - val_loss: 0.5759 - val_mae: 0.4949\n",
      "Epoch 202/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.6854 - mae: 0.9459 - val_loss: 0.5752 - val_mae: 0.4946\n",
      "Epoch 203/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.4766 - mae: 0.8748 - val_loss: 0.5751 - val_mae: 0.4945\n",
      "Epoch 204/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.7466 - mae: 0.9703 - val_loss: 0.5744 - val_mae: 0.4941\n",
      "Epoch 205/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.4802 - mae: 0.8535 - val_loss: 0.5739 - val_mae: 0.4939\n",
      "Epoch 206/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.4712 - mae: 0.8792 - val_loss: 0.5731 - val_mae: 0.4935\n",
      "Epoch 207/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.9233 - mae: 1.0474 - val_loss: 0.5727 - val_mae: 0.4933\n",
      "Epoch 208/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.5853 - mae: 0.9045 - val_loss: 0.5722 - val_mae: 0.4931\n",
      "Epoch 209/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.6496 - mae: 0.9479 - val_loss: 0.5718 - val_mae: 0.4928\n",
      "Epoch 210/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.5206 - mae: 0.9091 - val_loss: 0.5707 - val_mae: 0.4923\n",
      "Epoch 211/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.5396 - mae: 0.8779 - val_loss: 0.5698 - val_mae: 0.4918\n",
      "Epoch 212/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.6201 - mae: 0.9264 - val_loss: 0.5695 - val_mae: 0.4917\n",
      "Epoch 213/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.6010 - mae: 0.9007 - val_loss: 0.5688 - val_mae: 0.4913\n",
      "Epoch 214/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.6244 - mae: 0.9543 - val_loss: 0.5682 - val_mae: 0.4910\n",
      "Epoch 215/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.6990 - mae: 0.9531 - val_loss: 0.5678 - val_mae: 0.4907\n",
      "Epoch 216/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.7974 - mae: 1.0073 - val_loss: 0.5676 - val_mae: 0.4907\n",
      "Epoch 217/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.6043 - mae: 0.9345 - val_loss: 0.5671 - val_mae: 0.4904\n",
      "Epoch 218/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.5176 - mae: 0.8884 - val_loss: 0.5667 - val_mae: 0.4903\n",
      "Epoch 219/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.6434 - mae: 0.9391 - val_loss: 0.5661 - val_mae: 0.4899\n",
      "Epoch 220/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.6154 - mae: 0.9034 - val_loss: 0.5658 - val_mae: 0.4898\n",
      "Epoch 221/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.6683 - mae: 0.9434 - val_loss: 0.5653 - val_mae: 0.4895\n",
      "Epoch 222/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.4698 - mae: 0.8839 - val_loss: 0.5648 - val_mae: 0.4892\n",
      "Epoch 223/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.7138 - mae: 0.9519 - val_loss: 0.5646 - val_mae: 0.4892\n",
      "Epoch 224/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.4928 - mae: 0.8889 - val_loss: 0.5645 - val_mae: 0.4891\n",
      "Epoch 225/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.6411 - mae: 0.9579 - val_loss: 0.5638 - val_mae: 0.4888\n",
      "Epoch 226/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.3494 - mae: 0.8168 - val_loss: 0.5633 - val_mae: 0.4885\n",
      "Epoch 227/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.6507 - mae: 0.9355 - val_loss: 0.5625 - val_mae: 0.4880\n",
      "Epoch 228/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.5123 - mae: 0.8804 - val_loss: 0.5622 - val_mae: 0.4879\n",
      "Epoch 229/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.6395 - mae: 0.9354 - val_loss: 0.5616 - val_mae: 0.4876\n",
      "Epoch 230/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.5991 - mae: 0.9118 - val_loss: 0.5610 - val_mae: 0.4873\n",
      "Epoch 231/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.6363 - mae: 0.9033 - val_loss: 0.5604 - val_mae: 0.4870\n",
      "Epoch 232/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.6946 - mae: 0.9749 - val_loss: 0.5601 - val_mae: 0.4868\n",
      "Epoch 233/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.7261 - mae: 0.9684 - val_loss: 0.5592 - val_mae: 0.4863\n",
      "Epoch 234/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.5711 - mae: 0.9079 - val_loss: 0.5588 - val_mae: 0.4861\n",
      "Epoch 235/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.5959 - mae: 0.9242 - val_loss: 0.5581 - val_mae: 0.4857\n",
      "Epoch 236/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.5402 - mae: 0.8838 - val_loss: 0.5579 - val_mae: 0.4856\n",
      "Epoch 237/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.5692 - mae: 0.9091 - val_loss: 0.5571 - val_mae: 0.4852\n",
      "Epoch 238/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.6735 - mae: 0.9465 - val_loss: 0.5565 - val_mae: 0.4848\n",
      "Epoch 239/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.6227 - mae: 0.9424 - val_loss: 0.5562 - val_mae: 0.4847\n",
      "Epoch 240/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.6100 - mae: 0.9238 - val_loss: 0.5556 - val_mae: 0.4843\n",
      "Epoch 241/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.6942 - mae: 0.9583 - val_loss: 0.5551 - val_mae: 0.4841\n",
      "Epoch 242/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.5148 - mae: 0.8795 - val_loss: 0.5546 - val_mae: 0.4838\n",
      "Epoch 243/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.6811 - mae: 0.9511 - val_loss: 0.5538 - val_mae: 0.4834\n",
      "Epoch 244/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.6464 - mae: 0.9578 - val_loss: 0.5533 - val_mae: 0.4831\n",
      "Epoch 245/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.5385 - mae: 0.9263 - val_loss: 0.5528 - val_mae: 0.4829\n",
      "Epoch 246/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.6409 - mae: 0.9347 - val_loss: 0.5522 - val_mae: 0.4825\n",
      "Epoch 247/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.5205 - mae: 0.8895 - val_loss: 0.5516 - val_mae: 0.4822\n",
      "Epoch 248/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.7394 - mae: 0.9697 - val_loss: 0.5512 - val_mae: 0.4820\n",
      "Epoch 249/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.6604 - mae: 0.9657 - val_loss: 0.5507 - val_mae: 0.4817\n",
      "Epoch 250/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.6723 - mae: 0.9586 - val_loss: 0.5501 - val_mae: 0.4813\n",
      "Epoch 251/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.6873 - mae: 0.9701 - val_loss: 0.5496 - val_mae: 0.4811\n",
      "Epoch 252/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.5884 - mae: 0.9300 - val_loss: 0.5490 - val_mae: 0.4807\n",
      "Epoch 253/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.5758 - mae: 0.9388 - val_loss: 0.5483 - val_mae: 0.4803\n",
      "Epoch 254/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.4766 - mae: 0.8536 - val_loss: 0.5480 - val_mae: 0.4802\n",
      "Epoch 255/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.5103 - mae: 0.8826 - val_loss: 0.5473 - val_mae: 0.4798\n",
      "Epoch 256/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.5218 - mae: 0.9117 - val_loss: 0.5469 - val_mae: 0.4795\n",
      "Epoch 257/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.5742 - mae: 0.9196 - val_loss: 0.5462 - val_mae: 0.4792\n",
      "Epoch 258/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.4084 - mae: 0.8427 - val_loss: 0.5455 - val_mae: 0.4787\n",
      "Epoch 259/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.6755 - mae: 0.9472 - val_loss: 0.5449 - val_mae: 0.4784\n",
      "Epoch 260/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.4421 - mae: 0.8533 - val_loss: 0.5442 - val_mae: 0.4780\n",
      "Epoch 261/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.5928 - mae: 0.9354 - val_loss: 0.5439 - val_mae: 0.4778\n",
      "Epoch 262/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.5052 - mae: 0.8872 - val_loss: 0.5431 - val_mae: 0.4773\n",
      "Epoch 263/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.6687 - mae: 0.9687 - val_loss: 0.5425 - val_mae: 0.4770\n",
      "Epoch 264/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.5627 - mae: 0.8973 - val_loss: 0.5421 - val_mae: 0.4767\n",
      "Epoch 265/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.7221 - mae: 1.0077 - val_loss: 0.5417 - val_mae: 0.4765\n",
      "Epoch 266/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.5487 - mae: 0.9140 - val_loss: 0.5414 - val_mae: 0.4763\n",
      "Epoch 267/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.6459 - mae: 0.9650 - val_loss: 0.5409 - val_mae: 0.4761\n",
      "Epoch 268/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.5910 - mae: 0.9233 - val_loss: 0.5405 - val_mae: 0.4759\n",
      "Epoch 269/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.6538 - mae: 0.9428 - val_loss: 0.5399 - val_mae: 0.4755\n",
      "Epoch 270/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.4872 - mae: 0.9038 - val_loss: 0.5394 - val_mae: 0.4752\n",
      "Epoch 271/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.5670 - mae: 0.9185 - val_loss: 0.5386 - val_mae: 0.4748\n",
      "Epoch 272/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.5708 - mae: 0.8979 - val_loss: 0.5383 - val_mae: 0.4747\n",
      "Epoch 273/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.5192 - mae: 0.9158 - val_loss: 0.5379 - val_mae: 0.4744\n",
      "Epoch 274/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.4987 - mae: 0.9003 - val_loss: 0.5374 - val_mae: 0.4742\n",
      "Epoch 275/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.6954 - mae: 0.9604 - val_loss: 0.5369 - val_mae: 0.4740\n",
      "Epoch 276/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.4556 - mae: 0.8765 - val_loss: 0.5364 - val_mae: 0.4737\n",
      "Epoch 277/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.4360 - mae: 0.8926 - val_loss: 0.5358 - val_mae: 0.4734\n",
      "Epoch 278/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.6113 - mae: 0.9447 - val_loss: 0.5351 - val_mae: 0.4730\n",
      "Epoch 279/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.7137 - mae: 0.9575 - val_loss: 0.5344 - val_mae: 0.4727\n",
      "Epoch 280/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4806 - mae: 0.8808 - val_loss: 0.5338 - val_mae: 0.4724\n",
      "Epoch 281/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.5169 - mae: 0.8989 - val_loss: 0.5331 - val_mae: 0.4720\n",
      "Epoch 282/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.6356 - mae: 0.9478 - val_loss: 0.5327 - val_mae: 0.4718\n",
      "Epoch 283/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.4253 - mae: 0.8722 - val_loss: 0.5323 - val_mae: 0.4716\n",
      "Epoch 284/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.3750 - mae: 0.8254 - val_loss: 0.5317 - val_mae: 0.4714\n",
      "Epoch 285/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4326 - mae: 0.8789 - val_loss: 0.5311 - val_mae: 0.4712\n",
      "Epoch 286/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.5838 - mae: 0.9337 - val_loss: 0.5307 - val_mae: 0.4711\n",
      "Epoch 287/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.5256 - mae: 0.9098 - val_loss: 0.5303 - val_mae: 0.4710\n",
      "Epoch 288/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4996 - mae: 0.8782 - val_loss: 0.5297 - val_mae: 0.4707\n",
      "Epoch 289/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.5349 - mae: 0.8940 - val_loss: 0.5293 - val_mae: 0.4706\n",
      "Epoch 290/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.5462 - mae: 0.9097 - val_loss: 0.5287 - val_mae: 0.4704\n",
      "Epoch 291/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.5693 - mae: 0.9181 - val_loss: 0.5283 - val_mae: 0.4703\n",
      "Epoch 292/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.4403 - mae: 0.8539 - val_loss: 0.5277 - val_mae: 0.4701\n",
      "Epoch 293/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.6384 - mae: 0.9522 - val_loss: 0.5273 - val_mae: 0.4699\n",
      "Epoch 294/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.4619 - mae: 0.8889 - val_loss: 0.5265 - val_mae: 0.4697\n",
      "Epoch 295/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.4749 - mae: 0.8791 - val_loss: 0.5260 - val_mae: 0.4695\n",
      "Epoch 296/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.5115 - mae: 0.8987 - val_loss: 0.5255 - val_mae: 0.4693\n",
      "Epoch 297/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.5955 - mae: 0.9432 - val_loss: 0.5248 - val_mae: 0.4691\n",
      "Epoch 298/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.6603 - mae: 0.9596 - val_loss: 0.5243 - val_mae: 0.4689\n",
      "Epoch 299/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.4294 - mae: 0.8737 - val_loss: 0.5237 - val_mae: 0.4687\n",
      "Epoch 300/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.5133 - mae: 0.9080 - val_loss: 0.5231 - val_mae: 0.4684\n",
      "Epoch 301/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.4143 - mae: 0.8690 - val_loss: 0.5227 - val_mae: 0.4683\n",
      "Epoch 302/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.6099 - mae: 0.9544 - val_loss: 0.5219 - val_mae: 0.4680\n",
      "Epoch 303/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.5400 - mae: 0.9068 - val_loss: 0.5217 - val_mae: 0.4679\n",
      "Epoch 304/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.4778 - mae: 0.9103 - val_loss: 0.5209 - val_mae: 0.4676\n",
      "Epoch 305/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.3156 - mae: 0.8306 - val_loss: 0.5202 - val_mae: 0.4674\n",
      "Epoch 306/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.4769 - mae: 0.8908 - val_loss: 0.5197 - val_mae: 0.4672\n",
      "Epoch 307/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.6095 - mae: 0.9243 - val_loss: 0.5193 - val_mae: 0.4671\n",
      "Epoch 308/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.5138 - mae: 0.9079 - val_loss: 0.5187 - val_mae: 0.4668\n",
      "Epoch 309/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.6336 - mae: 0.9386 - val_loss: 0.5183 - val_mae: 0.4667\n",
      "Epoch 310/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.4374 - mae: 0.8829 - val_loss: 0.5178 - val_mae: 0.4666\n",
      "Epoch 311/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.4730 - mae: 0.8922 - val_loss: 0.5173 - val_mae: 0.4664\n",
      "Epoch 312/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.4225 - mae: 0.8606 - val_loss: 0.5170 - val_mae: 0.4663\n",
      "Epoch 313/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.5316 - mae: 0.9165 - val_loss: 0.5165 - val_mae: 0.4661\n",
      "Epoch 314/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.4973 - mae: 0.8758 - val_loss: 0.5159 - val_mae: 0.4659\n",
      "Epoch 315/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.4087 - mae: 0.8911 - val_loss: 0.5153 - val_mae: 0.4657\n",
      "Epoch 316/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.3976 - mae: 0.8671 - val_loss: 0.5146 - val_mae: 0.4654\n",
      "Epoch 317/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.4595 - mae: 0.8674 - val_loss: 0.5139 - val_mae: 0.4651\n",
      "Epoch 318/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.6312 - mae: 0.9474 - val_loss: 0.5135 - val_mae: 0.4650\n",
      "Epoch 319/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.3834 - mae: 0.8586 - val_loss: 0.5130 - val_mae: 0.4648\n",
      "Epoch 320/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.5333 - mae: 0.9236 - val_loss: 0.5123 - val_mae: 0.4645\n",
      "Epoch 321/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.5090 - mae: 0.8921 - val_loss: 0.5117 - val_mae: 0.4643\n",
      "Epoch 322/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.4313 - mae: 0.8658 - val_loss: 0.5112 - val_mae: 0.4641\n",
      "Epoch 323/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.5459 - mae: 0.9167 - val_loss: 0.5103 - val_mae: 0.4637\n",
      "Epoch 324/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.4461 - mae: 0.8794 - val_loss: 0.5099 - val_mae: 0.4636\n",
      "Epoch 325/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.6559 - mae: 0.9551 - val_loss: 0.5093 - val_mae: 0.4633\n",
      "Epoch 326/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.5911 - mae: 0.9221 - val_loss: 0.5089 - val_mae: 0.4632\n",
      "Epoch 327/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.5388 - mae: 0.9204 - val_loss: 0.5084 - val_mae: 0.4630\n",
      "Epoch 328/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.3804 - mae: 0.8556 - val_loss: 0.5080 - val_mae: 0.4629\n",
      "Epoch 329/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.4412 - mae: 0.8856 - val_loss: 0.5074 - val_mae: 0.4626\n",
      "Epoch 330/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.5452 - mae: 0.9031 - val_loss: 0.5067 - val_mae: 0.4623\n",
      "Epoch 331/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.5403 - mae: 0.9240 - val_loss: 0.5062 - val_mae: 0.4622\n",
      "Epoch 332/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.3932 - mae: 0.8757 - val_loss: 0.5057 - val_mae: 0.4620\n",
      "Epoch 333/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.5835 - mae: 0.9337 - val_loss: 0.5052 - val_mae: 0.4618\n",
      "Epoch 334/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.5069 - mae: 0.9086 - val_loss: 0.5047 - val_mae: 0.4616\n",
      "Epoch 335/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.4152 - mae: 0.8759 - val_loss: 0.5043 - val_mae: 0.4614\n",
      "Epoch 336/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.3543 - mae: 0.8403 - val_loss: 0.5039 - val_mae: 0.4613\n",
      "Epoch 337/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.4629 - mae: 0.8906 - val_loss: 0.5031 - val_mae: 0.4610\n",
      "Epoch 338/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.3691 - mae: 0.8608 - val_loss: 0.5026 - val_mae: 0.4609\n",
      "Epoch 339/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.4400 - mae: 0.8756 - val_loss: 0.5022 - val_mae: 0.4608\n",
      "Epoch 340/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.5919 - mae: 0.9366 - val_loss: 0.5019 - val_mae: 0.4607\n",
      "Epoch 341/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.5124 - mae: 0.9015 - val_loss: 0.5014 - val_mae: 0.4606\n",
      "Epoch 342/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.3741 - mae: 0.8609 - val_loss: 0.5009 - val_mae: 0.4604\n",
      "Epoch 343/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.3826 - mae: 0.8631 - val_loss: 0.5005 - val_mae: 0.4603\n",
      "Epoch 344/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.3694 - mae: 0.8594 - val_loss: 0.5002 - val_mae: 0.4603\n",
      "Epoch 345/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.5966 - mae: 0.9130 - val_loss: 0.4998 - val_mae: 0.4602\n",
      "Epoch 346/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.5062 - mae: 0.9181 - val_loss: 0.4992 - val_mae: 0.4600\n",
      "Epoch 347/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.5499 - mae: 0.9362 - val_loss: 0.4986 - val_mae: 0.4597\n",
      "Epoch 348/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.4909 - mae: 0.9117 - val_loss: 0.4983 - val_mae: 0.4597\n",
      "Epoch 349/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.3352 - mae: 0.8507 - val_loss: 0.4979 - val_mae: 0.4596\n",
      "Epoch 350/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.3740 - mae: 0.8519 - val_loss: 0.4973 - val_mae: 0.4594\n",
      "Epoch 351/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.3767 - mae: 0.8592 - val_loss: 0.4968 - val_mae: 0.4592\n",
      "Epoch 352/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.3500 - mae: 0.8461 - val_loss: 0.4965 - val_mae: 0.4591\n",
      "Epoch 353/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2941 - mae: 0.8375 - val_loss: 0.4961 - val_mae: 0.4590\n",
      "Epoch 354/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.4235 - mae: 0.8749 - val_loss: 0.4956 - val_mae: 0.4588\n",
      "Epoch 355/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.4470 - mae: 0.8839 - val_loss: 0.4952 - val_mae: 0.4587\n",
      "Epoch 356/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.5328 - mae: 0.9445 - val_loss: 0.4950 - val_mae: 0.4586\n",
      "Epoch 357/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.4253 - mae: 0.8909 - val_loss: 0.4945 - val_mae: 0.4585\n",
      "Epoch 358/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.3623 - mae: 0.8449 - val_loss: 0.4939 - val_mae: 0.4583\n",
      "Epoch 359/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2248 - mae: 0.7905 - val_loss: 0.4934 - val_mae: 0.4581\n",
      "Epoch 360/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.2461 - mae: 0.7884 - val_loss: 0.4928 - val_mae: 0.4579\n",
      "Epoch 361/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.5819 - mae: 0.9380 - val_loss: 0.4925 - val_mae: 0.4579\n",
      "Epoch 362/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.5472 - mae: 0.9270 - val_loss: 0.4920 - val_mae: 0.4577\n",
      "Epoch 363/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2981 - mae: 0.8432 - val_loss: 0.4916 - val_mae: 0.4575\n",
      "Epoch 364/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 1.5268 - mae: 0.9213 - val_loss: 0.4911 - val_mae: 0.4574\n",
      "Epoch 365/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.4170 - mae: 0.8858 - val_loss: 0.4908 - val_mae: 0.4573\n",
      "Epoch 366/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.3945 - mae: 0.8783 - val_loss: 0.4904 - val_mae: 0.4571\n",
      "Epoch 367/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2924 - mae: 0.8370 - val_loss: 0.4900 - val_mae: 0.4570\n",
      "Epoch 368/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.3284 - mae: 0.8225 - val_loss: 0.4895 - val_mae: 0.4569\n",
      "Epoch 369/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.4001 - mae: 0.8822 - val_loss: 0.4892 - val_mae: 0.4568\n",
      "Epoch 370/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.4454 - mae: 0.8910 - val_loss: 0.4888 - val_mae: 0.4567\n",
      "Epoch 371/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.4042 - mae: 0.8668 - val_loss: 0.4885 - val_mae: 0.4566\n",
      "Epoch 372/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2880 - mae: 0.8244 - val_loss: 0.4882 - val_mae: 0.4565\n",
      "Epoch 373/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.4907 - mae: 0.8967 - val_loss: 0.4875 - val_mae: 0.4563\n",
      "Epoch 374/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.5659 - mae: 0.9417 - val_loss: 0.4871 - val_mae: 0.4561\n",
      "Epoch 375/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.3741 - mae: 0.8787 - val_loss: 0.4869 - val_mae: 0.4561\n",
      "Epoch 376/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.4403 - mae: 0.8800 - val_loss: 0.4865 - val_mae: 0.4560\n",
      "Epoch 377/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2917 - mae: 0.8407 - val_loss: 0.4860 - val_mae: 0.4558\n",
      "Epoch 378/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.3065 - mae: 0.8261 - val_loss: 0.4856 - val_mae: 0.4557\n",
      "Epoch 379/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.4398 - mae: 0.8922 - val_loss: 0.4851 - val_mae: 0.4554\n",
      "Epoch 380/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.4128 - mae: 0.8681 - val_loss: 0.4847 - val_mae: 0.4553\n",
      "Epoch 381/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.4211 - mae: 0.8784 - val_loss: 0.4846 - val_mae: 0.4553\n",
      "Epoch 382/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.5049 - mae: 0.9271 - val_loss: 0.4842 - val_mae: 0.4552\n",
      "Epoch 383/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.3244 - mae: 0.8516 - val_loss: 0.4838 - val_mae: 0.4550\n",
      "Epoch 384/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.3042 - mae: 0.8494 - val_loss: 0.4831 - val_mae: 0.4548\n",
      "Epoch 385/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.5183 - mae: 0.9384 - val_loss: 0.4825 - val_mae: 0.4545\n",
      "Epoch 386/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.3060 - mae: 0.8415 - val_loss: 0.4820 - val_mae: 0.4543\n",
      "Epoch 387/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.4306 - mae: 0.9009 - val_loss: 0.4816 - val_mae: 0.4542\n",
      "Epoch 388/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.3893 - mae: 0.8859 - val_loss: 0.4812 - val_mae: 0.4541\n",
      "Epoch 389/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2119 - mae: 0.7913 - val_loss: 0.4809 - val_mae: 0.4539\n",
      "Epoch 390/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.4366 - mae: 0.8902 - val_loss: 0.4804 - val_mae: 0.4538\n",
      "Epoch 391/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.4446 - mae: 0.8781 - val_loss: 0.4800 - val_mae: 0.4536\n",
      "Epoch 392/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.4405 - mae: 0.9027 - val_loss: 0.4796 - val_mae: 0.4535\n",
      "Epoch 393/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.3451 - mae: 0.8578 - val_loss: 0.4793 - val_mae: 0.4534\n",
      "Epoch 394/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.3811 - mae: 0.8969 - val_loss: 0.4788 - val_mae: 0.4532\n",
      "Epoch 395/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.4404 - mae: 0.9045 - val_loss: 0.4785 - val_mae: 0.4531\n",
      "Epoch 396/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.3597 - mae: 0.8520 - val_loss: 0.4782 - val_mae: 0.4530\n",
      "Epoch 397/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.4412 - mae: 0.8955 - val_loss: 0.4779 - val_mae: 0.4529\n",
      "Epoch 398/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.3847 - mae: 0.8645 - val_loss: 0.4777 - val_mae: 0.4528\n",
      "Epoch 399/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.3877 - mae: 0.8710 - val_loss: 0.4773 - val_mae: 0.4527\n",
      "Epoch 400/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.3479 - mae: 0.8569 - val_loss: 0.4770 - val_mae: 0.4525\n",
      "Epoch 401/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.3746 - mae: 0.8938 - val_loss: 0.4767 - val_mae: 0.4525\n",
      "Epoch 402/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1875 - mae: 0.8028 - val_loss: 0.4762 - val_mae: 0.4522\n",
      "Epoch 403/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.4060 - mae: 0.8942 - val_loss: 0.4756 - val_mae: 0.4520\n",
      "Epoch 404/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.4294 - mae: 0.8936 - val_loss: 0.4753 - val_mae: 0.4519\n",
      "Epoch 405/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.2694 - mae: 0.8340 - val_loss: 0.4749 - val_mae: 0.4517\n",
      "Epoch 406/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.3054 - mae: 0.8513 - val_loss: 0.4745 - val_mae: 0.4516\n",
      "Epoch 407/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2500 - mae: 0.7935 - val_loss: 0.4741 - val_mae: 0.4514\n",
      "Epoch 408/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.3405 - mae: 0.8544 - val_loss: 0.4738 - val_mae: 0.4513\n",
      "Epoch 409/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4091 - mae: 0.8774 - val_loss: 0.4735 - val_mae: 0.4512\n",
      "Epoch 410/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.3738 - mae: 0.8937 - val_loss: 0.4731 - val_mae: 0.4511\n",
      "Epoch 411/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2865 - mae: 0.8533 - val_loss: 0.4727 - val_mae: 0.4509\n",
      "Epoch 412/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.4279 - mae: 0.9053 - val_loss: 0.4723 - val_mae: 0.4508\n",
      "Epoch 413/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.3168 - mae: 0.8466 - val_loss: 0.4721 - val_mae: 0.4507\n",
      "Epoch 414/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2223 - mae: 0.8246 - val_loss: 0.4719 - val_mae: 0.4506\n",
      "Epoch 415/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.3628 - mae: 0.8733 - val_loss: 0.4714 - val_mae: 0.4504\n",
      "Epoch 416/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2959 - mae: 0.8608 - val_loss: 0.4712 - val_mae: 0.4503\n",
      "Epoch 417/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.4017 - mae: 0.8848 - val_loss: 0.4709 - val_mae: 0.4502\n",
      "Epoch 418/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2819 - mae: 0.8355 - val_loss: 0.4707 - val_mae: 0.4501\n",
      "Epoch 419/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.4655 - mae: 0.9155 - val_loss: 0.4704 - val_mae: 0.4501\n",
      "Epoch 420/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.1941 - mae: 0.8028 - val_loss: 0.4701 - val_mae: 0.4499\n",
      "Epoch 421/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.2612 - mae: 0.8059 - val_loss: 0.4697 - val_mae: 0.4498\n",
      "Epoch 422/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.3554 - mae: 0.8741 - val_loss: 0.4693 - val_mae: 0.4496\n",
      "Epoch 423/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2831 - mae: 0.8320 - val_loss: 0.4690 - val_mae: 0.4495\n",
      "Epoch 424/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2448 - mae: 0.8244 - val_loss: 0.4688 - val_mae: 0.4494\n",
      "Epoch 425/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.2632 - mae: 0.8331 - val_loss: 0.4683 - val_mae: 0.4492\n",
      "Epoch 426/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2925 - mae: 0.8466 - val_loss: 0.4683 - val_mae: 0.4492\n",
      "Epoch 427/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1747 - mae: 0.7966 - val_loss: 0.4681 - val_mae: 0.4492\n",
      "Epoch 428/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.3118 - mae: 0.8419 - val_loss: 0.4678 - val_mae: 0.4490\n",
      "Epoch 429/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.3933 - mae: 0.8974 - val_loss: 0.4676 - val_mae: 0.4489\n",
      "Epoch 430/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.3273 - mae: 0.8707 - val_loss: 0.4674 - val_mae: 0.4489\n",
      "Epoch 431/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2813 - mae: 0.8409 - val_loss: 0.4671 - val_mae: 0.4488\n",
      "Epoch 432/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2745 - mae: 0.8458 - val_loss: 0.4668 - val_mae: 0.4487\n",
      "Epoch 433/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.4155 - mae: 0.9087 - val_loss: 0.4664 - val_mae: 0.4485\n",
      "Epoch 434/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.2963 - mae: 0.8512 - val_loss: 0.4660 - val_mae: 0.4483\n",
      "Epoch 435/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2469 - mae: 0.8234 - val_loss: 0.4657 - val_mae: 0.4481\n",
      "Epoch 436/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2695 - mae: 0.8373 - val_loss: 0.4655 - val_mae: 0.4480\n",
      "Epoch 437/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.3089 - mae: 0.8348 - val_loss: 0.4653 - val_mae: 0.4480\n",
      "Epoch 438/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.3033 - mae: 0.8597 - val_loss: 0.4652 - val_mae: 0.4480\n",
      "Epoch 439/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.3089 - mae: 0.8804 - val_loss: 0.4649 - val_mae: 0.4478\n",
      "Epoch 440/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2543 - mae: 0.8221 - val_loss: 0.4646 - val_mae: 0.4477\n",
      "Epoch 441/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1331 - mae: 0.7896 - val_loss: 0.4644 - val_mae: 0.4476\n",
      "Epoch 442/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.4350 - mae: 0.9087 - val_loss: 0.4643 - val_mae: 0.4476\n",
      "Epoch 443/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2822 - mae: 0.8375 - val_loss: 0.4638 - val_mae: 0.4474\n",
      "Epoch 444/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.3215 - mae: 0.8453 - val_loss: 0.4636 - val_mae: 0.4473\n",
      "Epoch 445/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2808 - mae: 0.8518 - val_loss: 0.4634 - val_mae: 0.4472\n",
      "Epoch 446/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2450 - mae: 0.8366 - val_loss: 0.4633 - val_mae: 0.4472\n",
      "Epoch 447/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.3103 - mae: 0.8575 - val_loss: 0.4631 - val_mae: 0.4471\n",
      "Epoch 448/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2503 - mae: 0.8072 - val_loss: 0.4630 - val_mae: 0.4471\n",
      "Epoch 449/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.3392 - mae: 0.8724 - val_loss: 0.4628 - val_mae: 0.4470\n",
      "Epoch 450/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2090 - mae: 0.8113 - val_loss: 0.4626 - val_mae: 0.4469\n",
      "Epoch 451/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2648 - mae: 0.8520 - val_loss: 0.4624 - val_mae: 0.4469\n",
      "Epoch 452/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2701 - mae: 0.8419 - val_loss: 0.4622 - val_mae: 0.4467\n",
      "Epoch 453/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2824 - mae: 0.8450 - val_loss: 0.4620 - val_mae: 0.4467\n",
      "Epoch 454/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.3667 - mae: 0.8956 - val_loss: 0.4618 - val_mae: 0.4465\n",
      "Epoch 455/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1728 - mae: 0.7854 - val_loss: 0.4614 - val_mae: 0.4464\n",
      "Epoch 456/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1676 - mae: 0.8074 - val_loss: 0.4611 - val_mae: 0.4462\n",
      "Epoch 457/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1688 - mae: 0.8137 - val_loss: 0.4611 - val_mae: 0.4462\n",
      "Epoch 458/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.3031 - mae: 0.8415 - val_loss: 0.4607 - val_mae: 0.4461\n",
      "Epoch 459/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.3196 - mae: 0.8827 - val_loss: 0.4606 - val_mae: 0.4460\n",
      "Epoch 460/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2496 - mae: 0.8354 - val_loss: 0.4605 - val_mae: 0.4460\n",
      "Epoch 461/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.1927 - mae: 0.8018 - val_loss: 0.4602 - val_mae: 0.4459\n",
      "Epoch 462/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2574 - mae: 0.8463 - val_loss: 0.4600 - val_mae: 0.4458\n",
      "Epoch 463/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.2411 - mae: 0.8314 - val_loss: 0.4599 - val_mae: 0.4457\n",
      "Epoch 464/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2610 - mae: 0.8449 - val_loss: 0.4597 - val_mae: 0.4456\n",
      "Epoch 465/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.1725 - mae: 0.7996 - val_loss: 0.4595 - val_mae: 0.4455\n",
      "Epoch 466/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2547 - mae: 0.8525 - val_loss: 0.4592 - val_mae: 0.4454\n",
      "Epoch 467/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2347 - mae: 0.8105 - val_loss: 0.4590 - val_mae: 0.4453\n",
      "Epoch 468/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.3079 - mae: 0.8652 - val_loss: 0.4587 - val_mae: 0.4452\n",
      "Epoch 469/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2159 - mae: 0.8226 - val_loss: 0.4584 - val_mae: 0.4450\n",
      "Epoch 470/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.1916 - mae: 0.8058 - val_loss: 0.4581 - val_mae: 0.4449\n",
      "Epoch 471/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1236 - mae: 0.7686 - val_loss: 0.4579 - val_mae: 0.4448\n",
      "Epoch 472/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.3727 - mae: 0.8551 - val_loss: 0.4579 - val_mae: 0.4448\n",
      "Epoch 473/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.2496 - mae: 0.8320 - val_loss: 0.4577 - val_mae: 0.4447\n",
      "Epoch 474/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2879 - mae: 0.8522 - val_loss: 0.4575 - val_mae: 0.4446\n",
      "Epoch 475/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2045 - mae: 0.8311 - val_loss: 0.4573 - val_mae: 0.4445\n",
      "Epoch 476/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2590 - mae: 0.8460 - val_loss: 0.4571 - val_mae: 0.4444\n",
      "Epoch 477/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2764 - mae: 0.8533 - val_loss: 0.4568 - val_mae: 0.4443\n",
      "Epoch 478/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1980 - mae: 0.8164 - val_loss: 0.4567 - val_mae: 0.4442\n",
      "Epoch 479/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.1411 - mae: 0.7948 - val_loss: 0.4564 - val_mae: 0.4440\n",
      "Epoch 480/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0944 - mae: 0.7758 - val_loss: 0.4562 - val_mae: 0.4439\n",
      "Epoch 481/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.1920 - mae: 0.8097 - val_loss: 0.4557 - val_mae: 0.4437\n",
      "Epoch 482/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2829 - mae: 0.8497 - val_loss: 0.4556 - val_mae: 0.4437\n",
      "Epoch 483/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1463 - mae: 0.7744 - val_loss: 0.4554 - val_mae: 0.4436\n",
      "Epoch 484/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2751 - mae: 0.8262 - val_loss: 0.4550 - val_mae: 0.4434\n",
      "Epoch 485/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2404 - mae: 0.8159 - val_loss: 0.4548 - val_mae: 0.4433\n",
      "Epoch 486/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.2833 - mae: 0.8439 - val_loss: 0.4547 - val_mae: 0.4432\n",
      "Epoch 487/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.1745 - mae: 0.7934 - val_loss: 0.4544 - val_mae: 0.4431\n",
      "Epoch 488/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2350 - mae: 0.8105 - val_loss: 0.4544 - val_mae: 0.4431\n",
      "Epoch 489/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.3300 - mae: 0.8715 - val_loss: 0.4542 - val_mae: 0.4430\n",
      "Epoch 490/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2580 - mae: 0.8494 - val_loss: 0.4541 - val_mae: 0.4429\n",
      "Epoch 491/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.2704 - mae: 0.8321 - val_loss: 0.4538 - val_mae: 0.4428\n",
      "Epoch 492/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.3766 - mae: 0.8863 - val_loss: 0.4538 - val_mae: 0.4428\n",
      "Epoch 493/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.2023 - mae: 0.8301 - val_loss: 0.4535 - val_mae: 0.4426\n",
      "Epoch 494/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1390 - mae: 0.7891 - val_loss: 0.4534 - val_mae: 0.4426\n",
      "Epoch 495/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.2788 - mae: 0.8579 - val_loss: 0.4533 - val_mae: 0.4425\n",
      "Epoch 496/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.1653 - mae: 0.7778 - val_loss: 0.4530 - val_mae: 0.4424\n",
      "Epoch 497/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2041 - mae: 0.8151 - val_loss: 0.4529 - val_mae: 0.4423\n",
      "Epoch 498/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2113 - mae: 0.8078 - val_loss: 0.4528 - val_mae: 0.4423\n",
      "Epoch 499/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.2526 - mae: 0.8257 - val_loss: 0.4526 - val_mae: 0.4422\n",
      "Epoch 500/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.1501 - mae: 0.8039 - val_loss: 0.4524 - val_mae: 0.4421\n",
      "Epoch 501/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.3076 - mae: 0.8580 - val_loss: 0.4522 - val_mae: 0.4420\n",
      "Epoch 502/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2003 - mae: 0.8046 - val_loss: 0.4520 - val_mae: 0.4419\n",
      "Epoch 503/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.3119 - mae: 0.8599 - val_loss: 0.4518 - val_mae: 0.4418\n",
      "Epoch 504/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.1740 - mae: 0.8153 - val_loss: 0.4518 - val_mae: 0.4418\n",
      "Epoch 505/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2622 - mae: 0.8702 - val_loss: 0.4516 - val_mae: 0.4417\n",
      "Epoch 506/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 1.2583 - mae: 0.8396 - val_loss: 0.4514 - val_mae: 0.4416\n",
      "Epoch 507/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2494 - mae: 0.8356 - val_loss: 0.4513 - val_mae: 0.4416\n",
      "Epoch 508/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1930 - mae: 0.7972 - val_loss: 0.4511 - val_mae: 0.4414\n",
      "Epoch 509/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1746 - mae: 0.8027 - val_loss: 0.4507 - val_mae: 0.4412\n",
      "Epoch 510/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1900 - mae: 0.8020 - val_loss: 0.4506 - val_mae: 0.4412\n",
      "Epoch 511/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.2407 - mae: 0.8247 - val_loss: 0.4504 - val_mae: 0.4411\n",
      "Epoch 512/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.2266 - mae: 0.8300 - val_loss: 0.4503 - val_mae: 0.4411\n",
      "Epoch 513/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.2242 - mae: 0.8205 - val_loss: 0.4502 - val_mae: 0.4410\n",
      "Epoch 514/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1629 - mae: 0.8153 - val_loss: 0.4501 - val_mae: 0.4409\n",
      "Epoch 515/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2404 - mae: 0.8394 - val_loss: 0.4500 - val_mae: 0.4409\n",
      "Epoch 516/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2953 - mae: 0.8582 - val_loss: 0.4499 - val_mae: 0.4409\n",
      "Epoch 517/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.3637 - mae: 0.8889 - val_loss: 0.4498 - val_mae: 0.4408\n",
      "Epoch 518/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.2141 - mae: 0.8349 - val_loss: 0.4498 - val_mae: 0.4408\n",
      "Epoch 519/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.2027 - mae: 0.8280 - val_loss: 0.4497 - val_mae: 0.4408\n",
      "Epoch 520/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2375 - mae: 0.8296 - val_loss: 0.4495 - val_mae: 0.4407\n",
      "Epoch 521/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.3495 - mae: 0.8758 - val_loss: 0.4494 - val_mae: 0.4406\n",
      "Epoch 522/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1141 - mae: 0.7713 - val_loss: 0.4494 - val_mae: 0.4406\n",
      "Epoch 523/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.2087 - mae: 0.8208 - val_loss: 0.4492 - val_mae: 0.4405\n",
      "Epoch 524/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1826 - mae: 0.8112 - val_loss: 0.4490 - val_mae: 0.4404\n",
      "Epoch 525/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2520 - mae: 0.8305 - val_loss: 0.4488 - val_mae: 0.4403\n",
      "Epoch 526/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.2870 - mae: 0.8757 - val_loss: 0.4489 - val_mae: 0.4404\n",
      "Epoch 527/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2041 - mae: 0.8271 - val_loss: 0.4486 - val_mae: 0.4402\n",
      "Epoch 528/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.2469 - mae: 0.8132 - val_loss: 0.4486 - val_mae: 0.4402\n",
      "Epoch 529/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1721 - mae: 0.7959 - val_loss: 0.4485 - val_mae: 0.4402\n",
      "Epoch 530/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2980 - mae: 0.8486 - val_loss: 0.4485 - val_mae: 0.4402\n",
      "Epoch 531/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.2261 - mae: 0.8156 - val_loss: 0.4485 - val_mae: 0.4402\n",
      "Epoch 532/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.2693 - mae: 0.8262 - val_loss: 0.4484 - val_mae: 0.4402\n",
      "Epoch 533/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.1626 - mae: 0.8135 - val_loss: 0.4482 - val_mae: 0.4401\n",
      "Epoch 534/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2477 - mae: 0.8322 - val_loss: 0.4482 - val_mae: 0.4401\n",
      "Epoch 535/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1062 - mae: 0.7603 - val_loss: 0.4481 - val_mae: 0.4400\n",
      "Epoch 536/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.2745 - mae: 0.8429 - val_loss: 0.4481 - val_mae: 0.4400\n",
      "Epoch 537/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2951 - mae: 0.8277 - val_loss: 0.4481 - val_mae: 0.4401\n",
      "Epoch 538/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.3359 - mae: 0.8918 - val_loss: 0.4481 - val_mae: 0.4401\n",
      "Epoch 539/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2200 - mae: 0.8287 - val_loss: 0.4480 - val_mae: 0.4400\n",
      "Epoch 540/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.3018 - mae: 0.8615 - val_loss: 0.4478 - val_mae: 0.4399\n",
      "Epoch 541/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.3089 - mae: 0.8681 - val_loss: 0.4478 - val_mae: 0.4399\n",
      "Epoch 542/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2067 - mae: 0.8166 - val_loss: 0.4477 - val_mae: 0.4399\n",
      "Epoch 543/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.2131 - mae: 0.8325 - val_loss: 0.4476 - val_mae: 0.4398\n",
      "Epoch 544/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0921 - mae: 0.7480 - val_loss: 0.4475 - val_mae: 0.4398\n",
      "Epoch 545/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2428 - mae: 0.8183 - val_loss: 0.4474 - val_mae: 0.4397\n",
      "Epoch 546/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1442 - mae: 0.7657 - val_loss: 0.4472 - val_mae: 0.4396\n",
      "Epoch 547/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1871 - mae: 0.7896 - val_loss: 0.4472 - val_mae: 0.4396\n",
      "Epoch 548/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1644 - mae: 0.7969 - val_loss: 0.4471 - val_mae: 0.4396\n",
      "Epoch 549/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2367 - mae: 0.8312 - val_loss: 0.4470 - val_mae: 0.4395\n",
      "Epoch 550/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.3340 - mae: 0.8789 - val_loss: 0.4468 - val_mae: 0.4394\n",
      "Epoch 551/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.1874 - mae: 0.8178 - val_loss: 0.4467 - val_mae: 0.4394\n",
      "Epoch 552/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1057 - mae: 0.7908 - val_loss: 0.4466 - val_mae: 0.4393\n",
      "Epoch 553/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 1.2058 - mae: 0.8216 - val_loss: 0.4464 - val_mae: 0.4392\n",
      "Epoch 554/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2669 - mae: 0.8530 - val_loss: 0.4462 - val_mae: 0.4391\n",
      "Epoch 555/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2749 - mae: 0.8343 - val_loss: 0.4461 - val_mae: 0.4391\n",
      "Epoch 556/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1431 - mae: 0.7970 - val_loss: 0.4461 - val_mae: 0.4391\n",
      "Epoch 557/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2409 - mae: 0.8142 - val_loss: 0.4461 - val_mae: 0.4391\n",
      "Epoch 558/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2292 - mae: 0.8283 - val_loss: 0.4461 - val_mae: 0.4391\n",
      "Epoch 559/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1937 - mae: 0.8234 - val_loss: 0.4459 - val_mae: 0.4390\n",
      "Epoch 560/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.3293 - mae: 0.8641 - val_loss: 0.4455 - val_mae: 0.4388\n",
      "Epoch 561/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1725 - mae: 0.7921 - val_loss: 0.4453 - val_mae: 0.4386\n",
      "Epoch 562/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2218 - mae: 0.8104 - val_loss: 0.4453 - val_mae: 0.4386\n",
      "Epoch 563/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.3608 - mae: 0.8701 - val_loss: 0.4452 - val_mae: 0.4386\n",
      "Epoch 564/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1902 - mae: 0.8075 - val_loss: 0.4451 - val_mae: 0.4386\n",
      "Epoch 565/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.1075 - mae: 0.7675 - val_loss: 0.4447 - val_mae: 0.4383\n",
      "Epoch 566/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1608 - mae: 0.8222 - val_loss: 0.4446 - val_mae: 0.4382\n",
      "Epoch 567/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.2348 - mae: 0.8065 - val_loss: 0.4446 - val_mae: 0.4383\n",
      "Epoch 568/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2422 - mae: 0.8240 - val_loss: 0.4444 - val_mae: 0.4381\n",
      "Epoch 569/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.2501 - mae: 0.8234 - val_loss: 0.4443 - val_mae: 0.4381\n",
      "Epoch 570/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0890 - mae: 0.7568 - val_loss: 0.4442 - val_mae: 0.4381\n",
      "Epoch 571/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.2570 - mae: 0.8446 - val_loss: 0.4442 - val_mae: 0.4381\n",
      "Epoch 572/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.2327 - mae: 0.8423 - val_loss: 0.4442 - val_mae: 0.4381\n",
      "Epoch 573/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1905 - mae: 0.8391 - val_loss: 0.4442 - val_mae: 0.4381\n",
      "Epoch 574/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2003 - mae: 0.8389 - val_loss: 0.4442 - val_mae: 0.4381\n",
      "Epoch 575/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1727 - mae: 0.8189 - val_loss: 0.4441 - val_mae: 0.4380\n",
      "Epoch 576/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1262 - mae: 0.7679 - val_loss: 0.4440 - val_mae: 0.4380\n",
      "Epoch 577/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.1947 - mae: 0.8284 - val_loss: 0.4439 - val_mae: 0.4380\n",
      "Epoch 578/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.2480 - mae: 0.8365 - val_loss: 0.4439 - val_mae: 0.4380\n",
      "Epoch 579/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2456 - mae: 0.8448 - val_loss: 0.4437 - val_mae: 0.4378\n",
      "Epoch 580/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2720 - mae: 0.8391 - val_loss: 0.4436 - val_mae: 0.4378\n",
      "Epoch 581/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.3247 - mae: 0.8725 - val_loss: 0.4436 - val_mae: 0.4378\n",
      "Epoch 582/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1546 - mae: 0.7951 - val_loss: 0.4434 - val_mae: 0.4377\n",
      "Epoch 583/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1500 - mae: 0.7829 - val_loss: 0.4432 - val_mae: 0.4376\n",
      "Epoch 584/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1119 - mae: 0.7803 - val_loss: 0.4432 - val_mae: 0.4376\n",
      "Epoch 585/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2745 - mae: 0.8626 - val_loss: 0.4430 - val_mae: 0.4375\n",
      "Epoch 586/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.1468 - mae: 0.7767 - val_loss: 0.4430 - val_mae: 0.4375\n",
      "Epoch 587/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.1803 - mae: 0.8099 - val_loss: 0.4429 - val_mae: 0.4375\n",
      "Epoch 588/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1868 - mae: 0.7972 - val_loss: 0.4429 - val_mae: 0.4375\n",
      "Epoch 589/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2097 - mae: 0.8354 - val_loss: 0.4429 - val_mae: 0.4374\n",
      "Epoch 590/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2471 - mae: 0.8445 - val_loss: 0.4428 - val_mae: 0.4374\n",
      "Epoch 591/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2976 - mae: 0.8465 - val_loss: 0.4427 - val_mae: 0.4374\n",
      "Epoch 592/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2905 - mae: 0.8603 - val_loss: 0.4427 - val_mae: 0.4374\n",
      "Epoch 593/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2201 - mae: 0.8188 - val_loss: 0.4426 - val_mae: 0.4373\n",
      "Epoch 594/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2469 - mae: 0.8361 - val_loss: 0.4425 - val_mae: 0.4373\n",
      "Epoch 595/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2123 - mae: 0.8143 - val_loss: 0.4424 - val_mae: 0.4372\n",
      "Epoch 596/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.1817 - mae: 0.7854 - val_loss: 0.4423 - val_mae: 0.4372\n",
      "Epoch 597/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1942 - mae: 0.8126 - val_loss: 0.4421 - val_mae: 0.4371\n",
      "Epoch 598/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.2008 - mae: 0.8205 - val_loss: 0.4419 - val_mae: 0.4369\n",
      "Epoch 599/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1418 - mae: 0.7838 - val_loss: 0.4416 - val_mae: 0.4368\n",
      "Epoch 600/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1349 - mae: 0.7730 - val_loss: 0.4416 - val_mae: 0.4367\n",
      "Epoch 601/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1667 - mae: 0.7853 - val_loss: 0.4414 - val_mae: 0.4366\n",
      "Epoch 602/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2666 - mae: 0.8378 - val_loss: 0.4412 - val_mae: 0.4365\n",
      "Epoch 603/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.2879 - mae: 0.8592 - val_loss: 0.4411 - val_mae: 0.4365\n",
      "Epoch 604/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2000 - mae: 0.8240 - val_loss: 0.4410 - val_mae: 0.4364\n",
      "Epoch 605/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.3387 - mae: 0.8741 - val_loss: 0.4410 - val_mae: 0.4364\n",
      "Epoch 606/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1519 - mae: 0.8243 - val_loss: 0.4409 - val_mae: 0.4364\n",
      "Epoch 607/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.1314 - mae: 0.7579 - val_loss: 0.4407 - val_mae: 0.4362\n",
      "Epoch 608/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1937 - mae: 0.7890 - val_loss: 0.4406 - val_mae: 0.4362\n",
      "Epoch 609/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1252 - mae: 0.7837 - val_loss: 0.4404 - val_mae: 0.4360\n",
      "Epoch 610/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2299 - mae: 0.8246 - val_loss: 0.4403 - val_mae: 0.4360\n",
      "Epoch 611/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0340 - mae: 0.7385 - val_loss: 0.4404 - val_mae: 0.4361\n",
      "Epoch 612/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2397 - mae: 0.8249 - val_loss: 0.4402 - val_mae: 0.4360\n",
      "Epoch 613/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.1468 - mae: 0.8023 - val_loss: 0.4401 - val_mae: 0.4359\n",
      "Epoch 614/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1913 - mae: 0.8107 - val_loss: 0.4401 - val_mae: 0.4359\n",
      "Epoch 615/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0298 - mae: 0.7545 - val_loss: 0.4399 - val_mae: 0.4358\n",
      "Epoch 616/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0365 - mae: 0.7582 - val_loss: 0.4397 - val_mae: 0.4357\n",
      "Epoch 617/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.1366 - mae: 0.7899 - val_loss: 0.4396 - val_mae: 0.4356\n",
      "Epoch 618/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1343 - mae: 0.8099 - val_loss: 0.4396 - val_mae: 0.4356\n",
      "Epoch 619/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0905 - mae: 0.7578 - val_loss: 0.4394 - val_mae: 0.4355\n",
      "Epoch 620/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.1694 - mae: 0.8234 - val_loss: 0.4393 - val_mae: 0.4355\n",
      "Epoch 621/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1907 - mae: 0.8157 - val_loss: 0.4393 - val_mae: 0.4355\n",
      "Epoch 622/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1573 - mae: 0.8104 - val_loss: 0.4393 - val_mae: 0.4355\n",
      "Epoch 623/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.1743 - mae: 0.8276 - val_loss: 0.4391 - val_mae: 0.4354\n",
      "Epoch 624/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2431 - mae: 0.8412 - val_loss: 0.4391 - val_mae: 0.4354\n",
      "Epoch 625/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2869 - mae: 0.8421 - val_loss: 0.4390 - val_mae: 0.4353\n",
      "Epoch 626/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.1543 - mae: 0.8009 - val_loss: 0.4389 - val_mae: 0.4353\n",
      "Epoch 627/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2790 - mae: 0.8720 - val_loss: 0.4391 - val_mae: 0.4354\n",
      "Epoch 628/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 1.2592 - mae: 0.8560 - val_loss: 0.4391 - val_mae: 0.4354\n",
      "Epoch 629/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2558 - mae: 0.8459 - val_loss: 0.4391 - val_mae: 0.4354\n",
      "Epoch 630/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1519 - mae: 0.8125 - val_loss: 0.4389 - val_mae: 0.4353\n",
      "Epoch 631/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1838 - mae: 0.8135 - val_loss: 0.4388 - val_mae: 0.4352\n",
      "Epoch 632/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1423 - mae: 0.7872 - val_loss: 0.4387 - val_mae: 0.4352\n",
      "Epoch 633/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1548 - mae: 0.8083 - val_loss: 0.4386 - val_mae: 0.4351\n",
      "Epoch 634/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2449 - mae: 0.8432 - val_loss: 0.4385 - val_mae: 0.4351\n",
      "Epoch 635/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.3078 - mae: 0.8534 - val_loss: 0.4385 - val_mae: 0.4351\n",
      "Epoch 636/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2618 - mae: 0.8196 - val_loss: 0.4383 - val_mae: 0.4349\n",
      "Epoch 637/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2184 - mae: 0.8337 - val_loss: 0.4383 - val_mae: 0.4350\n",
      "Epoch 638/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.2128 - mae: 0.8368 - val_loss: 0.4381 - val_mae: 0.4349\n",
      "Epoch 639/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.2215 - mae: 0.8216 - val_loss: 0.4380 - val_mae: 0.4348\n",
      "Epoch 640/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2765 - mae: 0.8506 - val_loss: 0.4379 - val_mae: 0.4347\n",
      "Epoch 641/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2103 - mae: 0.8350 - val_loss: 0.4379 - val_mae: 0.4347\n",
      "Epoch 642/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.3304 - mae: 0.8807 - val_loss: 0.4379 - val_mae: 0.4347\n",
      "Epoch 643/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.0641 - mae: 0.7496 - val_loss: 0.4379 - val_mae: 0.4348\n",
      "Epoch 644/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0544 - mae: 0.7577 - val_loss: 0.4379 - val_mae: 0.4348\n",
      "Epoch 645/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2331 - mae: 0.8282 - val_loss: 0.4379 - val_mae: 0.4347\n",
      "Epoch 646/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 1.1613 - mae: 0.8033 - val_loss: 0.4378 - val_mae: 0.4347\n",
      "Epoch 647/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2141 - mae: 0.8137 - val_loss: 0.4377 - val_mae: 0.4347\n",
      "Epoch 648/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1167 - mae: 0.7833 - val_loss: 0.4377 - val_mae: 0.4346\n",
      "Epoch 649/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2884 - mae: 0.8574 - val_loss: 0.4374 - val_mae: 0.4345\n",
      "Epoch 650/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2630 - mae: 0.8316 - val_loss: 0.4373 - val_mae: 0.4344\n",
      "Epoch 651/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1525 - mae: 0.7829 - val_loss: 0.4372 - val_mae: 0.4344\n",
      "Epoch 652/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.1948 - mae: 0.8283 - val_loss: 0.4371 - val_mae: 0.4343\n",
      "Epoch 653/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1811 - mae: 0.8236 - val_loss: 0.4372 - val_mae: 0.4344\n",
      "Epoch 654/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1919 - mae: 0.8112 - val_loss: 0.4371 - val_mae: 0.4343\n",
      "Epoch 655/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1274 - mae: 0.7961 - val_loss: 0.4370 - val_mae: 0.4343\n",
      "Epoch 656/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 1.2695 - mae: 0.8476 - val_loss: 0.4371 - val_mae: 0.4344\n",
      "Epoch 657/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.3833 - mae: 0.8879 - val_loss: 0.4371 - val_mae: 0.4344\n",
      "Epoch 658/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2831 - mae: 0.8633 - val_loss: 0.4370 - val_mae: 0.4343\n",
      "Epoch 659/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.2739 - mae: 0.8508 - val_loss: 0.4369 - val_mae: 0.4342\n",
      "Epoch 660/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.2486 - mae: 0.8547 - val_loss: 0.4369 - val_mae: 0.4343\n",
      "Epoch 661/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.2648 - mae: 0.8414 - val_loss: 0.4369 - val_mae: 0.4343\n",
      "Epoch 662/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1366 - mae: 0.7849 - val_loss: 0.4369 - val_mae: 0.4343\n",
      "Epoch 663/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1094 - mae: 0.7740 - val_loss: 0.4368 - val_mae: 0.4342\n",
      "Epoch 664/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2286 - mae: 0.8413 - val_loss: 0.4367 - val_mae: 0.4341\n",
      "Epoch 665/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0860 - mae: 0.7444 - val_loss: 0.4364 - val_mae: 0.4340\n",
      "Epoch 666/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.2199 - mae: 0.8048 - val_loss: 0.4362 - val_mae: 0.4338\n",
      "Epoch 667/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1391 - mae: 0.8025 - val_loss: 0.4361 - val_mae: 0.4338\n",
      "Epoch 668/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1898 - mae: 0.8223 - val_loss: 0.4363 - val_mae: 0.4339\n",
      "Epoch 669/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2055 - mae: 0.8236 - val_loss: 0.4362 - val_mae: 0.4338\n",
      "Epoch 670/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1941 - mae: 0.8461 - val_loss: 0.4360 - val_mae: 0.4337\n",
      "Epoch 671/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.1422 - mae: 0.8091 - val_loss: 0.4360 - val_mae: 0.4337\n",
      "Epoch 672/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.1683 - mae: 0.8260 - val_loss: 0.4359 - val_mae: 0.4337\n",
      "Epoch 673/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0758 - mae: 0.7655 - val_loss: 0.4359 - val_mae: 0.4337\n",
      "Epoch 674/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1697 - mae: 0.7929 - val_loss: 0.4359 - val_mae: 0.4337\n",
      "Epoch 675/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.0501 - mae: 0.7323 - val_loss: 0.4359 - val_mae: 0.4337\n",
      "Epoch 676/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1504 - mae: 0.7878 - val_loss: 0.4357 - val_mae: 0.4336\n",
      "Epoch 677/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1992 - mae: 0.8073 - val_loss: 0.4357 - val_mae: 0.4336\n",
      "Epoch 678/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2737 - mae: 0.8469 - val_loss: 0.4357 - val_mae: 0.4336\n",
      "Epoch 679/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1570 - mae: 0.7937 - val_loss: 0.4357 - val_mae: 0.4336\n",
      "Epoch 680/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1245 - mae: 0.8063 - val_loss: 0.4357 - val_mae: 0.4336\n",
      "Epoch 681/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1933 - mae: 0.7797 - val_loss: 0.4357 - val_mae: 0.4336\n",
      "Epoch 682/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1829 - mae: 0.8176 - val_loss: 0.4356 - val_mae: 0.4336\n",
      "Epoch 683/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2250 - mae: 0.8573 - val_loss: 0.4356 - val_mae: 0.4336\n",
      "Epoch 684/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.0438 - mae: 0.7687 - val_loss: 0.4356 - val_mae: 0.4336\n",
      "Epoch 685/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2173 - mae: 0.8453 - val_loss: 0.4355 - val_mae: 0.4335\n",
      "Epoch 686/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.1464 - mae: 0.7961 - val_loss: 0.4353 - val_mae: 0.4334\n",
      "Epoch 687/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.1504 - mae: 0.8113 - val_loss: 0.4355 - val_mae: 0.4335\n",
      "Epoch 688/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.1371 - mae: 0.7845 - val_loss: 0.4356 - val_mae: 0.4336\n",
      "Epoch 689/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2461 - mae: 0.8299 - val_loss: 0.4356 - val_mae: 0.4336\n",
      "Epoch 690/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1101 - mae: 0.7906 - val_loss: 0.4356 - val_mae: 0.4336\n",
      "Epoch 691/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2821 - mae: 0.8622 - val_loss: 0.4357 - val_mae: 0.4336\n",
      "Epoch 692/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 1.1593 - mae: 0.7929 - val_loss: 0.4354 - val_mae: 0.4334\n",
      "Epoch 693/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0790 - mae: 0.7579 - val_loss: 0.4354 - val_mae: 0.4335\n",
      "Epoch 694/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.1648 - mae: 0.7958 - val_loss: 0.4352 - val_mae: 0.4334\n",
      "Epoch 695/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0877 - mae: 0.7909 - val_loss: 0.4352 - val_mae: 0.4334\n",
      "Epoch 696/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1602 - mae: 0.8238 - val_loss: 0.4352 - val_mae: 0.4334\n",
      "Epoch 697/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1523 - mae: 0.8226 - val_loss: 0.4352 - val_mae: 0.4334\n",
      "Epoch 698/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1979 - mae: 0.8162 - val_loss: 0.4351 - val_mae: 0.4334\n",
      "Epoch 699/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1289 - mae: 0.7868 - val_loss: 0.4350 - val_mae: 0.4334\n",
      "Epoch 700/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 1.1393 - mae: 0.7925 - val_loss: 0.4348 - val_mae: 0.4333\n",
      "Epoch 701/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0659 - mae: 0.7799 - val_loss: 0.4346 - val_mae: 0.4332\n",
      "Epoch 702/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.1751 - mae: 0.8144 - val_loss: 0.4346 - val_mae: 0.4332\n",
      "Epoch 703/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2108 - mae: 0.8412 - val_loss: 0.4346 - val_mae: 0.4332\n",
      "Epoch 704/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1923 - mae: 0.8264 - val_loss: 0.4345 - val_mae: 0.4332\n",
      "Epoch 705/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1394 - mae: 0.7784 - val_loss: 0.4346 - val_mae: 0.4332\n",
      "Epoch 706/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.2517 - mae: 0.8303 - val_loss: 0.4345 - val_mae: 0.4332\n",
      "Epoch 707/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0738 - mae: 0.7480 - val_loss: 0.4345 - val_mae: 0.4332\n",
      "Epoch 708/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2438 - mae: 0.8328 - val_loss: 0.4344 - val_mae: 0.4332\n",
      "Epoch 709/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0995 - mae: 0.7802 - val_loss: 0.4344 - val_mae: 0.4332\n",
      "Epoch 710/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.1708 - mae: 0.8107 - val_loss: 0.4341 - val_mae: 0.4331\n",
      "Epoch 711/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2139 - mae: 0.7983 - val_loss: 0.4341 - val_mae: 0.4331\n",
      "Epoch 712/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1026 - mae: 0.7739 - val_loss: 0.4341 - val_mae: 0.4331\n",
      "Epoch 713/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2263 - mae: 0.8495 - val_loss: 0.4341 - val_mae: 0.4331\n",
      "Epoch 714/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1016 - mae: 0.7798 - val_loss: 0.4341 - val_mae: 0.4331\n",
      "Epoch 715/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1193 - mae: 0.8057 - val_loss: 0.4341 - val_mae: 0.4331\n",
      "Epoch 716/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1305 - mae: 0.7968 - val_loss: 0.4341 - val_mae: 0.4332\n",
      "Epoch 717/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1950 - mae: 0.8155 - val_loss: 0.4341 - val_mae: 0.4332\n",
      "Epoch 718/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.2501 - mae: 0.8445 - val_loss: 0.4341 - val_mae: 0.4332\n",
      "Epoch 719/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.2266 - mae: 0.8354 - val_loss: 0.4338 - val_mae: 0.4331\n",
      "Epoch 720/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2318 - mae: 0.8479 - val_loss: 0.4338 - val_mae: 0.4331\n",
      "Epoch 721/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1343 - mae: 0.7901 - val_loss: 0.4337 - val_mae: 0.4330\n",
      "Epoch 722/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1985 - mae: 0.8120 - val_loss: 0.4337 - val_mae: 0.4330\n",
      "Epoch 723/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2171 - mae: 0.8259 - val_loss: 0.4338 - val_mae: 0.4331\n",
      "Epoch 724/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2053 - mae: 0.8384 - val_loss: 0.4338 - val_mae: 0.4331\n",
      "Epoch 725/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1278 - mae: 0.8012 - val_loss: 0.4338 - val_mae: 0.4331\n",
      "Epoch 726/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.0574 - mae: 0.7404 - val_loss: 0.4338 - val_mae: 0.4331\n",
      "Epoch 727/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1.3018 - mae: 0.8832 - val_loss: 0.4337 - val_mae: 0.4331\n",
      "Epoch 728/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1582 - mae: 0.7950 - val_loss: 0.4336 - val_mae: 0.4331\n",
      "Epoch 729/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.1759 - mae: 0.8063 - val_loss: 0.4336 - val_mae: 0.4331\n",
      "Epoch 730/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1042 - mae: 0.7995 - val_loss: 0.4336 - val_mae: 0.4331\n",
      "Epoch 731/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0683 - mae: 0.7595 - val_loss: 0.4334 - val_mae: 0.4330\n",
      "Epoch 732/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1325 - mae: 0.7944 - val_loss: 0.4332 - val_mae: 0.4329\n",
      "Epoch 733/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1127 - mae: 0.7808 - val_loss: 0.4333 - val_mae: 0.4330\n",
      "Epoch 734/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0992 - mae: 0.7956 - val_loss: 0.4332 - val_mae: 0.4330\n",
      "Epoch 735/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.2162 - mae: 0.8121 - val_loss: 0.4331 - val_mae: 0.4329\n",
      "Epoch 736/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0969 - mae: 0.7431 - val_loss: 0.4331 - val_mae: 0.4329\n",
      "Epoch 737/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1591 - mae: 0.8187 - val_loss: 0.4331 - val_mae: 0.4329\n",
      "Epoch 738/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0965 - mae: 0.7677 - val_loss: 0.4330 - val_mae: 0.4329\n",
      "Epoch 739/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.1610 - mae: 0.8117 - val_loss: 0.4328 - val_mae: 0.4329\n",
      "Epoch 740/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.1072 - mae: 0.7688 - val_loss: 0.4327 - val_mae: 0.4328\n",
      "Epoch 741/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1247 - mae: 0.7908 - val_loss: 0.4325 - val_mae: 0.4327\n",
      "Epoch 742/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1254 - mae: 0.7944 - val_loss: 0.4324 - val_mae: 0.4327\n",
      "Epoch 743/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.0918 - mae: 0.7624 - val_loss: 0.4322 - val_mae: 0.4326\n",
      "Epoch 744/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.1609 - mae: 0.8239 - val_loss: 0.4322 - val_mae: 0.4326\n",
      "Epoch 745/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1834 - mae: 0.8289 - val_loss: 0.4322 - val_mae: 0.4326\n",
      "Epoch 746/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.1995 - mae: 0.8313 - val_loss: 0.4322 - val_mae: 0.4326\n",
      "Epoch 747/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2291 - mae: 0.8288 - val_loss: 0.4322 - val_mae: 0.4327\n",
      "Epoch 748/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1586 - mae: 0.8140 - val_loss: 0.4322 - val_mae: 0.4326\n",
      "Epoch 749/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.2181 - mae: 0.8354 - val_loss: 0.4321 - val_mae: 0.4326\n",
      "Epoch 750/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1927 - mae: 0.8134 - val_loss: 0.4321 - val_mae: 0.4326\n",
      "Epoch 751/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.2336 - mae: 0.8231 - val_loss: 0.4320 - val_mae: 0.4326\n",
      "Epoch 752/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1810 - mae: 0.8179 - val_loss: 0.4321 - val_mae: 0.4326\n",
      "Epoch 753/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.2247 - mae: 0.8525 - val_loss: 0.4320 - val_mae: 0.4326\n",
      "Epoch 754/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0973 - mae: 0.7885 - val_loss: 0.4320 - val_mae: 0.4326\n",
      "Epoch 755/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0984 - mae: 0.7683 - val_loss: 0.4320 - val_mae: 0.4326\n",
      "Epoch 756/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1484 - mae: 0.7993 - val_loss: 0.4319 - val_mae: 0.4326\n",
      "Epoch 757/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1925 - mae: 0.8088 - val_loss: 0.4319 - val_mae: 0.4326\n",
      "Epoch 758/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.0669 - mae: 0.7655 - val_loss: 0.4319 - val_mae: 0.4326\n",
      "Epoch 759/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0726 - mae: 0.7709 - val_loss: 0.4319 - val_mae: 0.4326\n",
      "Epoch 760/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1.2706 - mae: 0.8499 - val_loss: 0.4319 - val_mae: 0.4326\n",
      "Epoch 761/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1083 - mae: 0.7783 - val_loss: 0.4319 - val_mae: 0.4326\n",
      "Epoch 762/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.1283 - mae: 0.8073 - val_loss: 0.4318 - val_mae: 0.4325\n",
      "Epoch 763/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1698 - mae: 0.8097 - val_loss: 0.4317 - val_mae: 0.4325\n",
      "Epoch 764/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1283 - mae: 0.8042 - val_loss: 0.4314 - val_mae: 0.4324\n",
      "Epoch 765/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2471 - mae: 0.8550 - val_loss: 0.4314 - val_mae: 0.4324\n",
      "Epoch 766/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1965 - mae: 0.8084 - val_loss: 0.4314 - val_mae: 0.4324\n",
      "Epoch 767/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2192 - mae: 0.8287 - val_loss: 0.4315 - val_mae: 0.4325\n",
      "Epoch 768/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2265 - mae: 0.8271 - val_loss: 0.4315 - val_mae: 0.4324\n",
      "Epoch 769/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.1889 - mae: 0.8181 - val_loss: 0.4315 - val_mae: 0.4325\n",
      "Epoch 770/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2434 - mae: 0.8403 - val_loss: 0.4315 - val_mae: 0.4325\n",
      "Epoch 771/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0406 - mae: 0.7461 - val_loss: 0.4315 - val_mae: 0.4325\n",
      "Epoch 772/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1215 - mae: 0.7920 - val_loss: 0.4314 - val_mae: 0.4324\n",
      "Epoch 773/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1183 - mae: 0.7811 - val_loss: 0.4314 - val_mae: 0.4324\n",
      "Epoch 774/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1634 - mae: 0.8045 - val_loss: 0.4314 - val_mae: 0.4324\n",
      "Epoch 775/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.1151 - mae: 0.7937 - val_loss: 0.4314 - val_mae: 0.4324\n",
      "Epoch 776/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1531 - mae: 0.8042 - val_loss: 0.4314 - val_mae: 0.4324\n",
      "Epoch 777/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.1170 - mae: 0.7848 - val_loss: 0.4312 - val_mae: 0.4324\n",
      "Epoch 778/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0789 - mae: 0.7788 - val_loss: 0.4311 - val_mae: 0.4323\n",
      "Epoch 779/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.1288 - mae: 0.8046 - val_loss: 0.4310 - val_mae: 0.4323\n",
      "Epoch 780/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.1595 - mae: 0.8042 - val_loss: 0.4308 - val_mae: 0.4322\n",
      "Epoch 781/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2060 - mae: 0.8273 - val_loss: 0.4308 - val_mae: 0.4322\n",
      "Epoch 782/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2832 - mae: 0.8429 - val_loss: 0.4308 - val_mae: 0.4322\n",
      "Epoch 783/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1215 - mae: 0.7889 - val_loss: 0.4308 - val_mae: 0.4322\n",
      "Epoch 784/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1963 - mae: 0.8569 - val_loss: 0.4306 - val_mae: 0.4322\n",
      "Epoch 785/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2148 - mae: 0.8247 - val_loss: 0.4305 - val_mae: 0.4321\n",
      "Epoch 786/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2837 - mae: 0.8314 - val_loss: 0.4304 - val_mae: 0.4321\n",
      "Epoch 787/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.1351 - mae: 0.7756 - val_loss: 0.4306 - val_mae: 0.4322\n",
      "Epoch 788/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1499 - mae: 0.7954 - val_loss: 0.4305 - val_mae: 0.4322\n",
      "Epoch 789/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2156 - mae: 0.8254 - val_loss: 0.4305 - val_mae: 0.4321\n",
      "Epoch 790/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.1426 - mae: 0.7949 - val_loss: 0.4304 - val_mae: 0.4321\n",
      "Epoch 791/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2557 - mae: 0.8449 - val_loss: 0.4303 - val_mae: 0.4321\n",
      "Epoch 792/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1134 - mae: 0.7874 - val_loss: 0.4303 - val_mae: 0.4321\n",
      "Epoch 793/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1468 - mae: 0.8015 - val_loss: 0.4303 - val_mae: 0.4321\n",
      "Epoch 794/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1210 - mae: 0.7900 - val_loss: 0.4305 - val_mae: 0.4321\n",
      "Epoch 795/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1537 - mae: 0.7992 - val_loss: 0.4306 - val_mae: 0.4322\n",
      "Epoch 796/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2139 - mae: 0.8333 - val_loss: 0.4305 - val_mae: 0.4322\n",
      "Epoch 797/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1152 - mae: 0.7776 - val_loss: 0.4306 - val_mae: 0.4322\n",
      "Epoch 798/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.2256 - mae: 0.8286 - val_loss: 0.4306 - val_mae: 0.4322\n",
      "Epoch 799/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1640 - mae: 0.7891 - val_loss: 0.4306 - val_mae: 0.4322\n",
      "Epoch 800/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.0811 - mae: 0.7846 - val_loss: 0.4305 - val_mae: 0.4322\n",
      "Epoch 801/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.2471 - mae: 0.8483 - val_loss: 0.4306 - val_mae: 0.4322\n",
      "Epoch 802/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1626 - mae: 0.8103 - val_loss: 0.4307 - val_mae: 0.4323\n",
      "Epoch 803/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2323 - mae: 0.8365 - val_loss: 0.4306 - val_mae: 0.4322\n",
      "Epoch 804/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2157 - mae: 0.8477 - val_loss: 0.4306 - val_mae: 0.4322\n",
      "Epoch 805/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.1051 - mae: 0.7730 - val_loss: 0.4304 - val_mae: 0.4322\n",
      "Epoch 806/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1696 - mae: 0.7943 - val_loss: 0.4302 - val_mae: 0.4321\n",
      "Epoch 807/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0985 - mae: 0.7844 - val_loss: 0.4301 - val_mae: 0.4321\n",
      "Epoch 808/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.1724 - mae: 0.8185 - val_loss: 0.4299 - val_mae: 0.4320\n",
      "Epoch 809/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0673 - mae: 0.7555 - val_loss: 0.4297 - val_mae: 0.4319\n",
      "Epoch 810/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1877 - mae: 0.8219 - val_loss: 0.4297 - val_mae: 0.4319\n",
      "Epoch 811/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0810 - mae: 0.7715 - val_loss: 0.4298 - val_mae: 0.4319\n",
      "Epoch 812/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1510 - mae: 0.8039 - val_loss: 0.4297 - val_mae: 0.4319\n",
      "Epoch 813/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1257 - mae: 0.7960 - val_loss: 0.4297 - val_mae: 0.4319\n",
      "Epoch 814/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.0184 - mae: 0.7266 - val_loss: 0.4296 - val_mae: 0.4319\n",
      "Epoch 815/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1186 - mae: 0.8004 - val_loss: 0.4295 - val_mae: 0.4318\n",
      "Epoch 816/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0722 - mae: 0.7559 - val_loss: 0.4296 - val_mae: 0.4319\n",
      "Epoch 817/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1.2690 - mae: 0.8605 - val_loss: 0.4296 - val_mae: 0.4319\n",
      "Epoch 818/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1346 - mae: 0.8006 - val_loss: 0.4297 - val_mae: 0.4319\n",
      "Epoch 819/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1658 - mae: 0.8261 - val_loss: 0.4296 - val_mae: 0.4319\n",
      "Epoch 820/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1679 - mae: 0.8101 - val_loss: 0.4296 - val_mae: 0.4319\n",
      "Epoch 821/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2343 - mae: 0.8498 - val_loss: 0.4294 - val_mae: 0.4318\n",
      "Epoch 822/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0689 - mae: 0.7832 - val_loss: 0.4294 - val_mae: 0.4318\n",
      "Epoch 823/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0800 - mae: 0.7673 - val_loss: 0.4292 - val_mae: 0.4317\n",
      "Epoch 824/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.0631 - mae: 0.7508 - val_loss: 0.4291 - val_mae: 0.4317\n",
      "Epoch 825/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0219 - mae: 0.7560 - val_loss: 0.4290 - val_mae: 0.4316\n",
      "Epoch 826/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.2632 - mae: 0.8645 - val_loss: 0.4290 - val_mae: 0.4317\n",
      "Epoch 827/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 1.0986 - mae: 0.7741 - val_loss: 0.4290 - val_mae: 0.4317\n",
      "Epoch 828/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1205 - mae: 0.7904 - val_loss: 0.4290 - val_mae: 0.4317\n",
      "Epoch 829/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1585 - mae: 0.8078 - val_loss: 0.4291 - val_mae: 0.4317\n",
      "Epoch 830/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.0975 - mae: 0.7741 - val_loss: 0.4292 - val_mae: 0.4317\n",
      "Epoch 831/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.1713 - mae: 0.8161 - val_loss: 0.4292 - val_mae: 0.4317\n",
      "Epoch 832/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1756 - mae: 0.8111 - val_loss: 0.4293 - val_mae: 0.4318\n",
      "Epoch 833/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1039 - mae: 0.7619 - val_loss: 0.4292 - val_mae: 0.4317\n",
      "Epoch 834/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1717 - mae: 0.8058 - val_loss: 0.4292 - val_mae: 0.4317\n",
      "Epoch 835/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0844 - mae: 0.7762 - val_loss: 0.4293 - val_mae: 0.4317\n",
      "Epoch 836/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.0949 - mae: 0.7863 - val_loss: 0.4293 - val_mae: 0.4318\n",
      "Epoch 837/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2772 - mae: 0.8679 - val_loss: 0.4294 - val_mae: 0.4318\n",
      "Epoch 838/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1639 - mae: 0.8177 - val_loss: 0.4293 - val_mae: 0.4318\n",
      "Epoch 839/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.3520 - mae: 0.8942 - val_loss: 0.4293 - val_mae: 0.4318\n",
      "Epoch 840/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.2056 - mae: 0.8493 - val_loss: 0.4294 - val_mae: 0.4318\n",
      "Epoch 841/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0221 - mae: 0.7371 - val_loss: 0.4294 - val_mae: 0.4318\n",
      "Epoch 842/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1762 - mae: 0.8181 - val_loss: 0.4292 - val_mae: 0.4318\n",
      "Epoch 843/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2000 - mae: 0.8340 - val_loss: 0.4293 - val_mae: 0.4318\n",
      "Epoch 844/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.2321 - mae: 0.8434 - val_loss: 0.4293 - val_mae: 0.4318\n",
      "Epoch 845/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.1647 - mae: 0.8129 - val_loss: 0.4293 - val_mae: 0.4318\n",
      "Epoch 846/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.0942 - mae: 0.8023 - val_loss: 0.4293 - val_mae: 0.4318\n",
      "Epoch 847/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1298 - mae: 0.8133 - val_loss: 0.4292 - val_mae: 0.4317\n",
      "Epoch 848/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0969 - mae: 0.7668 - val_loss: 0.4293 - val_mae: 0.4318\n",
      "Epoch 849/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2281 - mae: 0.8232 - val_loss: 0.4293 - val_mae: 0.4318\n",
      "Epoch 850/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.1805 - mae: 0.8126 - val_loss: 0.4293 - val_mae: 0.4318\n",
      "Epoch 851/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.2911 - mae: 0.8489 - val_loss: 0.4292 - val_mae: 0.4317\n",
      "Epoch 852/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1035 - mae: 0.7886 - val_loss: 0.4291 - val_mae: 0.4317\n",
      "Epoch 853/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.1619 - mae: 0.7998 - val_loss: 0.4290 - val_mae: 0.4317\n",
      "Epoch 854/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1516 - mae: 0.8128 - val_loss: 0.4291 - val_mae: 0.4317\n",
      "Epoch 855/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0642 - mae: 0.7781 - val_loss: 0.4292 - val_mae: 0.4317\n",
      "Epoch 856/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.1567 - mae: 0.8372 - val_loss: 0.4291 - val_mae: 0.4317\n",
      "Epoch 857/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.1734 - mae: 0.8050 - val_loss: 0.4293 - val_mae: 0.4318\n",
      "Epoch 858/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0527 - mae: 0.7670 - val_loss: 0.4293 - val_mae: 0.4318\n",
      "Epoch 859/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0646 - mae: 0.7612 - val_loss: 0.4292 - val_mae: 0.4317\n",
      "Epoch 860/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1774 - mae: 0.8268 - val_loss: 0.4292 - val_mae: 0.4317\n",
      "Epoch 861/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.0999 - mae: 0.7718 - val_loss: 0.4292 - val_mae: 0.4317\n",
      "Epoch 862/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1914 - mae: 0.8433 - val_loss: 0.4291 - val_mae: 0.4317\n",
      "Epoch 863/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1423 - mae: 0.8090 - val_loss: 0.4292 - val_mae: 0.4317\n",
      "Epoch 864/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0186 - mae: 0.7317 - val_loss: 0.4292 - val_mae: 0.4317\n",
      "Epoch 865/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2817 - mae: 0.8576 - val_loss: 0.4294 - val_mae: 0.4318\n",
      "Epoch 866/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1700 - mae: 0.8132 - val_loss: 0.4293 - val_mae: 0.4317\n",
      "Epoch 867/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0902 - mae: 0.7772 - val_loss: 0.4293 - val_mae: 0.4317\n",
      "Epoch 868/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0625 - mae: 0.7704 - val_loss: 0.4293 - val_mae: 0.4317\n",
      "Epoch 869/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.2000 - mae: 0.8195 - val_loss: 0.4293 - val_mae: 0.4317\n",
      "Epoch 870/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0764 - mae: 0.7755 - val_loss: 0.4293 - val_mae: 0.4317\n",
      "Epoch 871/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1297 - mae: 0.7969 - val_loss: 0.4293 - val_mae: 0.4317\n",
      "Epoch 872/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1262 - mae: 0.7878 - val_loss: 0.4291 - val_mae: 0.4316\n",
      "Epoch 873/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1524 - mae: 0.8180 - val_loss: 0.4291 - val_mae: 0.4316\n",
      "Epoch 874/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1488 - mae: 0.8164 - val_loss: 0.4291 - val_mae: 0.4316\n",
      "Epoch 875/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0718 - mae: 0.7639 - val_loss: 0.4291 - val_mae: 0.4316\n",
      "Epoch 876/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0638 - mae: 0.7644 - val_loss: 0.4291 - val_mae: 0.4316\n",
      "Epoch 877/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.0365 - mae: 0.7458 - val_loss: 0.4291 - val_mae: 0.4316\n",
      "Epoch 878/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1271 - mae: 0.7826 - val_loss: 0.4292 - val_mae: 0.4316\n",
      "Epoch 879/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1437 - mae: 0.7964 - val_loss: 0.4292 - val_mae: 0.4316\n",
      "Epoch 880/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.2240 - mae: 0.8306 - val_loss: 0.4291 - val_mae: 0.4316\n",
      "Epoch 881/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.1381 - mae: 0.7846 - val_loss: 0.4289 - val_mae: 0.4315\n",
      "Epoch 882/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0677 - mae: 0.7638 - val_loss: 0.4289 - val_mae: 0.4315\n",
      "Epoch 883/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1308 - mae: 0.7868 - val_loss: 0.4288 - val_mae: 0.4315\n",
      "Epoch 884/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.2086 - mae: 0.8373 - val_loss: 0.4287 - val_mae: 0.4314\n",
      "Epoch 885/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1456 - mae: 0.7961 - val_loss: 0.4288 - val_mae: 0.4314\n",
      "Epoch 886/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0956 - mae: 0.7998 - val_loss: 0.4286 - val_mae: 0.4314\n",
      "Epoch 887/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1230 - mae: 0.8002 - val_loss: 0.4286 - val_mae: 0.4314\n",
      "Epoch 888/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.2389 - mae: 0.8501 - val_loss: 0.4285 - val_mae: 0.4313\n",
      "Epoch 889/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.1674 - mae: 0.7972 - val_loss: 0.4284 - val_mae: 0.4313\n",
      "Epoch 890/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0676 - mae: 0.7633 - val_loss: 0.4284 - val_mae: 0.4313\n",
      "Epoch 891/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1424 - mae: 0.8133 - val_loss: 0.4282 - val_mae: 0.4312\n",
      "Epoch 892/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2394 - mae: 0.8494 - val_loss: 0.4282 - val_mae: 0.4312\n",
      "Epoch 893/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0865 - mae: 0.7507 - val_loss: 0.4281 - val_mae: 0.4312\n",
      "Epoch 894/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.2104 - mae: 0.8309 - val_loss: 0.4281 - val_mae: 0.4312\n",
      "Epoch 895/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1354 - mae: 0.7982 - val_loss: 0.4282 - val_mae: 0.4312\n",
      "Epoch 896/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2236 - mae: 0.8324 - val_loss: 0.4282 - val_mae: 0.4312\n",
      "Epoch 897/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1089 - mae: 0.7652 - val_loss: 0.4281 - val_mae: 0.4312\n",
      "Epoch 898/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1990 - mae: 0.8337 - val_loss: 0.4280 - val_mae: 0.4311\n",
      "Epoch 899/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1244 - mae: 0.7938 - val_loss: 0.4280 - val_mae: 0.4311\n",
      "Epoch 900/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0605 - mae: 0.7636 - val_loss: 0.4280 - val_mae: 0.4311\n",
      "Epoch 901/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0807 - mae: 0.7717 - val_loss: 0.4279 - val_mae: 0.4311\n",
      "Epoch 902/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1071 - mae: 0.7779 - val_loss: 0.4278 - val_mae: 0.4310\n",
      "Epoch 903/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2194 - mae: 0.8290 - val_loss: 0.4278 - val_mae: 0.4310\n",
      "Epoch 904/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0944 - mae: 0.7891 - val_loss: 0.4277 - val_mae: 0.4310\n",
      "Epoch 905/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.1532 - mae: 0.8172 - val_loss: 0.4277 - val_mae: 0.4310\n",
      "Epoch 906/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2003 - mae: 0.8348 - val_loss: 0.4276 - val_mae: 0.4310\n",
      "Epoch 907/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1101 - mae: 0.7721 - val_loss: 0.4276 - val_mae: 0.4309\n",
      "Epoch 908/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0717 - mae: 0.7561 - val_loss: 0.4276 - val_mae: 0.4309\n",
      "Epoch 909/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0330 - mae: 0.7555 - val_loss: 0.4276 - val_mae: 0.4309\n",
      "Epoch 910/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2960 - mae: 0.8684 - val_loss: 0.4275 - val_mae: 0.4309\n",
      "Epoch 911/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.1045 - mae: 0.7650 - val_loss: 0.4273 - val_mae: 0.4308\n",
      "Epoch 912/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1173 - mae: 0.7846 - val_loss: 0.4272 - val_mae: 0.4308\n",
      "Epoch 913/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1099 - mae: 0.7770 - val_loss: 0.4271 - val_mae: 0.4307\n",
      "Epoch 914/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0616 - mae: 0.7496 - val_loss: 0.4269 - val_mae: 0.4306\n",
      "Epoch 915/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1143 - mae: 0.8093 - val_loss: 0.4269 - val_mae: 0.4306\n",
      "Epoch 916/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0366 - mae: 0.7459 - val_loss: 0.4267 - val_mae: 0.4305\n",
      "Epoch 917/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0915 - mae: 0.7706 - val_loss: 0.4268 - val_mae: 0.4306\n",
      "Epoch 918/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1805 - mae: 0.8161 - val_loss: 0.4268 - val_mae: 0.4306\n",
      "Epoch 919/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0645 - mae: 0.7801 - val_loss: 0.4267 - val_mae: 0.4305\n",
      "Epoch 920/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1618 - mae: 0.8180 - val_loss: 0.4267 - val_mae: 0.4305\n",
      "Epoch 921/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.1596 - mae: 0.8139 - val_loss: 0.4265 - val_mae: 0.4304\n",
      "Epoch 922/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1703 - mae: 0.8177 - val_loss: 0.4264 - val_mae: 0.4304\n",
      "Epoch 923/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2553 - mae: 0.8358 - val_loss: 0.4263 - val_mae: 0.4304\n",
      "Epoch 924/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1284 - mae: 0.7899 - val_loss: 0.4262 - val_mae: 0.4303\n",
      "Epoch 925/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1041 - mae: 0.7912 - val_loss: 0.4263 - val_mae: 0.4303\n",
      "Epoch 926/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1757 - mae: 0.8214 - val_loss: 0.4262 - val_mae: 0.4303\n",
      "Epoch 927/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1259 - mae: 0.7910 - val_loss: 0.4262 - val_mae: 0.4303\n",
      "Epoch 928/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1367 - mae: 0.8066 - val_loss: 0.4263 - val_mae: 0.4303\n",
      "Epoch 929/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1084 - mae: 0.7744 - val_loss: 0.4263 - val_mae: 0.4303\n",
      "Epoch 930/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1505 - mae: 0.7960 - val_loss: 0.4264 - val_mae: 0.4303\n",
      "Epoch 931/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.1691 - mae: 0.8301 - val_loss: 0.4264 - val_mae: 0.4304\n",
      "Epoch 932/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0864 - mae: 0.7608 - val_loss: 0.4263 - val_mae: 0.4303\n",
      "Epoch 933/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1634 - mae: 0.8038 - val_loss: 0.4262 - val_mae: 0.4303\n",
      "Epoch 934/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2020 - mae: 0.8271 - val_loss: 0.4262 - val_mae: 0.4303\n",
      "Epoch 935/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0900 - mae: 0.7767 - val_loss: 0.4262 - val_mae: 0.4303\n",
      "Epoch 936/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1123 - mae: 0.7788 - val_loss: 0.4263 - val_mae: 0.4303\n",
      "Epoch 937/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0590 - mae: 0.7614 - val_loss: 0.4263 - val_mae: 0.4303\n",
      "Epoch 938/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.2380 - mae: 0.8296 - val_loss: 0.4264 - val_mae: 0.4303\n",
      "Epoch 939/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0666 - mae: 0.7590 - val_loss: 0.4263 - val_mae: 0.4303\n",
      "Epoch 940/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1498 - mae: 0.7989 - val_loss: 0.4263 - val_mae: 0.4302\n",
      "Epoch 941/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.0692 - mae: 0.7697 - val_loss: 0.4263 - val_mae: 0.4302\n",
      "Epoch 942/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1434 - mae: 0.8086 - val_loss: 0.4264 - val_mae: 0.4303\n",
      "Epoch 943/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.9960 - mae: 0.7433 - val_loss: 0.4264 - val_mae: 0.4302\n",
      "Epoch 944/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0086 - mae: 0.7418 - val_loss: 0.4264 - val_mae: 0.4303\n",
      "Epoch 945/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0897 - mae: 0.7899 - val_loss: 0.4263 - val_mae: 0.4302\n",
      "Epoch 946/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1347 - mae: 0.7726 - val_loss: 0.4264 - val_mae: 0.4302\n",
      "Epoch 947/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1024 - mae: 0.7848 - val_loss: 0.4264 - val_mae: 0.4302\n",
      "Epoch 948/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0214 - mae: 0.7410 - val_loss: 0.4263 - val_mae: 0.4302\n",
      "Epoch 949/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1035 - mae: 0.7753 - val_loss: 0.4263 - val_mae: 0.4302\n",
      "Epoch 950/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1637 - mae: 0.8108 - val_loss: 0.4261 - val_mae: 0.4301\n",
      "Epoch 951/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.0931 - mae: 0.7807 - val_loss: 0.4260 - val_mae: 0.4301\n",
      "Epoch 952/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2343 - mae: 0.8445 - val_loss: 0.4259 - val_mae: 0.4300\n",
      "Epoch 953/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1001 - mae: 0.7943 - val_loss: 0.4259 - val_mae: 0.4300\n",
      "Epoch 954/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1602 - mae: 0.8208 - val_loss: 0.4260 - val_mae: 0.4300\n",
      "Epoch 955/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1169 - mae: 0.8082 - val_loss: 0.4260 - val_mae: 0.4300\n",
      "Epoch 956/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0202 - mae: 0.7429 - val_loss: 0.4260 - val_mae: 0.4300\n",
      "Epoch 957/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1452 - mae: 0.7991 - val_loss: 0.4260 - val_mae: 0.4300\n",
      "Epoch 958/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0979 - mae: 0.7622 - val_loss: 0.4259 - val_mae: 0.4300\n",
      "Epoch 959/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0517 - mae: 0.7842 - val_loss: 0.4259 - val_mae: 0.4299\n",
      "Epoch 960/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1255 - mae: 0.7977 - val_loss: 0.4258 - val_mae: 0.4299\n",
      "Epoch 961/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.1162 - mae: 0.7886 - val_loss: 0.4258 - val_mae: 0.4299\n",
      "Epoch 962/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0360 - mae: 0.7425 - val_loss: 0.4257 - val_mae: 0.4299\n",
      "Epoch 963/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0707 - mae: 0.7553 - val_loss: 0.4255 - val_mae: 0.4298\n",
      "Epoch 964/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0714 - mae: 0.7493 - val_loss: 0.4254 - val_mae: 0.4297\n",
      "Epoch 965/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0852 - mae: 0.7797 - val_loss: 0.4254 - val_mae: 0.4297\n",
      "Epoch 966/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0802 - mae: 0.7784 - val_loss: 0.4252 - val_mae: 0.4297\n",
      "Epoch 967/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0747 - mae: 0.7853 - val_loss: 0.4251 - val_mae: 0.4296\n",
      "Epoch 968/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0985 - mae: 0.7711 - val_loss: 0.4252 - val_mae: 0.4296\n",
      "Epoch 969/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0225 - mae: 0.7575 - val_loss: 0.4252 - val_mae: 0.4296\n",
      "Epoch 970/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2543 - mae: 0.8522 - val_loss: 0.4251 - val_mae: 0.4296\n",
      "Epoch 971/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.1069 - mae: 0.7926 - val_loss: 0.4250 - val_mae: 0.4295\n",
      "Epoch 972/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0278 - mae: 0.7638 - val_loss: 0.4250 - val_mae: 0.4295\n",
      "Epoch 973/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1010 - mae: 0.7898 - val_loss: 0.4250 - val_mae: 0.4295\n",
      "Epoch 974/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0666 - mae: 0.7731 - val_loss: 0.4250 - val_mae: 0.4295\n",
      "Epoch 975/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1469 - mae: 0.8128 - val_loss: 0.4250 - val_mae: 0.4295\n",
      "Epoch 976/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0391 - mae: 0.7642 - val_loss: 0.4250 - val_mae: 0.4295\n",
      "Epoch 977/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.0993 - mae: 0.7906 - val_loss: 0.4250 - val_mae: 0.4294\n",
      "Epoch 978/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.1303 - mae: 0.7934 - val_loss: 0.4250 - val_mae: 0.4294\n",
      "Epoch 979/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2186 - mae: 0.8289 - val_loss: 0.4251 - val_mae: 0.4295\n",
      "Epoch 980/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1296 - mae: 0.8061 - val_loss: 0.4250 - val_mae: 0.4294\n",
      "Epoch 981/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1305 - mae: 0.7950 - val_loss: 0.4250 - val_mae: 0.4294\n",
      "Epoch 982/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0850 - mae: 0.7542 - val_loss: 0.4251 - val_mae: 0.4294\n",
      "Epoch 983/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0991 - mae: 0.7792 - val_loss: 0.4250 - val_mae: 0.4294\n",
      "Epoch 984/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1956 - mae: 0.8140 - val_loss: 0.4251 - val_mae: 0.4294\n",
      "Epoch 985/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0706 - mae: 0.7750 - val_loss: 0.4251 - val_mae: 0.4294\n",
      "Epoch 986/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1995 - mae: 0.8391 - val_loss: 0.4251 - val_mae: 0.4294\n",
      "Epoch 987/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.9919 - mae: 0.7516 - val_loss: 0.4251 - val_mae: 0.4294\n",
      "Epoch 988/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0645 - mae: 0.7618 - val_loss: 0.4250 - val_mae: 0.4293\n",
      "Epoch 989/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0816 - mae: 0.7659 - val_loss: 0.4250 - val_mae: 0.4293\n",
      "Epoch 990/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1412 - mae: 0.8384 - val_loss: 0.4251 - val_mae: 0.4293\n",
      "Epoch 991/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0357 - mae: 0.7607 - val_loss: 0.4251 - val_mae: 0.4293\n",
      "Epoch 992/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1670 - mae: 0.8293 - val_loss: 0.4251 - val_mae: 0.4293\n",
      "Epoch 993/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1181 - mae: 0.8109 - val_loss: 0.4251 - val_mae: 0.4293\n",
      "Epoch 994/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.9742 - mae: 0.7195 - val_loss: 0.4251 - val_mae: 0.4293\n",
      "Epoch 995/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.1604 - mae: 0.8114 - val_loss: 0.4252 - val_mae: 0.4293\n",
      "Epoch 996/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1027 - mae: 0.7674 - val_loss: 0.4253 - val_mae: 0.4293\n",
      "Epoch 997/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2058 - mae: 0.8362 - val_loss: 0.4251 - val_mae: 0.4292\n",
      "Epoch 998/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1135 - mae: 0.7850 - val_loss: 0.4249 - val_mae: 0.4292\n",
      "Epoch 999/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.9813 - mae: 0.7411 - val_loss: 0.4248 - val_mae: 0.4291\n",
      "Epoch 1000/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0651 - mae: 0.7608 - val_loss: 0.4247 - val_mae: 0.4291\n",
      "Epoch 1001/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0280 - mae: 0.7491 - val_loss: 0.4246 - val_mae: 0.4290\n",
      "Epoch 1002/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.0284 - mae: 0.7437 - val_loss: 0.4245 - val_mae: 0.4290\n",
      "Epoch 1003/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1223 - mae: 0.7859 - val_loss: 0.4245 - val_mae: 0.4290\n",
      "Epoch 1004/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1349 - mae: 0.8149 - val_loss: 0.4245 - val_mae: 0.4290\n",
      "Epoch 1005/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1527 - mae: 0.8155 - val_loss: 0.4243 - val_mae: 0.4289\n",
      "Epoch 1006/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1801 - mae: 0.8163 - val_loss: 0.4243 - val_mae: 0.4289\n",
      "Epoch 1007/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1505 - mae: 0.8103 - val_loss: 0.4243 - val_mae: 0.4288\n",
      "Epoch 1008/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0853 - mae: 0.7923 - val_loss: 0.4244 - val_mae: 0.4288\n",
      "Epoch 1009/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0293 - mae: 0.7536 - val_loss: 0.4243 - val_mae: 0.4288\n",
      "Epoch 1010/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1817 - mae: 0.8417 - val_loss: 0.4244 - val_mae: 0.4288\n",
      "Epoch 1011/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.0887 - mae: 0.7752 - val_loss: 0.4244 - val_mae: 0.4288\n",
      "Epoch 1012/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1046 - mae: 0.8200 - val_loss: 0.4245 - val_mae: 0.4288\n",
      "Epoch 1013/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1289 - mae: 0.7996 - val_loss: 0.4244 - val_mae: 0.4288\n",
      "Epoch 1014/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0895 - mae: 0.7785 - val_loss: 0.4244 - val_mae: 0.4288\n",
      "Epoch 1015/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1380 - mae: 0.8106 - val_loss: 0.4244 - val_mae: 0.4288\n",
      "Epoch 1016/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0429 - mae: 0.7852 - val_loss: 0.4245 - val_mae: 0.4288\n",
      "Epoch 1017/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.9941 - mae: 0.7205 - val_loss: 0.4245 - val_mae: 0.4288\n",
      "Epoch 1018/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1166 - mae: 0.7801 - val_loss: 0.4245 - val_mae: 0.4288\n",
      "Epoch 1019/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0415 - mae: 0.7723 - val_loss: 0.4244 - val_mae: 0.4287\n",
      "Epoch 1020/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1005 - mae: 0.7853 - val_loss: 0.4245 - val_mae: 0.4287\n",
      "Epoch 1021/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0832 - mae: 0.7732 - val_loss: 0.4246 - val_mae: 0.4287\n",
      "Epoch 1022/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0663 - mae: 0.7742 - val_loss: 0.4246 - val_mae: 0.4287\n",
      "Epoch 1023/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0524 - mae: 0.7770 - val_loss: 0.4246 - val_mae: 0.4287\n",
      "Epoch 1024/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0727 - mae: 0.7618 - val_loss: 0.4244 - val_mae: 0.4286\n",
      "Epoch 1025/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1132 - mae: 0.8114 - val_loss: 0.4243 - val_mae: 0.4286\n",
      "Epoch 1026/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.1304 - mae: 0.7894 - val_loss: 0.4242 - val_mae: 0.4285\n",
      "Epoch 1027/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1798 - mae: 0.8199 - val_loss: 0.4242 - val_mae: 0.4285\n",
      "Epoch 1028/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1277 - mae: 0.7946 - val_loss: 0.4242 - val_mae: 0.4285\n",
      "Epoch 1029/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1623 - mae: 0.8020 - val_loss: 0.4242 - val_mae: 0.4285\n",
      "Epoch 1030/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1205 - mae: 0.7875 - val_loss: 0.4242 - val_mae: 0.4285\n",
      "Epoch 1031/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0366 - mae: 0.7783 - val_loss: 0.4242 - val_mae: 0.4285\n",
      "Epoch 1032/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.2039 - mae: 0.8451 - val_loss: 0.4242 - val_mae: 0.4285\n",
      "Epoch 1033/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.0852 - mae: 0.7820 - val_loss: 0.4241 - val_mae: 0.4285\n",
      "Epoch 1034/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0886 - mae: 0.7731 - val_loss: 0.4240 - val_mae: 0.4285\n",
      "Epoch 1035/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1268 - mae: 0.8006 - val_loss: 0.4238 - val_mae: 0.4284\n",
      "Epoch 1036/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.0787 - mae: 0.7793 - val_loss: 0.4238 - val_mae: 0.4284\n",
      "Epoch 1037/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.0813 - mae: 0.7815 - val_loss: 0.4238 - val_mae: 0.4285\n",
      "Epoch 1038/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.1568 - mae: 0.8185 - val_loss: 0.4238 - val_mae: 0.4285\n",
      "Epoch 1039/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0593 - mae: 0.7887 - val_loss: 0.4237 - val_mae: 0.4285\n",
      "Epoch 1040/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.0453 - mae: 0.7716 - val_loss: 0.4237 - val_mae: 0.4285\n",
      "Epoch 1041/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0094 - mae: 0.7533 - val_loss: 0.4237 - val_mae: 0.4285\n",
      "Epoch 1042/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.0839 - mae: 0.7639 - val_loss: 0.4237 - val_mae: 0.4285\n",
      "Epoch 1043/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0857 - mae: 0.7765 - val_loss: 0.4236 - val_mae: 0.4285\n",
      "Epoch 1044/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0356 - mae: 0.7735 - val_loss: 0.4235 - val_mae: 0.4285\n",
      "Epoch 1045/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0694 - mae: 0.7717 - val_loss: 0.4235 - val_mae: 0.4285\n",
      "Epoch 1046/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1223 - mae: 0.8186 - val_loss: 0.4234 - val_mae: 0.4285\n",
      "Epoch 1047/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1025 - mae: 0.7942 - val_loss: 0.4234 - val_mae: 0.4285\n",
      "Epoch 1048/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.9738 - mae: 0.7431 - val_loss: 0.4232 - val_mae: 0.4284\n",
      "Epoch 1049/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1184 - mae: 0.8000 - val_loss: 0.4232 - val_mae: 0.4284\n",
      "Epoch 1050/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0425 - mae: 0.7611 - val_loss: 0.4232 - val_mae: 0.4285\n",
      "Epoch 1051/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1294 - mae: 0.8134 - val_loss: 0.4231 - val_mae: 0.4284\n",
      "Epoch 1052/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0868 - mae: 0.7930 - val_loss: 0.4230 - val_mae: 0.4284\n",
      "Epoch 1053/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2207 - mae: 0.8348 - val_loss: 0.4230 - val_mae: 0.4284\n",
      "Epoch 1054/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0195 - mae: 0.7392 - val_loss: 0.4229 - val_mae: 0.4284\n",
      "Epoch 1055/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1235 - mae: 0.7979 - val_loss: 0.4228 - val_mae: 0.4283\n",
      "Epoch 1056/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1206 - mae: 0.8195 - val_loss: 0.4227 - val_mae: 0.4283\n",
      "Epoch 1057/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.0238 - mae: 0.7443 - val_loss: 0.4227 - val_mae: 0.4284\n",
      "Epoch 1058/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0706 - mae: 0.7829 - val_loss: 0.4226 - val_mae: 0.4283\n",
      "Epoch 1059/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2175 - mae: 0.8421 - val_loss: 0.4226 - val_mae: 0.4284\n",
      "Epoch 1060/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1458 - mae: 0.8237 - val_loss: 0.4226 - val_mae: 0.4283\n",
      "Epoch 1061/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0139 - mae: 0.7485 - val_loss: 0.4225 - val_mae: 0.4283\n",
      "Epoch 1062/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0065 - mae: 0.7619 - val_loss: 0.4225 - val_mae: 0.4283\n",
      "Epoch 1063/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0456 - mae: 0.7672 - val_loss: 0.4225 - val_mae: 0.4283\n",
      "Epoch 1064/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0135 - mae: 0.7585 - val_loss: 0.4225 - val_mae: 0.4284\n",
      "Epoch 1065/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0605 - mae: 0.7597 - val_loss: 0.4223 - val_mae: 0.4283\n",
      "Epoch 1066/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.0805 - mae: 0.7858 - val_loss: 0.4222 - val_mae: 0.4282\n",
      "Epoch 1067/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0388 - mae: 0.7482 - val_loss: 0.4221 - val_mae: 0.4282\n",
      "Epoch 1068/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1105 - mae: 0.7887 - val_loss: 0.4221 - val_mae: 0.4283\n",
      "Epoch 1069/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0707 - mae: 0.7716 - val_loss: 0.4220 - val_mae: 0.4282\n",
      "Epoch 1070/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0394 - mae: 0.7516 - val_loss: 0.4221 - val_mae: 0.4283\n",
      "Epoch 1071/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1937 - mae: 0.8437 - val_loss: 0.4220 - val_mae: 0.4283\n",
      "Epoch 1072/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.0129 - mae: 0.7707 - val_loss: 0.4220 - val_mae: 0.4283\n",
      "Epoch 1073/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1292 - mae: 0.8229 - val_loss: 0.4220 - val_mae: 0.4283\n",
      "Epoch 1074/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0349 - mae: 0.7545 - val_loss: 0.4219 - val_mae: 0.4283\n",
      "Epoch 1075/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.1625 - mae: 0.7963 - val_loss: 0.4219 - val_mae: 0.4284\n",
      "Epoch 1076/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0423 - mae: 0.7406 - val_loss: 0.4218 - val_mae: 0.4283\n",
      "Epoch 1077/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1746 - mae: 0.8195 - val_loss: 0.4218 - val_mae: 0.4283\n",
      "Epoch 1078/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1174 - mae: 0.7864 - val_loss: 0.4215 - val_mae: 0.4282\n",
      "Epoch 1079/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1739 - mae: 0.8337 - val_loss: 0.4215 - val_mae: 0.4282\n",
      "Epoch 1080/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1689 - mae: 0.8291 - val_loss: 0.4214 - val_mae: 0.4282\n",
      "Epoch 1081/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0816 - mae: 0.7601 - val_loss: 0.4214 - val_mae: 0.4282\n",
      "Epoch 1082/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1110 - mae: 0.8010 - val_loss: 0.4212 - val_mae: 0.4281\n",
      "Epoch 1083/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1497 - mae: 0.8012 - val_loss: 0.4212 - val_mae: 0.4281\n",
      "Epoch 1084/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.0966 - mae: 0.8061 - val_loss: 0.4212 - val_mae: 0.4281\n",
      "Epoch 1085/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0407 - mae: 0.7680 - val_loss: 0.4211 - val_mae: 0.4281\n",
      "Epoch 1086/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1190 - mae: 0.7975 - val_loss: 0.4210 - val_mae: 0.4281\n",
      "Epoch 1087/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0588 - mae: 0.7668 - val_loss: 0.4209 - val_mae: 0.4281\n",
      "Epoch 1088/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0648 - mae: 0.7846 - val_loss: 0.4210 - val_mae: 0.4281\n",
      "Epoch 1089/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1128 - mae: 0.8019 - val_loss: 0.4208 - val_mae: 0.4280\n",
      "Epoch 1090/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0594 - mae: 0.7599 - val_loss: 0.4207 - val_mae: 0.4280\n",
      "Epoch 1091/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1645 - mae: 0.8327 - val_loss: 0.4206 - val_mae: 0.4280\n",
      "Epoch 1092/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0295 - mae: 0.7359 - val_loss: 0.4206 - val_mae: 0.4280\n",
      "Epoch 1093/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 1.0517 - mae: 0.7757 - val_loss: 0.4206 - val_mae: 0.4280\n",
      "Epoch 1094/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0897 - mae: 0.7840 - val_loss: 0.4206 - val_mae: 0.4280\n",
      "Epoch 1095/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0971 - mae: 0.7839 - val_loss: 0.4205 - val_mae: 0.4280\n",
      "Epoch 1096/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0762 - mae: 0.7791 - val_loss: 0.4204 - val_mae: 0.4280\n",
      "Epoch 1097/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.0843 - mae: 0.7919 - val_loss: 0.4204 - val_mae: 0.4280\n",
      "Epoch 1098/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.1411 - mae: 0.7945 - val_loss: 0.4203 - val_mae: 0.4280\n",
      "Epoch 1099/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0434 - mae: 0.7624 - val_loss: 0.4202 - val_mae: 0.4279\n",
      "Epoch 1100/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0310 - mae: 0.7625 - val_loss: 0.4200 - val_mae: 0.4278\n",
      "Epoch 1101/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1167 - mae: 0.8093 - val_loss: 0.4199 - val_mae: 0.4278\n",
      "Epoch 1102/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1639 - mae: 0.8260 - val_loss: 0.4200 - val_mae: 0.4278\n",
      "Epoch 1103/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1105 - mae: 0.7959 - val_loss: 0.4199 - val_mae: 0.4278\n",
      "Epoch 1104/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1025 - mae: 0.8096 - val_loss: 0.4198 - val_mae: 0.4278\n",
      "Epoch 1105/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.0345 - mae: 0.7604 - val_loss: 0.4198 - val_mae: 0.4278\n",
      "Epoch 1106/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0805 - mae: 0.7797 - val_loss: 0.4198 - val_mae: 0.4278\n",
      "Epoch 1107/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.9752 - mae: 0.7221 - val_loss: 0.4197 - val_mae: 0.4278\n",
      "Epoch 1108/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0284 - mae: 0.7682 - val_loss: 0.4197 - val_mae: 0.4278\n",
      "Epoch 1109/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0641 - mae: 0.7763 - val_loss: 0.4195 - val_mae: 0.4277\n",
      "Epoch 1110/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.1044 - mae: 0.7846 - val_loss: 0.4195 - val_mae: 0.4277\n",
      "Epoch 1111/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.0615 - mae: 0.7709 - val_loss: 0.4195 - val_mae: 0.4277\n",
      "Epoch 1112/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2126 - mae: 0.8392 - val_loss: 0.4194 - val_mae: 0.4277\n",
      "Epoch 1113/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.2083 - mae: 0.8388 - val_loss: 0.4193 - val_mae: 0.4277\n",
      "Epoch 1114/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0649 - mae: 0.7771 - val_loss: 0.4193 - val_mae: 0.4277\n",
      "Epoch 1115/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0116 - mae: 0.7222 - val_loss: 0.4193 - val_mae: 0.4277\n",
      "Epoch 1116/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0066 - mae: 0.7617 - val_loss: 0.4192 - val_mae: 0.4276\n",
      "Epoch 1117/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0311 - mae: 0.7452 - val_loss: 0.4191 - val_mae: 0.4276\n",
      "Epoch 1118/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1240 - mae: 0.7964 - val_loss: 0.4191 - val_mae: 0.4276\n",
      "Epoch 1119/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.0006 - mae: 0.7428 - val_loss: 0.4191 - val_mae: 0.4276\n",
      "Epoch 1120/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.9547 - mae: 0.7113 - val_loss: 0.4188 - val_mae: 0.4274\n",
      "Epoch 1121/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0895 - mae: 0.7969 - val_loss: 0.4187 - val_mae: 0.4274\n",
      "Epoch 1122/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1155 - mae: 0.8109 - val_loss: 0.4185 - val_mae: 0.4273\n",
      "Epoch 1123/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1154 - mae: 0.7984 - val_loss: 0.4183 - val_mae: 0.4272\n",
      "Epoch 1124/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1339 - mae: 0.8047 - val_loss: 0.4183 - val_mae: 0.4272\n",
      "Epoch 1125/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0871 - mae: 0.7710 - val_loss: 0.4183 - val_mae: 0.4272\n",
      "Epoch 1126/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.0908 - mae: 0.7784 - val_loss: 0.4181 - val_mae: 0.4271\n",
      "Epoch 1127/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0553 - mae: 0.7764 - val_loss: 0.4182 - val_mae: 0.4272\n",
      "Epoch 1128/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.9604 - mae: 0.7143 - val_loss: 0.4180 - val_mae: 0.4271\n",
      "Epoch 1129/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.9714 - mae: 0.7149 - val_loss: 0.4179 - val_mae: 0.4271\n",
      "Epoch 1130/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0570 - mae: 0.7845 - val_loss: 0.4178 - val_mae: 0.4270\n",
      "Epoch 1131/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0341 - mae: 0.7533 - val_loss: 0.4178 - val_mae: 0.4271\n",
      "Epoch 1132/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.9945 - mae: 0.7173 - val_loss: 0.4177 - val_mae: 0.4271\n",
      "Epoch 1133/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0585 - mae: 0.7712 - val_loss: 0.4177 - val_mae: 0.4271\n",
      "Epoch 1134/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0260 - mae: 0.7487 - val_loss: 0.4178 - val_mae: 0.4271\n",
      "Epoch 1135/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.0596 - mae: 0.7589 - val_loss: 0.4176 - val_mae: 0.4270\n",
      "Epoch 1136/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0986 - mae: 0.7951 - val_loss: 0.4175 - val_mae: 0.4270\n",
      "Epoch 1137/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1369 - mae: 0.8309 - val_loss: 0.4175 - val_mae: 0.4270\n",
      "Epoch 1138/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0213 - mae: 0.7419 - val_loss: 0.4173 - val_mae: 0.4269\n",
      "Epoch 1139/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0453 - mae: 0.7806 - val_loss: 0.4172 - val_mae: 0.4269\n",
      "Epoch 1140/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0951 - mae: 0.7767 - val_loss: 0.4171 - val_mae: 0.4268\n",
      "Epoch 1141/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.2432 - mae: 0.8555 - val_loss: 0.4170 - val_mae: 0.4268\n",
      "Epoch 1142/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0796 - mae: 0.7882 - val_loss: 0.4169 - val_mae: 0.4267\n",
      "Epoch 1143/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0213 - mae: 0.7477 - val_loss: 0.4167 - val_mae: 0.4266\n",
      "Epoch 1144/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.0600 - mae: 0.7727 - val_loss: 0.4167 - val_mae: 0.4266\n",
      "Epoch 1145/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1198 - mae: 0.7923 - val_loss: 0.4166 - val_mae: 0.4266\n",
      "Epoch 1146/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0044 - mae: 0.7304 - val_loss: 0.4166 - val_mae: 0.4266\n",
      "Epoch 1147/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0355 - mae: 0.7336 - val_loss: 0.4165 - val_mae: 0.4266\n",
      "Epoch 1148/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.0994 - mae: 0.8139 - val_loss: 0.4166 - val_mae: 0.4266\n",
      "Epoch 1149/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.9881 - mae: 0.7391 - val_loss: 0.4165 - val_mae: 0.4266\n",
      "Epoch 1150/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1210 - mae: 0.7946 - val_loss: 0.4163 - val_mae: 0.4265\n",
      "Epoch 1151/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.9310 - mae: 0.7004 - val_loss: 0.4164 - val_mae: 0.4265\n",
      "Epoch 1152/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1084 - mae: 0.7911 - val_loss: 0.4163 - val_mae: 0.4265\n",
      "Epoch 1153/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1075 - mae: 0.8030 - val_loss: 0.4164 - val_mae: 0.4266\n",
      "Epoch 1154/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0120 - mae: 0.7600 - val_loss: 0.4163 - val_mae: 0.4265\n",
      "Epoch 1155/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0154 - mae: 0.7359 - val_loss: 0.4162 - val_mae: 0.4265\n",
      "Epoch 1156/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0784 - mae: 0.7815 - val_loss: 0.4161 - val_mae: 0.4265\n",
      "Epoch 1157/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0021 - mae: 0.7350 - val_loss: 0.4160 - val_mae: 0.4264\n",
      "Epoch 1158/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0403 - mae: 0.7806 - val_loss: 0.4160 - val_mae: 0.4264\n",
      "Epoch 1159/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1155 - mae: 0.8058 - val_loss: 0.4159 - val_mae: 0.4264\n",
      "Epoch 1160/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.9679 - mae: 0.7106 - val_loss: 0.4158 - val_mae: 0.4263\n",
      "Epoch 1161/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0498 - mae: 0.7700 - val_loss: 0.4157 - val_mae: 0.4263\n",
      "Epoch 1162/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0219 - mae: 0.7509 - val_loss: 0.4156 - val_mae: 0.4262\n",
      "Epoch 1163/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.1314 - mae: 0.7853 - val_loss: 0.4156 - val_mae: 0.4263\n",
      "Epoch 1164/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1274 - mae: 0.7979 - val_loss: 0.4155 - val_mae: 0.4262\n",
      "Epoch 1165/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.9630 - mae: 0.7317 - val_loss: 0.4155 - val_mae: 0.4262\n",
      "Epoch 1166/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0025 - mae: 0.7448 - val_loss: 0.4153 - val_mae: 0.4261\n",
      "Epoch 1167/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0348 - mae: 0.7519 - val_loss: 0.4153 - val_mae: 0.4261\n",
      "Epoch 1168/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0019 - mae: 0.7647 - val_loss: 0.4153 - val_mae: 0.4261\n",
      "Epoch 1169/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0437 - mae: 0.7750 - val_loss: 0.4153 - val_mae: 0.4261\n",
      "Epoch 1170/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.9930 - mae: 0.7451 - val_loss: 0.4151 - val_mae: 0.4260\n",
      "Epoch 1171/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.9482 - mae: 0.7202 - val_loss: 0.4151 - val_mae: 0.4260\n",
      "Epoch 1172/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0811 - mae: 0.7869 - val_loss: 0.4150 - val_mae: 0.4260\n",
      "Epoch 1173/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2168 - mae: 0.8415 - val_loss: 0.4150 - val_mae: 0.4259\n",
      "Epoch 1174/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0560 - mae: 0.7711 - val_loss: 0.4148 - val_mae: 0.4259\n",
      "Epoch 1175/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0371 - mae: 0.7494 - val_loss: 0.4149 - val_mae: 0.4259\n",
      "Epoch 1176/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0550 - mae: 0.7980 - val_loss: 0.4148 - val_mae: 0.4259\n",
      "Epoch 1177/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.0118 - mae: 0.7436 - val_loss: 0.4148 - val_mae: 0.4259\n",
      "Epoch 1178/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0861 - mae: 0.7976 - val_loss: 0.4147 - val_mae: 0.4259\n",
      "Epoch 1179/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0441 - mae: 0.7463 - val_loss: 0.4146 - val_mae: 0.4258\n",
      "Epoch 1180/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1168 - mae: 0.7880 - val_loss: 0.4144 - val_mae: 0.4257\n",
      "Epoch 1181/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0806 - mae: 0.7752 - val_loss: 0.4144 - val_mae: 0.4257\n",
      "Epoch 1182/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1580 - mae: 0.8234 - val_loss: 0.4144 - val_mae: 0.4257\n",
      "Epoch 1183/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0238 - mae: 0.7436 - val_loss: 0.4144 - val_mae: 0.4257\n",
      "Epoch 1184/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0251 - mae: 0.7547 - val_loss: 0.4144 - val_mae: 0.4257\n",
      "Epoch 1185/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0923 - mae: 0.7918 - val_loss: 0.4143 - val_mae: 0.4257\n",
      "Epoch 1186/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0180 - mae: 0.7630 - val_loss: 0.4142 - val_mae: 0.4256\n",
      "Epoch 1187/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.9759 - mae: 0.7428 - val_loss: 0.4141 - val_mae: 0.4256\n",
      "Epoch 1188/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0931 - mae: 0.8024 - val_loss: 0.4141 - val_mae: 0.4256\n",
      "Epoch 1189/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.1499 - mae: 0.8220 - val_loss: 0.4141 - val_mae: 0.4256\n",
      "Epoch 1190/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1217 - mae: 0.8104 - val_loss: 0.4142 - val_mae: 0.4256\n",
      "Epoch 1191/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0621 - mae: 0.7817 - val_loss: 0.4142 - val_mae: 0.4256\n",
      "Epoch 1192/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0559 - mae: 0.7787 - val_loss: 0.4141 - val_mae: 0.4256\n",
      "Epoch 1193/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0748 - mae: 0.7835 - val_loss: 0.4140 - val_mae: 0.4255\n",
      "Epoch 1194/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0382 - mae: 0.7695 - val_loss: 0.4139 - val_mae: 0.4255\n",
      "Epoch 1195/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.9930 - mae: 0.7367 - val_loss: 0.4137 - val_mae: 0.4254\n",
      "Epoch 1196/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0050 - mae: 0.7473 - val_loss: 0.4137 - val_mae: 0.4254\n",
      "Epoch 1197/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0948 - mae: 0.7916 - val_loss: 0.4138 - val_mae: 0.4255\n",
      "Epoch 1198/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0819 - mae: 0.7849 - val_loss: 0.4137 - val_mae: 0.4254\n",
      "Epoch 1199/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0170 - mae: 0.7379 - val_loss: 0.4134 - val_mae: 0.4253\n",
      "Epoch 1200/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.1206 - mae: 0.7973 - val_loss: 0.4134 - val_mae: 0.4253\n",
      "Epoch 1201/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1190 - mae: 0.8105 - val_loss: 0.4134 - val_mae: 0.4253\n",
      "Epoch 1202/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0521 - mae: 0.7945 - val_loss: 0.4134 - val_mae: 0.4253\n",
      "Epoch 1203/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0986 - mae: 0.7873 - val_loss: 0.4133 - val_mae: 0.4252\n",
      "Epoch 1204/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0454 - mae: 0.7643 - val_loss: 0.4132 - val_mae: 0.4252\n",
      "Epoch 1205/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0415 - mae: 0.7627 - val_loss: 0.4133 - val_mae: 0.4252\n",
      "Epoch 1206/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1178 - mae: 0.7997 - val_loss: 0.4133 - val_mae: 0.4253\n",
      "Epoch 1207/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1152 - mae: 0.7780 - val_loss: 0.4131 - val_mae: 0.4252\n",
      "Epoch 1208/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.1166 - mae: 0.8094 - val_loss: 0.4131 - val_mae: 0.4251\n",
      "Epoch 1209/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1326 - mae: 0.8130 - val_loss: 0.4131 - val_mae: 0.4252\n",
      "Epoch 1210/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.9763 - mae: 0.7142 - val_loss: 0.4131 - val_mae: 0.4252\n",
      "Epoch 1211/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.9912 - mae: 0.7442 - val_loss: 0.4130 - val_mae: 0.4251\n",
      "Epoch 1212/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0713 - mae: 0.7856 - val_loss: 0.4130 - val_mae: 0.4251\n",
      "Epoch 1213/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.0624 - mae: 0.7613 - val_loss: 0.4131 - val_mae: 0.4252\n",
      "Epoch 1214/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0697 - mae: 0.7696 - val_loss: 0.4131 - val_mae: 0.4252\n",
      "Epoch 1215/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0463 - mae: 0.7540 - val_loss: 0.4130 - val_mae: 0.4252\n",
      "Epoch 1216/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.9182 - mae: 0.6973 - val_loss: 0.4128 - val_mae: 0.4250\n",
      "Epoch 1217/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0687 - mae: 0.7614 - val_loss: 0.4126 - val_mae: 0.4249\n",
      "Epoch 1218/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.9966 - mae: 0.7421 - val_loss: 0.4126 - val_mae: 0.4250\n",
      "Epoch 1219/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.0239 - mae: 0.7654 - val_loss: 0.4127 - val_mae: 0.4250\n",
      "Epoch 1220/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0238 - mae: 0.7681 - val_loss: 0.4127 - val_mae: 0.4250\n",
      "Epoch 1221/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0462 - mae: 0.7710 - val_loss: 0.4126 - val_mae: 0.4250\n",
      "Epoch 1222/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.9700 - mae: 0.7312 - val_loss: 0.4127 - val_mae: 0.4250\n",
      "Epoch 1223/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0562 - mae: 0.7729 - val_loss: 0.4125 - val_mae: 0.4250\n",
      "Epoch 1224/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0874 - mae: 0.7845 - val_loss: 0.4125 - val_mae: 0.4249\n",
      "Epoch 1225/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0713 - mae: 0.7869 - val_loss: 0.4125 - val_mae: 0.4249\n",
      "Epoch 1226/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0141 - mae: 0.7514 - val_loss: 0.4125 - val_mae: 0.4249\n",
      "Epoch 1227/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.0766 - mae: 0.7985 - val_loss: 0.4125 - val_mae: 0.4249\n",
      "Epoch 1228/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1426 - mae: 0.8100 - val_loss: 0.4124 - val_mae: 0.4249\n",
      "Epoch 1229/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0337 - mae: 0.7590 - val_loss: 0.4123 - val_mae: 0.4249\n",
      "Epoch 1230/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.9874 - mae: 0.7490 - val_loss: 0.4122 - val_mae: 0.4248\n",
      "Epoch 1231/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0829 - mae: 0.7832 - val_loss: 0.4121 - val_mae: 0.4247\n",
      "Epoch 1232/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0589 - mae: 0.7728 - val_loss: 0.4120 - val_mae: 0.4247\n",
      "Epoch 1233/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0805 - mae: 0.7897 - val_loss: 0.4121 - val_mae: 0.4248\n",
      "Epoch 1234/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.0806 - mae: 0.7572 - val_loss: 0.4121 - val_mae: 0.4247\n",
      "Epoch 1235/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1493 - mae: 0.8226 - val_loss: 0.4121 - val_mae: 0.4248\n",
      "Epoch 1236/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0841 - mae: 0.7972 - val_loss: 0.4121 - val_mae: 0.4248\n",
      "Epoch 1237/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.2073 - mae: 0.8521 - val_loss: 0.4120 - val_mae: 0.4247\n",
      "Epoch 1238/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0276 - mae: 0.7627 - val_loss: 0.4120 - val_mae: 0.4247\n",
      "Epoch 1239/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1047 - mae: 0.7800 - val_loss: 0.4118 - val_mae: 0.4246\n",
      "Epoch 1240/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1993 - mae: 0.8539 - val_loss: 0.4117 - val_mae: 0.4245\n",
      "Epoch 1241/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0233 - mae: 0.7502 - val_loss: 0.4116 - val_mae: 0.4245\n",
      "Epoch 1242/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.0745 - mae: 0.7829 - val_loss: 0.4116 - val_mae: 0.4245\n",
      "Epoch 1243/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.0942 - mae: 0.7730 - val_loss: 0.4117 - val_mae: 0.4246\n",
      "Epoch 1244/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0980 - mae: 0.7853 - val_loss: 0.4116 - val_mae: 0.4245\n",
      "Epoch 1245/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.9954 - mae: 0.7316 - val_loss: 0.4116 - val_mae: 0.4245\n",
      "Epoch 1246/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.9741 - mae: 0.7434 - val_loss: 0.4115 - val_mae: 0.4245\n",
      "Epoch 1247/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.9458 - mae: 0.7225 - val_loss: 0.4115 - val_mae: 0.4244\n",
      "Epoch 1248/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0007 - mae: 0.7685 - val_loss: 0.4115 - val_mae: 0.4244\n",
      "Epoch 1249/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0495 - mae: 0.7630 - val_loss: 0.4115 - val_mae: 0.4245\n",
      "Epoch 1250/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.9843 - mae: 0.7387 - val_loss: 0.4115 - val_mae: 0.4245\n",
      "Epoch 1251/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0652 - mae: 0.7898 - val_loss: 0.4115 - val_mae: 0.4245\n",
      "Epoch 1252/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.9355 - mae: 0.7125 - val_loss: 0.4114 - val_mae: 0.4244\n",
      "Epoch 1253/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0401 - mae: 0.7642 - val_loss: 0.4114 - val_mae: 0.4244\n",
      "Epoch 1254/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.1000 - mae: 0.8197 - val_loss: 0.4114 - val_mae: 0.4245\n",
      "Epoch 1255/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0852 - mae: 0.7814 - val_loss: 0.4115 - val_mae: 0.4245\n",
      "Epoch 1256/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.9473 - mae: 0.7212 - val_loss: 0.4113 - val_mae: 0.4244\n",
      "Epoch 1257/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.9850 - mae: 0.7283 - val_loss: 0.4113 - val_mae: 0.4244\n",
      "Epoch 1258/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.9959 - mae: 0.7454 - val_loss: 0.4112 - val_mae: 0.4243\n",
      "Epoch 1259/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0043 - mae: 0.7497 - val_loss: 0.4112 - val_mae: 0.4243\n",
      "Epoch 1260/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0968 - mae: 0.8044 - val_loss: 0.4111 - val_mae: 0.4243\n",
      "Epoch 1261/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0467 - mae: 0.7736 - val_loss: 0.4110 - val_mae: 0.4242\n",
      "Epoch 1262/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.9706 - mae: 0.7358 - val_loss: 0.4110 - val_mae: 0.4242\n",
      "Epoch 1263/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0097 - mae: 0.7641 - val_loss: 0.4110 - val_mae: 0.4242\n",
      "Epoch 1264/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0256 - mae: 0.7465 - val_loss: 0.4108 - val_mae: 0.4241\n",
      "Epoch 1265/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.9900 - mae: 0.7380 - val_loss: 0.4108 - val_mae: 0.4241\n",
      "Epoch 1266/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0292 - mae: 0.7451 - val_loss: 0.4107 - val_mae: 0.4240\n",
      "Epoch 1267/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.9555 - mae: 0.7048 - val_loss: 0.4107 - val_mae: 0.4240\n",
      "Epoch 1268/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1163 - mae: 0.8253 - val_loss: 0.4107 - val_mae: 0.4241\n",
      "Epoch 1269/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0433 - mae: 0.7730 - val_loss: 0.4107 - val_mae: 0.4241\n",
      "Epoch 1270/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.9627 - mae: 0.7280 - val_loss: 0.4107 - val_mae: 0.4241\n",
      "Epoch 1271/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0932 - mae: 0.7755 - val_loss: 0.4107 - val_mae: 0.4240\n",
      "Epoch 1272/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0122 - mae: 0.7441 - val_loss: 0.4106 - val_mae: 0.4240\n",
      "Epoch 1273/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.9820 - mae: 0.7248 - val_loss: 0.4106 - val_mae: 0.4240\n",
      "Epoch 1274/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.9835 - mae: 0.7402 - val_loss: 0.4105 - val_mae: 0.4240\n",
      "Epoch 1275/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.9891 - mae: 0.7442 - val_loss: 0.4104 - val_mae: 0.4239\n",
      "Epoch 1276/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0575 - mae: 0.7641 - val_loss: 0.4104 - val_mae: 0.4239\n",
      "Epoch 1277/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.9437 - mae: 0.6891 - val_loss: 0.4103 - val_mae: 0.4238\n",
      "Epoch 1278/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0324 - mae: 0.7545 - val_loss: 0.4102 - val_mae: 0.4238\n",
      "Epoch 1279/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0150 - mae: 0.7667 - val_loss: 0.4102 - val_mae: 0.4238\n",
      "Epoch 1280/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0004 - mae: 0.7369 - val_loss: 0.4102 - val_mae: 0.4238\n",
      "Epoch 1281/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0696 - mae: 0.7592 - val_loss: 0.4102 - val_mae: 0.4238\n",
      "Epoch 1282/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.9367 - mae: 0.7161 - val_loss: 0.4102 - val_mae: 0.4238\n",
      "Epoch 1283/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0666 - mae: 0.7782 - val_loss: 0.4101 - val_mae: 0.4238\n",
      "Epoch 1284/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.0222 - mae: 0.7586 - val_loss: 0.4100 - val_mae: 0.4237\n",
      "Epoch 1285/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0852 - mae: 0.7877 - val_loss: 0.4100 - val_mae: 0.4237\n",
      "Epoch 1286/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1141 - mae: 0.8121 - val_loss: 0.4100 - val_mae: 0.4237\n",
      "Epoch 1287/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.9905 - mae: 0.7476 - val_loss: 0.4099 - val_mae: 0.4237\n",
      "Epoch 1288/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0363 - mae: 0.7525 - val_loss: 0.4098 - val_mae: 0.4236\n",
      "Epoch 1289/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0337 - mae: 0.7616 - val_loss: 0.4097 - val_mae: 0.4236\n",
      "Epoch 1290/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1381 - mae: 0.8270 - val_loss: 0.4097 - val_mae: 0.4235\n",
      "Epoch 1291/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1496 - mae: 0.8226 - val_loss: 0.4097 - val_mae: 0.4236\n",
      "Epoch 1292/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1267 - mae: 0.8051 - val_loss: 0.4097 - val_mae: 0.4235\n",
      "Epoch 1293/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0812 - mae: 0.7763 - val_loss: 0.4096 - val_mae: 0.4235\n",
      "Epoch 1294/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0746 - mae: 0.7878 - val_loss: 0.4096 - val_mae: 0.4235\n",
      "Epoch 1295/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.0768 - mae: 0.7769 - val_loss: 0.4097 - val_mae: 0.4236\n",
      "Epoch 1296/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0423 - mae: 0.7773 - val_loss: 0.4097 - val_mae: 0.4236\n",
      "Epoch 1297/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1233 - mae: 0.8005 - val_loss: 0.4097 - val_mae: 0.4236\n",
      "Epoch 1298/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.9611 - mae: 0.7011 - val_loss: 0.4097 - val_mae: 0.4236\n",
      "Epoch 1299/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0355 - mae: 0.7684 - val_loss: 0.4097 - val_mae: 0.4236\n",
      "Epoch 1300/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0279 - mae: 0.7633 - val_loss: 0.4096 - val_mae: 0.4235\n",
      "Epoch 1301/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0924 - mae: 0.7946 - val_loss: 0.4096 - val_mae: 0.4235\n",
      "Epoch 1302/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0305 - mae: 0.7907 - val_loss: 0.4095 - val_mae: 0.4235\n",
      "Epoch 1303/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1470 - mae: 0.8227 - val_loss: 0.4094 - val_mae: 0.4234\n",
      "Epoch 1304/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0796 - mae: 0.7837 - val_loss: 0.4094 - val_mae: 0.4234\n",
      "Epoch 1305/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0169 - mae: 0.7469 - val_loss: 0.4095 - val_mae: 0.4235\n",
      "Epoch 1306/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.0645 - mae: 0.7713 - val_loss: 0.4095 - val_mae: 0.4235\n",
      "Epoch 1307/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0174 - mae: 0.7496 - val_loss: 0.4094 - val_mae: 0.4234\n",
      "Epoch 1308/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1172 - mae: 0.8186 - val_loss: 0.4094 - val_mae: 0.4234\n",
      "Epoch 1309/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0141 - mae: 0.7486 - val_loss: 0.4094 - val_mae: 0.4234\n",
      "Epoch 1310/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.9966 - mae: 0.7322 - val_loss: 0.4093 - val_mae: 0.4234\n",
      "Epoch 1311/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0033 - mae: 0.7529 - val_loss: 0.4093 - val_mae: 0.4234\n",
      "Epoch 1312/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1295 - mae: 0.8070 - val_loss: 0.4093 - val_mae: 0.4234\n",
      "Epoch 1313/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.9868 - mae: 0.7363 - val_loss: 0.4093 - val_mae: 0.4234\n",
      "Epoch 1314/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0690 - mae: 0.7820 - val_loss: 0.4093 - val_mae: 0.4234\n",
      "Epoch 1315/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1062 - mae: 0.7966 - val_loss: 0.4092 - val_mae: 0.4234\n",
      "Epoch 1316/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.9866 - mae: 0.7206 - val_loss: 0.4092 - val_mae: 0.4234\n",
      "Epoch 1317/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0106 - mae: 0.7508 - val_loss: 0.4092 - val_mae: 0.4233\n",
      "Epoch 1318/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0919 - mae: 0.7971 - val_loss: 0.4092 - val_mae: 0.4234\n",
      "Epoch 1319/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1451 - mae: 0.8310 - val_loss: 0.4092 - val_mae: 0.4234\n",
      "Epoch 1320/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0391 - mae: 0.7783 - val_loss: 0.4093 - val_mae: 0.4234\n",
      "Epoch 1321/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.9256 - mae: 0.6934 - val_loss: 0.4092 - val_mae: 0.4233\n",
      "Epoch 1322/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0409 - mae: 0.7745 - val_loss: 0.4091 - val_mae: 0.4233\n",
      "Epoch 1323/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0323 - mae: 0.7321 - val_loss: 0.4091 - val_mae: 0.4233\n",
      "Epoch 1324/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0297 - mae: 0.7564 - val_loss: 0.4090 - val_mae: 0.4232\n",
      "Epoch 1325/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0204 - mae: 0.7672 - val_loss: 0.4090 - val_mae: 0.4232\n",
      "Epoch 1326/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.9920 - mae: 0.7416 - val_loss: 0.4090 - val_mae: 0.4232\n",
      "Epoch 1327/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.0214 - mae: 0.7444 - val_loss: 0.4090 - val_mae: 0.4232\n",
      "Epoch 1328/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0979 - mae: 0.7864 - val_loss: 0.4089 - val_mae: 0.4231\n",
      "Epoch 1329/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0772 - mae: 0.7752 - val_loss: 0.4088 - val_mae: 0.4231\n",
      "Epoch 1330/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.9846 - mae: 0.7467 - val_loss: 0.4088 - val_mae: 0.4231\n",
      "Epoch 1331/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.9946 - mae: 0.7335 - val_loss: 0.4088 - val_mae: 0.4231\n",
      "Epoch 1332/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0109 - mae: 0.7485 - val_loss: 0.4088 - val_mae: 0.4231\n",
      "Epoch 1333/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0221 - mae: 0.7702 - val_loss: 0.4088 - val_mae: 0.4231\n",
      "Epoch 1334/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.9673 - mae: 0.7290 - val_loss: 0.4088 - val_mae: 0.4231\n",
      "Epoch 1335/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.9952 - mae: 0.7561 - val_loss: 0.4088 - val_mae: 0.4231\n",
      "Epoch 1336/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.9827 - mae: 0.7510 - val_loss: 0.4086 - val_mae: 0.4230\n",
      "Epoch 1337/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0980 - mae: 0.7940 - val_loss: 0.4085 - val_mae: 0.4229\n",
      "Epoch 1338/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.9856 - mae: 0.7248 - val_loss: 0.4085 - val_mae: 0.4229\n",
      "Epoch 1339/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.9996 - mae: 0.7472 - val_loss: 0.4086 - val_mae: 0.4230\n",
      "Epoch 1340/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.9815 - mae: 0.7608 - val_loss: 0.4086 - val_mae: 0.4230\n",
      "Epoch 1341/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.0304 - mae: 0.7725 - val_loss: 0.4086 - val_mae: 0.4230\n",
      "Epoch 1342/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0262 - mae: 0.7598 - val_loss: 0.4085 - val_mae: 0.4230\n",
      "Epoch 1343/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.0520 - mae: 0.7659 - val_loss: 0.4085 - val_mae: 0.4230\n",
      "Epoch 1344/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0389 - mae: 0.7694 - val_loss: 0.4085 - val_mae: 0.4230\n",
      "Epoch 1345/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0326 - mae: 0.7776 - val_loss: 0.4086 - val_mae: 0.4230\n",
      "Epoch 1346/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0778 - mae: 0.7865 - val_loss: 0.4086 - val_mae: 0.4230\n",
      "Epoch 1347/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0268 - mae: 0.7696 - val_loss: 0.4086 - val_mae: 0.4230\n",
      "Epoch 1348/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.9861 - mae: 0.7394 - val_loss: 0.4087 - val_mae: 0.4231\n",
      "Epoch 1349/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0142 - mae: 0.7351 - val_loss: 0.4086 - val_mae: 0.4230\n",
      "Epoch 1350/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0936 - mae: 0.8042 - val_loss: 0.4086 - val_mae: 0.4231\n",
      "Epoch 1351/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1160 - mae: 0.8020 - val_loss: 0.4086 - val_mae: 0.4230\n",
      "Epoch 1352/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1394 - mae: 0.8067 - val_loss: 0.4086 - val_mae: 0.4230\n",
      "Epoch 1353/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.9396 - mae: 0.7149 - val_loss: 0.4087 - val_mae: 0.4231\n",
      "Epoch 1354/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.9967 - mae: 0.7247 - val_loss: 0.4086 - val_mae: 0.4231\n",
      "Epoch 1355/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.9889 - mae: 0.7504 - val_loss: 0.4086 - val_mae: 0.4230\n",
      "Epoch 1356/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1254 - mae: 0.8083 - val_loss: 0.4086 - val_mae: 0.4230\n",
      "Epoch 1357/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0649 - mae: 0.7813 - val_loss: 0.4086 - val_mae: 0.4230\n",
      "Epoch 1358/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.9530 - mae: 0.7199 - val_loss: 0.4085 - val_mae: 0.4230\n",
      "Epoch 1359/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0758 - mae: 0.7985 - val_loss: 0.4085 - val_mae: 0.4230\n",
      "Epoch 1360/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0547 - mae: 0.7914 - val_loss: 0.4084 - val_mae: 0.4229\n",
      "Epoch 1361/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0349 - mae: 0.7550 - val_loss: 0.4082 - val_mae: 0.4228\n",
      "Epoch 1362/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.0730 - mae: 0.7924 - val_loss: 0.4082 - val_mae: 0.4228\n",
      "Epoch 1363/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0882 - mae: 0.7818 - val_loss: 0.4082 - val_mae: 0.4228\n",
      "Epoch 1364/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0281 - mae: 0.7556 - val_loss: 0.4082 - val_mae: 0.4227\n",
      "Epoch 1365/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.9934 - mae: 0.7375 - val_loss: 0.4081 - val_mae: 0.4227\n",
      "Epoch 1366/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.9826 - mae: 0.7469 - val_loss: 0.4082 - val_mae: 0.4228\n",
      "Epoch 1367/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.9769 - mae: 0.7442 - val_loss: 0.4082 - val_mae: 0.4228\n",
      "Epoch 1368/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 1.1112 - mae: 0.7988 - val_loss: 0.4081 - val_mae: 0.4227\n",
      "Epoch 1369/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.9615 - mae: 0.7247 - val_loss: 0.4081 - val_mae: 0.4227\n",
      "Epoch 1370/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.0325 - mae: 0.7734 - val_loss: 0.4080 - val_mae: 0.4227\n",
      "Epoch 1371/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.0108 - mae: 0.7406 - val_loss: 0.4080 - val_mae: 0.4227\n",
      "Epoch 1372/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.8896 - mae: 0.7134 - val_loss: 0.4080 - val_mae: 0.4227\n",
      "Epoch 1373/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0167 - mae: 0.7509 - val_loss: 0.4080 - val_mae: 0.4227\n",
      "Epoch 1374/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 1.0572 - mae: 0.7699 - val_loss: 0.4081 - val_mae: 0.4227\n",
      "Epoch 1375/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0368 - mae: 0.7623 - val_loss: 0.4082 - val_mae: 0.4228\n",
      "Epoch 1376/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0156 - mae: 0.7420 - val_loss: 0.4081 - val_mae: 0.4227\n",
      "Epoch 1377/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.0609 - mae: 0.7600 - val_loss: 0.4079 - val_mae: 0.4226\n",
      "Epoch 1378/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.9725 - mae: 0.7330 - val_loss: 0.4080 - val_mae: 0.4227\n",
      "Epoch 1379/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.0436 - mae: 0.7578 - val_loss: 0.4081 - val_mae: 0.4227\n",
      "Epoch 1380/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 1.1138 - mae: 0.8087 - val_loss: 0.4080 - val_mae: 0.4227\n",
      "Epoch 1381/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.9604 - mae: 0.7112 - val_loss: 0.4080 - val_mae: 0.4227\n",
      "Epoch 1382/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.0772 - mae: 0.7809 - val_loss: 0.4080 - val_mae: 0.4227\n",
      "Epoch 1383/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.0176 - mae: 0.7488 - val_loss: 0.4080 - val_mae: 0.4227\n",
      "Epoch 1384/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1221 - mae: 0.8080 - val_loss: 0.4080 - val_mae: 0.4227\n",
      "Epoch 1385/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0387 - mae: 0.7656 - val_loss: 0.4080 - val_mae: 0.4227\n",
      "Epoch 1386/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0090 - mae: 0.7430 - val_loss: 0.4079 - val_mae: 0.4226\n",
      "Epoch 1387/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.0259 - mae: 0.7546 - val_loss: 0.4079 - val_mae: 0.4226\n",
      "Epoch 1388/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.9751 - mae: 0.7337 - val_loss: 0.4078 - val_mae: 0.4225\n",
      "Epoch 1389/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.9918 - mae: 0.7518 - val_loss: 0.4078 - val_mae: 0.4226\n",
      "Epoch 1390/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0319 - mae: 0.7738 - val_loss: 0.4078 - val_mae: 0.4226\n",
      "Epoch 1391/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.9896 - mae: 0.7220 - val_loss: 0.4078 - val_mae: 0.4225\n",
      "Epoch 1392/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.9672 - mae: 0.7103 - val_loss: 0.4077 - val_mae: 0.4225\n",
      "Epoch 1393/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0052 - mae: 0.7586 - val_loss: 0.4077 - val_mae: 0.4225\n",
      "Epoch 1394/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0723 - mae: 0.7912 - val_loss: 0.4077 - val_mae: 0.4225\n",
      "Epoch 1395/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0052 - mae: 0.7550 - val_loss: 0.4076 - val_mae: 0.4225\n",
      "Epoch 1396/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.9789 - mae: 0.7371 - val_loss: 0.4076 - val_mae: 0.4224\n",
      "Epoch 1397/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.1342 - mae: 0.8177 - val_loss: 0.4076 - val_mae: 0.4224\n",
      "Epoch 1398/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1087 - mae: 0.7877 - val_loss: 0.4076 - val_mae: 0.4224\n",
      "Epoch 1399/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0329 - mae: 0.7835 - val_loss: 0.4076 - val_mae: 0.4224\n",
      "Epoch 1400/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.9944 - mae: 0.7393 - val_loss: 0.4076 - val_mae: 0.4224\n",
      "Epoch 1401/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1500 - mae: 0.8249 - val_loss: 0.4076 - val_mae: 0.4224\n",
      "Epoch 1402/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.0659 - mae: 0.7685 - val_loss: 0.4075 - val_mae: 0.4224\n",
      "Epoch 1403/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0520 - mae: 0.7704 - val_loss: 0.4074 - val_mae: 0.4223\n",
      "Epoch 1404/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0673 - mae: 0.7757 - val_loss: 0.4074 - val_mae: 0.4223\n",
      "Epoch 1405/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0073 - mae: 0.7526 - val_loss: 0.4074 - val_mae: 0.4223\n",
      "Epoch 1406/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0300 - mae: 0.7530 - val_loss: 0.4074 - val_mae: 0.4223\n",
      "Epoch 1407/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0199 - mae: 0.7399 - val_loss: 0.4075 - val_mae: 0.4224\n",
      "Epoch 1408/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0164 - mae: 0.7502 - val_loss: 0.4075 - val_mae: 0.4224\n",
      "Epoch 1409/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.9234 - mae: 0.6976 - val_loss: 0.4075 - val_mae: 0.4224\n",
      "Epoch 1410/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.9989 - mae: 0.7519 - val_loss: 0.4075 - val_mae: 0.4224\n",
      "Epoch 1411/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.0861 - mae: 0.7918 - val_loss: 0.4075 - val_mae: 0.4224\n",
      "Epoch 1412/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0503 - mae: 0.7621 - val_loss: 0.4075 - val_mae: 0.4224\n",
      "Epoch 1413/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1351 - mae: 0.8030 - val_loss: 0.4074 - val_mae: 0.4223\n",
      "Epoch 1414/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.9998 - mae: 0.7320 - val_loss: 0.4074 - val_mae: 0.4224\n",
      "Epoch 1415/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0270 - mae: 0.7614 - val_loss: 0.4074 - val_mae: 0.4224\n",
      "Epoch 1416/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.1409 - mae: 0.8245 - val_loss: 0.4074 - val_mae: 0.4224\n",
      "Epoch 1417/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0498 - mae: 0.7837 - val_loss: 0.4072 - val_mae: 0.4222\n",
      "Epoch 1418/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0496 - mae: 0.7724 - val_loss: 0.4073 - val_mae: 0.4223\n",
      "Epoch 1419/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0464 - mae: 0.7881 - val_loss: 0.4073 - val_mae: 0.4223\n",
      "Epoch 1420/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0966 - mae: 0.8004 - val_loss: 0.4074 - val_mae: 0.4223\n",
      "Epoch 1421/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0227 - mae: 0.7508 - val_loss: 0.4073 - val_mae: 0.4223\n",
      "Epoch 1422/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.9519 - mae: 0.7213 - val_loss: 0.4073 - val_mae: 0.4223\n",
      "Epoch 1423/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.0090 - mae: 0.7369 - val_loss: 0.4073 - val_mae: 0.4223\n",
      "Epoch 1424/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0905 - mae: 0.7892 - val_loss: 0.4072 - val_mae: 0.4222\n",
      "Epoch 1425/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1037 - mae: 0.7884 - val_loss: 0.4072 - val_mae: 0.4222\n",
      "Epoch 1426/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0827 - mae: 0.7686 - val_loss: 0.4071 - val_mae: 0.4222\n",
      "Epoch 1427/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1030 - mae: 0.7724 - val_loss: 0.4071 - val_mae: 0.4221\n",
      "Epoch 1428/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0026 - mae: 0.7516 - val_loss: 0.4071 - val_mae: 0.4222\n",
      "Epoch 1429/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0956 - mae: 0.7815 - val_loss: 0.4071 - val_mae: 0.4222\n",
      "Epoch 1430/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.9945 - mae: 0.7391 - val_loss: 0.4071 - val_mae: 0.4222\n",
      "Epoch 1431/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0950 - mae: 0.7972 - val_loss: 0.4071 - val_mae: 0.4222\n",
      "Epoch 1432/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0651 - mae: 0.7647 - val_loss: 0.4070 - val_mae: 0.4221\n",
      "Epoch 1433/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.9967 - mae: 0.7315 - val_loss: 0.4070 - val_mae: 0.4221\n",
      "Epoch 1434/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0224 - mae: 0.7554 - val_loss: 0.4069 - val_mae: 0.4220\n",
      "Epoch 1435/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.0987 - mae: 0.7925 - val_loss: 0.4069 - val_mae: 0.4220\n",
      "Epoch 1436/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0103 - mae: 0.7655 - val_loss: 0.4069 - val_mae: 0.4220\n",
      "Epoch 1437/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1211 - mae: 0.7944 - val_loss: 0.4069 - val_mae: 0.4220\n",
      "Epoch 1438/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.9576 - mae: 0.7335 - val_loss: 0.4068 - val_mae: 0.4220\n",
      "Epoch 1439/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.9928 - mae: 0.7316 - val_loss: 0.4068 - val_mae: 0.4220\n",
      "Epoch 1440/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.0040 - mae: 0.7498 - val_loss: 0.4069 - val_mae: 0.4220\n",
      "Epoch 1441/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.9898 - mae: 0.7494 - val_loss: 0.4069 - val_mae: 0.4220\n",
      "Epoch 1442/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.9714 - mae: 0.7235 - val_loss: 0.4069 - val_mae: 0.4220\n",
      "Epoch 1443/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.9099 - mae: 0.7144 - val_loss: 0.4068 - val_mae: 0.4220\n",
      "Epoch 1444/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0759 - mae: 0.7812 - val_loss: 0.4069 - val_mae: 0.4220\n",
      "Epoch 1445/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0487 - mae: 0.7829 - val_loss: 0.4069 - val_mae: 0.4221\n",
      "Epoch 1446/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1830 - mae: 0.8432 - val_loss: 0.4069 - val_mae: 0.4220\n",
      "Epoch 1447/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0575 - mae: 0.7620 - val_loss: 0.4070 - val_mae: 0.4221\n",
      "Epoch 1448/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0433 - mae: 0.7985 - val_loss: 0.4070 - val_mae: 0.4221\n",
      "Epoch 1449/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0520 - mae: 0.7842 - val_loss: 0.4070 - val_mae: 0.4221\n",
      "Epoch 1450/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1182 - mae: 0.8073 - val_loss: 0.4071 - val_mae: 0.4222\n",
      "Epoch 1451/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0823 - mae: 0.7824 - val_loss: 0.4071 - val_mae: 0.4222\n",
      "Epoch 1452/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.9795 - mae: 0.7381 - val_loss: 0.4071 - val_mae: 0.4222\n",
      "Epoch 1453/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0076 - mae: 0.7334 - val_loss: 0.4070 - val_mae: 0.4221\n",
      "Epoch 1454/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0183 - mae: 0.7737 - val_loss: 0.4070 - val_mae: 0.4221\n",
      "Epoch 1455/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0866 - mae: 0.8108 - val_loss: 0.4070 - val_mae: 0.4221\n",
      "Epoch 1456/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1324 - mae: 0.7975 - val_loss: 0.4069 - val_mae: 0.4221\n",
      "Epoch 1457/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.9993 - mae: 0.7503 - val_loss: 0.4069 - val_mae: 0.4220\n",
      "Epoch 1458/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.9996 - mae: 0.7648 - val_loss: 0.4068 - val_mae: 0.4220\n",
      "Epoch 1459/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0399 - mae: 0.7625 - val_loss: 0.4068 - val_mae: 0.4220\n",
      "Epoch 1460/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0451 - mae: 0.7801 - val_loss: 0.4068 - val_mae: 0.4220\n",
      "Epoch 1461/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.1348 - mae: 0.8200 - val_loss: 0.4068 - val_mae: 0.4220\n",
      "Epoch 1462/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0516 - mae: 0.7748 - val_loss: 0.4068 - val_mae: 0.4220\n",
      "Epoch 1463/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.8808 - mae: 0.6915 - val_loss: 0.4069 - val_mae: 0.4220\n",
      "Epoch 1464/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.9990 - mae: 0.7529 - val_loss: 0.4068 - val_mae: 0.4220\n",
      "Epoch 1465/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.9985 - mae: 0.7308 - val_loss: 0.4068 - val_mae: 0.4220\n",
      "Epoch 1466/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.9767 - mae: 0.7239 - val_loss: 0.4067 - val_mae: 0.4219\n",
      "Epoch 1467/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.0783 - mae: 0.7853 - val_loss: 0.4067 - val_mae: 0.4219\n",
      "Epoch 1468/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1727 - mae: 0.8314 - val_loss: 0.4066 - val_mae: 0.4219\n",
      "Epoch 1469/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0410 - mae: 0.7764 - val_loss: 0.4066 - val_mae: 0.4219\n",
      "Epoch 1470/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.9988 - mae: 0.7376 - val_loss: 0.4066 - val_mae: 0.4218\n",
      "Epoch 1471/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.9679 - mae: 0.7140 - val_loss: 0.4065 - val_mae: 0.4218\n",
      "Epoch 1472/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.9557 - mae: 0.7361 - val_loss: 0.4065 - val_mae: 0.4218\n",
      "Epoch 1473/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.9633 - mae: 0.7253 - val_loss: 0.4066 - val_mae: 0.4219\n",
      "Epoch 1474/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1360 - mae: 0.8168 - val_loss: 0.4066 - val_mae: 0.4219\n",
      "Epoch 1475/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.0784 - mae: 0.8005 - val_loss: 0.4065 - val_mae: 0.4218\n",
      "Epoch 1476/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0271 - mae: 0.7598 - val_loss: 0.4064 - val_mae: 0.4217\n",
      "Epoch 1477/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.9994 - mae: 0.7445 - val_loss: 0.4064 - val_mae: 0.4217\n",
      "Epoch 1478/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.0095 - mae: 0.7428 - val_loss: 0.4063 - val_mae: 0.4217\n",
      "Epoch 1479/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.1020 - mae: 0.8008 - val_loss: 0.4062 - val_mae: 0.4216\n",
      "Epoch 1480/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0735 - mae: 0.7723 - val_loss: 0.4063 - val_mae: 0.4216\n",
      "Epoch 1481/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0264 - mae: 0.7613 - val_loss: 0.4063 - val_mae: 0.4217\n",
      "Epoch 1482/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0723 - mae: 0.7750 - val_loss: 0.4063 - val_mae: 0.4217\n",
      "Epoch 1483/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.9922 - mae: 0.7371 - val_loss: 0.4063 - val_mae: 0.4216\n",
      "Epoch 1484/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.0098 - mae: 0.7498 - val_loss: 0.4062 - val_mae: 0.4216\n",
      "Epoch 1485/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.9466 - mae: 0.7365 - val_loss: 0.4062 - val_mae: 0.4216\n",
      "Epoch 1486/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0102 - mae: 0.7425 - val_loss: 0.4061 - val_mae: 0.4215\n",
      "Epoch 1487/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.0601 - mae: 0.7754 - val_loss: 0.4060 - val_mae: 0.4215\n",
      "Epoch 1488/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.9820 - mae: 0.7537 - val_loss: 0.4060 - val_mae: 0.4215\n",
      "Epoch 1489/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1003 - mae: 0.7991 - val_loss: 0.4060 - val_mae: 0.4215\n",
      "Epoch 1490/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.9777 - mae: 0.7068 - val_loss: 0.4061 - val_mae: 0.4215\n",
      "Epoch 1491/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0793 - mae: 0.8032 - val_loss: 0.4062 - val_mae: 0.4216\n",
      "Epoch 1492/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.9212 - mae: 0.6954 - val_loss: 0.4062 - val_mae: 0.4216\n",
      "Epoch 1493/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.0402 - mae: 0.7666 - val_loss: 0.4062 - val_mae: 0.4216\n",
      "Epoch 1494/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.9932 - mae: 0.7501 - val_loss: 0.4063 - val_mae: 0.4217\n",
      "Epoch 1495/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.9898 - mae: 0.7418 - val_loss: 0.4063 - val_mae: 0.4216\n",
      "Epoch 1496/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0505 - mae: 0.8009 - val_loss: 0.4063 - val_mae: 0.4216\n",
      "Epoch 1497/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.0795 - mae: 0.7952 - val_loss: 0.4062 - val_mae: 0.4216\n",
      "Epoch 1498/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0165 - mae: 0.7798 - val_loss: 0.4062 - val_mae: 0.4216\n",
      "Epoch 1499/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.0969 - mae: 0.7993 - val_loss: 0.4062 - val_mae: 0.4216\n",
      "Epoch 1500/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.0947 - mae: 0.7948 - val_loss: 0.4062 - val_mae: 0.4216\n",
      "Epoch 1501/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0936 - mae: 0.7893 - val_loss: 0.4061 - val_mae: 0.4215\n",
      "Epoch 1502/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.0008 - mae: 0.7504 - val_loss: 0.4060 - val_mae: 0.4215\n",
      "Epoch 1503/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0222 - mae: 0.7396 - val_loss: 0.4060 - val_mae: 0.4215\n",
      "Epoch 1504/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.9696 - mae: 0.7270 - val_loss: 0.4061 - val_mae: 0.4215\n",
      "Epoch 1505/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1.0451 - mae: 0.7826 - val_loss: 0.4061 - val_mae: 0.4215\n",
      "Epoch 1506/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.9439 - mae: 0.7119 - val_loss: 0.4061 - val_mae: 0.4215\n",
      "Epoch 1507/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.9381 - mae: 0.7247 - val_loss: 0.4061 - val_mae: 0.4215\n",
      "Epoch 1508/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0186 - mae: 0.7604 - val_loss: 0.4061 - val_mae: 0.4215\n",
      "Epoch 1509/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.9921 - mae: 0.7593 - val_loss: 0.4061 - val_mae: 0.4215\n",
      "Epoch 1510/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.1335 - mae: 0.8258 - val_loss: 0.4061 - val_mae: 0.4215\n",
      "Epoch 1511/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0329 - mae: 0.7675 - val_loss: 0.4061 - val_mae: 0.4215\n",
      "Epoch 1512/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.9667 - mae: 0.7273 - val_loss: 0.4062 - val_mae: 0.4215\n",
      "Epoch 1513/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.9685 - mae: 0.7285 - val_loss: 0.4061 - val_mae: 0.4215\n",
      "Epoch 1514/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.9133 - mae: 0.6962 - val_loss: 0.4061 - val_mae: 0.4215\n",
      "Epoch 1515/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0191 - mae: 0.7576 - val_loss: 0.4061 - val_mae: 0.4215\n",
      "Epoch 1516/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.0107 - mae: 0.7561 - val_loss: 0.4061 - val_mae: 0.4215\n",
      "Epoch 1517/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.9395 - mae: 0.7353 - val_loss: 0.4060 - val_mae: 0.4215\n",
      "Epoch 1518/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 1.1040 - mae: 0.8122 - val_loss: 0.4060 - val_mae: 0.4214\n",
      "Epoch 1519/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.0289 - mae: 0.7457 - val_loss: 0.4060 - val_mae: 0.4214\n",
      "Epoch 1520/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.0133 - mae: 0.7335 - val_loss: 0.4060 - val_mae: 0.4214\n",
      "Epoch 1521/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.0112 - mae: 0.7573 - val_loss: 0.4059 - val_mae: 0.4214\n",
      "Epoch 1522/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0857 - mae: 0.7910 - val_loss: 0.4058 - val_mae: 0.4213\n",
      "Epoch 1523/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0061 - mae: 0.7493 - val_loss: 0.4057 - val_mae: 0.4212\n",
      "Epoch 1524/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0031 - mae: 0.7457 - val_loss: 0.4057 - val_mae: 0.4213\n",
      "Epoch 1525/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0105 - mae: 0.7370 - val_loss: 0.4058 - val_mae: 0.4213\n",
      "Epoch 1526/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.9496 - mae: 0.7218 - val_loss: 0.4057 - val_mae: 0.4212\n",
      "Epoch 1527/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0993 - mae: 0.8118 - val_loss: 0.4057 - val_mae: 0.4212\n",
      "Epoch 1528/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0241 - mae: 0.7489 - val_loss: 0.4056 - val_mae: 0.4212\n",
      "Epoch 1529/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.0940 - mae: 0.7941 - val_loss: 0.4057 - val_mae: 0.4213\n",
      "Epoch 1530/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.9956 - mae: 0.7598 - val_loss: 0.4057 - val_mae: 0.4212\n",
      "Epoch 1531/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.8881 - mae: 0.6797 - val_loss: 0.4057 - val_mae: 0.4212\n",
      "Epoch 1532/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.0970 - mae: 0.8003 - val_loss: 0.4058 - val_mae: 0.4213\n",
      "Epoch 1533/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.8437 - mae: 0.6625 - val_loss: 0.4058 - val_mae: 0.4213\n",
      "Epoch 1534/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.9359 - mae: 0.7164 - val_loss: 0.4058 - val_mae: 0.4213\n",
      "Epoch 1535/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.0476 - mae: 0.7672 - val_loss: 0.4059 - val_mae: 0.4213\n",
      "Epoch 1536/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.0063 - mae: 0.7572 - val_loss: 0.4058 - val_mae: 0.4213\n",
      "Epoch 1537/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.0733 - mae: 0.8051 - val_loss: 0.4058 - val_mae: 0.4213\n",
      "Epoch 1538/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1233 - mae: 0.8125 - val_loss: 0.4058 - val_mae: 0.4213\n",
      "Epoch 1539/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0493 - mae: 0.7703 - val_loss: 0.4058 - val_mae: 0.4213\n",
      "Epoch 1540/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.8924 - mae: 0.6965 - val_loss: 0.4058 - val_mae: 0.4213\n",
      "Epoch 1541/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1.0787 - mae: 0.7836 - val_loss: 0.4058 - val_mae: 0.4213\n",
      "Epoch 1542/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0554 - mae: 0.8098 - val_loss: 0.4058 - val_mae: 0.4213\n",
      "Epoch 1543/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.9811 - mae: 0.7358 - val_loss: 0.4058 - val_mae: 0.4213\n",
      "Epoch 1544/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0572 - mae: 0.7806 - val_loss: 0.4059 - val_mae: 0.4213\n",
      "Epoch 1545/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.9109 - mae: 0.6984 - val_loss: 0.4058 - val_mae: 0.4213\n",
      "Epoch 1546/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.9397 - mae: 0.7304 - val_loss: 0.4059 - val_mae: 0.4213\n",
      "Epoch 1547/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.0515 - mae: 0.7586 - val_loss: 0.4059 - val_mae: 0.4214\n",
      "Epoch 1548/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.0432 - mae: 0.7662 - val_loss: 0.4059 - val_mae: 0.4214\n",
      "Epoch 1549/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.0687 - mae: 0.7832 - val_loss: 0.4059 - val_mae: 0.4213\n",
      "Epoch 1550/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0218 - mae: 0.7628 - val_loss: 0.4057 - val_mae: 0.4212\n",
      "Epoch 1551/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.0442 - mae: 0.7750 - val_loss: 0.4058 - val_mae: 0.4212\n",
      "Epoch 1552/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.9800 - mae: 0.7424 - val_loss: 0.4058 - val_mae: 0.4213\n",
      "Epoch 1553/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.9162 - mae: 0.7127 - val_loss: 0.4058 - val_mae: 0.4212\n",
      "Epoch 1554/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.9859 - mae: 0.7353 - val_loss: 0.4057 - val_mae: 0.4212\n",
      "Epoch 1555/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.0262 - mae: 0.7688 - val_loss: 0.4057 - val_mae: 0.4212\n",
      "Epoch 1556/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0361 - mae: 0.7693 - val_loss: 0.4056 - val_mae: 0.4212\n",
      "Epoch 1557/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0615 - mae: 0.7720 - val_loss: 0.4057 - val_mae: 0.4212\n",
      "Epoch 1558/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.9913 - mae: 0.7531 - val_loss: 0.4057 - val_mae: 0.4212\n",
      "Epoch 1559/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.0601 - mae: 0.7788 - val_loss: 0.4057 - val_mae: 0.4212\n",
      "Epoch 1560/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0825 - mae: 0.8025 - val_loss: 0.4057 - val_mae: 0.4212\n",
      "Epoch 1561/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.9135 - mae: 0.7028 - val_loss: 0.4058 - val_mae: 0.4212\n",
      "Epoch 1562/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.0134 - mae: 0.7543 - val_loss: 0.4057 - val_mae: 0.4212\n",
      "Epoch 1563/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 1.1169 - mae: 0.7863 - val_loss: 0.4055 - val_mae: 0.4211\n",
      "Epoch 1564/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.1798 - mae: 0.8436 - val_loss: 0.4055 - val_mae: 0.4210\n",
      "Epoch 1565/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0609 - mae: 0.7838 - val_loss: 0.4055 - val_mae: 0.4211\n",
      "Epoch 1566/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0891 - mae: 0.7930 - val_loss: 0.4054 - val_mae: 0.4210\n",
      "Epoch 1567/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.0866 - mae: 0.7970 - val_loss: 0.4054 - val_mae: 0.4210\n",
      "Epoch 1568/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.9529 - mae: 0.7051 - val_loss: 0.4053 - val_mae: 0.4210\n",
      "Epoch 1569/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0088 - mae: 0.7559 - val_loss: 0.4053 - val_mae: 0.4210\n",
      "Epoch 1570/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.9461 - mae: 0.7246 - val_loss: 0.4053 - val_mae: 0.4210\n",
      "Epoch 1571/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.0587 - mae: 0.7821 - val_loss: 0.4053 - val_mae: 0.4209\n",
      "Epoch 1572/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0177 - mae: 0.7418 - val_loss: 0.4053 - val_mae: 0.4209\n",
      "Epoch 1573/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0779 - mae: 0.7990 - val_loss: 0.4052 - val_mae: 0.4209\n",
      "Epoch 1574/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0536 - mae: 0.7845 - val_loss: 0.4052 - val_mae: 0.4208\n",
      "Epoch 1575/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.0267 - mae: 0.7646 - val_loss: 0.4051 - val_mae: 0.4208\n",
      "Epoch 1576/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.0300 - mae: 0.7547 - val_loss: 0.4052 - val_mae: 0.4209\n",
      "Epoch 1577/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.0356 - mae: 0.7684 - val_loss: 0.4052 - val_mae: 0.4209\n",
      "Epoch 1578/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0720 - mae: 0.7919 - val_loss: 0.4052 - val_mae: 0.4209\n",
      "Epoch 1579/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1083 - mae: 0.7992 - val_loss: 0.4053 - val_mae: 0.4209\n",
      "Epoch 1580/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.9986 - mae: 0.7306 - val_loss: 0.4053 - val_mae: 0.4209\n",
      "Epoch 1581/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.9637 - mae: 0.7271 - val_loss: 0.4053 - val_mae: 0.4209\n",
      "Epoch 1582/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.9660 - mae: 0.7281 - val_loss: 0.4053 - val_mae: 0.4209\n",
      "Epoch 1583/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.9674 - mae: 0.7246 - val_loss: 0.4053 - val_mae: 0.4209\n",
      "Epoch 1584/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.9868 - mae: 0.7439 - val_loss: 0.4054 - val_mae: 0.4210\n",
      "Epoch 1585/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.0026 - mae: 0.7315 - val_loss: 0.4053 - val_mae: 0.4209\n",
      "Epoch 1586/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.9923 - mae: 0.7480 - val_loss: 0.4053 - val_mae: 0.4209\n",
      "Epoch 1587/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0447 - mae: 0.7534 - val_loss: 0.4053 - val_mae: 0.4209\n",
      "Epoch 1588/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0312 - mae: 0.7728 - val_loss: 0.4053 - val_mae: 0.4209\n",
      "Epoch 1589/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.0302 - mae: 0.7501 - val_loss: 0.4053 - val_mae: 0.4209\n",
      "Epoch 1590/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0585 - mae: 0.7819 - val_loss: 0.4053 - val_mae: 0.4209\n",
      "Epoch 1591/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.9934 - mae: 0.7508 - val_loss: 0.4052 - val_mae: 0.4209\n",
      "Epoch 1592/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0772 - mae: 0.7800 - val_loss: 0.4053 - val_mae: 0.4209\n",
      "Epoch 1593/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0514 - mae: 0.7875 - val_loss: 0.4053 - val_mae: 0.4209\n",
      "Epoch 1594/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.0340 - mae: 0.7618 - val_loss: 0.4053 - val_mae: 0.4209\n",
      "Epoch 1595/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1705 - mae: 0.8296 - val_loss: 0.4053 - val_mae: 0.4209\n",
      "Epoch 1596/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.9595 - mae: 0.7280 - val_loss: 0.4054 - val_mae: 0.4210\n",
      "Epoch 1597/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.0235 - mae: 0.7420 - val_loss: 0.4054 - val_mae: 0.4209\n",
      "Epoch 1598/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.9473 - mae: 0.7199 - val_loss: 0.4054 - val_mae: 0.4210\n",
      "Epoch 1599/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.9002 - mae: 0.7054 - val_loss: 0.4054 - val_mae: 0.4210\n",
      "Epoch 1600/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.0358 - mae: 0.7729 - val_loss: 0.4054 - val_mae: 0.4210\n",
      "Epoch 1601/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0469 - mae: 0.7816 - val_loss: 0.4054 - val_mae: 0.4209\n",
      "Epoch 1602/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.1015 - mae: 0.8191 - val_loss: 0.4053 - val_mae: 0.4209\n",
      "Epoch 1603/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.9570 - mae: 0.7526 - val_loss: 0.4053 - val_mae: 0.4209\n",
      "Epoch 1604/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.9938 - mae: 0.7462 - val_loss: 0.4053 - val_mae: 0.4208\n",
      "Epoch 1605/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0287 - mae: 0.7646 - val_loss: 0.4053 - val_mae: 0.4209\n",
      "Epoch 1606/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.0283 - mae: 0.7633 - val_loss: 0.4053 - val_mae: 0.4209\n",
      "Epoch 1607/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1073 - mae: 0.7995 - val_loss: 0.4054 - val_mae: 0.4209\n",
      "Epoch 1608/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0102 - mae: 0.7716 - val_loss: 0.4054 - val_mae: 0.4209\n",
      "Epoch 1609/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.0037 - mae: 0.7558 - val_loss: 0.4054 - val_mae: 0.4209\n",
      "Epoch 1610/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0985 - mae: 0.8014 - val_loss: 0.4053 - val_mae: 0.4208\n",
      "Epoch 1611/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0180 - mae: 0.7574 - val_loss: 0.4052 - val_mae: 0.4208\n",
      "Epoch 1612/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.9335 - mae: 0.7142 - val_loss: 0.4052 - val_mae: 0.4208\n",
      "Epoch 1613/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0403 - mae: 0.7638 - val_loss: 0.4051 - val_mae: 0.4207\n",
      "Epoch 1614/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.0826 - mae: 0.7802 - val_loss: 0.4051 - val_mae: 0.4207\n",
      "Epoch 1615/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.9726 - mae: 0.7309 - val_loss: 0.4051 - val_mae: 0.4207\n",
      "Epoch 1616/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.9118 - mae: 0.7090 - val_loss: 0.4051 - val_mae: 0.4207\n",
      "Epoch 1617/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.9825 - mae: 0.7459 - val_loss: 0.4051 - val_mae: 0.4207\n",
      "Epoch 1618/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.0359 - mae: 0.7750 - val_loss: 0.4051 - val_mae: 0.4207\n",
      "Epoch 1619/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.9923 - mae: 0.7420 - val_loss: 0.4052 - val_mae: 0.4207\n",
      "Epoch 1620/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0193 - mae: 0.7561 - val_loss: 0.4051 - val_mae: 0.4207\n",
      "Epoch 1621/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1123 - mae: 0.7993 - val_loss: 0.4051 - val_mae: 0.4207\n",
      "Epoch 1622/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0083 - mae: 0.7595 - val_loss: 0.4052 - val_mae: 0.4208\n",
      "Epoch 1623/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.1723 - mae: 0.8409 - val_loss: 0.4053 - val_mae: 0.4208\n",
      "Epoch 1624/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.0609 - mae: 0.7855 - val_loss: 0.4052 - val_mae: 0.4208\n",
      "Epoch 1625/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0148 - mae: 0.7536 - val_loss: 0.4053 - val_mae: 0.4208\n",
      "Epoch 1626/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.9338 - mae: 0.7130 - val_loss: 0.4052 - val_mae: 0.4208\n",
      "Epoch 1627/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.0363 - mae: 0.7766 - val_loss: 0.4053 - val_mae: 0.4209\n",
      "Epoch 1628/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.9197 - mae: 0.7120 - val_loss: 0.4053 - val_mae: 0.4208\n",
      "Epoch 1629/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.1288 - mae: 0.8041 - val_loss: 0.4053 - val_mae: 0.4209\n",
      "Epoch 1630/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0409 - mae: 0.7724 - val_loss: 0.4053 - val_mae: 0.4208\n",
      "Epoch 1631/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.0330 - mae: 0.7665 - val_loss: 0.4054 - val_mae: 0.4209\n",
      "Epoch 1632/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.1263 - mae: 0.8329 - val_loss: 0.4053 - val_mae: 0.4209\n",
      "Epoch 1633/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.0302 - mae: 0.7895 - val_loss: 0.4053 - val_mae: 0.4208\n",
      "Epoch 1634/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.0679 - mae: 0.8045 - val_loss: 0.4052 - val_mae: 0.4208\n",
      "Epoch 1635/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.0850 - mae: 0.8026 - val_loss: 0.4053 - val_mae: 0.4208\n",
      "Epoch 1636/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.9797 - mae: 0.7419 - val_loss: 0.4053 - val_mae: 0.4208\n",
      "Epoch 1637/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.0198 - mae: 0.7594 - val_loss: 0.4053 - val_mae: 0.4208\n",
      "Epoch 1638/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.1150 - mae: 0.8076 - val_loss: 0.4053 - val_mae: 0.4208\n",
      "Epoch 1639/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.9380 - mae: 0.7247 - val_loss: 0.4054 - val_mae: 0.4209\n",
      "Epoch 1640/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.9707 - mae: 0.7270 - val_loss: 0.4054 - val_mae: 0.4208\n",
      "Epoch 1641/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.0647 - mae: 0.7834 - val_loss: 0.4054 - val_mae: 0.4208\n",
      "Epoch 1642/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.0294 - mae: 0.7814 - val_loss: 0.4054 - val_mae: 0.4208\n",
      "Epoch 1643/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.9924 - mae: 0.7434 - val_loss: 0.4054 - val_mae: 0.4208\n",
      "Epoch 1644/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.0420 - mae: 0.7625 - val_loss: 0.4054 - val_mae: 0.4208\n",
      "Epoch 1645/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0158 - mae: 0.7520 - val_loss: 0.4055 - val_mae: 0.4209\n",
      "Epoch 1646/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.0057 - mae: 0.7341 - val_loss: 0.4053 - val_mae: 0.4208\n",
      "Epoch 1647/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.0755 - mae: 0.7905 - val_loss: 0.4053 - val_mae: 0.4207\n",
      "Epoch 1648/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.0139 - mae: 0.7657 - val_loss: 0.4052 - val_mae: 0.4207\n",
      "Epoch 1649/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.9516 - mae: 0.7233 - val_loss: 0.4052 - val_mae: 0.4207\n",
      "Epoch 1650/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0458 - mae: 0.7718 - val_loss: 0.4052 - val_mae: 0.4207\n",
      "Epoch 1651/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0303 - mae: 0.7577 - val_loss: 0.4051 - val_mae: 0.4206\n",
      "Epoch 1652/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0463 - mae: 0.7728 - val_loss: 0.4052 - val_mae: 0.4206\n",
      "Epoch 1653/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0565 - mae: 0.7697 - val_loss: 0.4051 - val_mae: 0.4206\n",
      "Epoch 1654/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.9844 - mae: 0.7384 - val_loss: 0.4051 - val_mae: 0.4206\n",
      "Epoch 1655/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.9959 - mae: 0.7538 - val_loss: 0.4051 - val_mae: 0.4206\n",
      "Epoch 1656/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.1179 - mae: 0.7998 - val_loss: 0.4051 - val_mae: 0.4206\n",
      "Epoch 1657/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.0626 - mae: 0.7792 - val_loss: 0.4050 - val_mae: 0.4205\n",
      "Epoch 1658/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.9905 - mae: 0.7646 - val_loss: 0.4050 - val_mae: 0.4205\n",
      "Epoch 1659/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.9966 - mae: 0.7591 - val_loss: 0.4050 - val_mae: 0.4205\n",
      "Epoch 1660/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.0512 - mae: 0.7821 - val_loss: 0.4049 - val_mae: 0.4204\n",
      "Epoch 1661/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0483 - mae: 0.7780 - val_loss: 0.4049 - val_mae: 0.4204\n",
      "Epoch 1662/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.9140 - mae: 0.7186 - val_loss: 0.4049 - val_mae: 0.4204\n",
      "Epoch 1663/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0643 - mae: 0.7835 - val_loss: 0.4050 - val_mae: 0.4205\n",
      "Epoch 1664/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.0153 - mae: 0.7519 - val_loss: 0.4051 - val_mae: 0.4205\n",
      "Epoch 1665/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.0264 - mae: 0.7801 - val_loss: 0.4050 - val_mae: 0.4205\n",
      "Epoch 1666/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0979 - mae: 0.7838 - val_loss: 0.4051 - val_mae: 0.4206\n",
      "Epoch 1667/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.9665 - mae: 0.7483 - val_loss: 0.4051 - val_mae: 0.4206\n",
      "Epoch 1668/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.9711 - mae: 0.7399 - val_loss: 0.4050 - val_mae: 0.4205\n",
      "Epoch 1669/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.0356 - mae: 0.7715 - val_loss: 0.4050 - val_mae: 0.4205\n",
      "Epoch 1670/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.1398 - mae: 0.8216 - val_loss: 0.4051 - val_mae: 0.4205\n",
      "Epoch 1671/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.9609 - mae: 0.7049 - val_loss: 0.4051 - val_mae: 0.4205\n",
      "Epoch 1672/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0250 - mae: 0.7676 - val_loss: 0.4050 - val_mae: 0.4205\n",
      "Epoch 1673/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.9563 - mae: 0.7442 - val_loss: 0.4051 - val_mae: 0.4205\n",
      "Epoch 1674/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.0202 - mae: 0.7619 - val_loss: 0.4051 - val_mae: 0.4205\n",
      "Epoch 1675/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.9576 - mae: 0.7312 - val_loss: 0.4051 - val_mae: 0.4206\n",
      "Epoch 1676/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.8996 - mae: 0.7113 - val_loss: 0.4052 - val_mae: 0.4206\n",
      "Epoch 1677/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.0562 - mae: 0.7732 - val_loss: 0.4051 - val_mae: 0.4205\n",
      "Epoch 1678/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.9073 - mae: 0.6832 - val_loss: 0.4051 - val_mae: 0.4205\n",
      "Epoch 1679/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.9844 - mae: 0.7391 - val_loss: 0.4052 - val_mae: 0.4206\n",
      "Epoch 1680/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.9864 - mae: 0.7404 - val_loss: 0.4051 - val_mae: 0.4205\n",
      "Epoch 1681/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0553 - mae: 0.7686 - val_loss: 0.4051 - val_mae: 0.4205\n",
      "Epoch 1682/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.9698 - mae: 0.7689 - val_loss: 0.4051 - val_mae: 0.4205\n",
      "Epoch 1683/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.9817 - mae: 0.7495 - val_loss: 0.4050 - val_mae: 0.4205\n",
      "Epoch 1684/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0496 - mae: 0.7766 - val_loss: 0.4051 - val_mae: 0.4205\n",
      "Epoch 1685/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1.1501 - mae: 0.8188 - val_loss: 0.4051 - val_mae: 0.4205\n",
      "Epoch 1686/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.9404 - mae: 0.7106 - val_loss: 0.4051 - val_mae: 0.4205\n",
      "Epoch 1687/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.0069 - mae: 0.7524 - val_loss: 0.4052 - val_mae: 0.4206\n",
      "Epoch 1688/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.9799 - mae: 0.7407 - val_loss: 0.4053 - val_mae: 0.4206\n",
      "Epoch 1689/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.0458 - mae: 0.7669 - val_loss: 0.4054 - val_mae: 0.4207\n",
      "Epoch 1690/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1538 - mae: 0.8336 - val_loss: 0.4053 - val_mae: 0.4206\n",
      "Epoch 1691/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.0373 - mae: 0.7719 - val_loss: 0.4053 - val_mae: 0.4206\n",
      "Epoch 1692/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0615 - mae: 0.7818 - val_loss: 0.4053 - val_mae: 0.4206\n",
      "Epoch 1693/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.0067 - mae: 0.7513 - val_loss: 0.4053 - val_mae: 0.4206\n",
      "Epoch 1694/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.9961 - mae: 0.7468 - val_loss: 0.4052 - val_mae: 0.4205\n",
      "Epoch 1695/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0252 - mae: 0.7609 - val_loss: 0.4053 - val_mae: 0.4206\n",
      "Epoch 1696/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.9912 - mae: 0.7521 - val_loss: 0.4053 - val_mae: 0.4206\n",
      "Epoch 1697/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 1.0203 - mae: 0.7663 - val_loss: 0.4053 - val_mae: 0.4206\n",
      "Epoch 1698/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.0343 - mae: 0.7579 - val_loss: 0.4052 - val_mae: 0.4205\n",
      "Epoch 1699/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.2070 - mae: 0.8522 - val_loss: 0.4051 - val_mae: 0.4205\n",
      "Epoch 1700/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.0122 - mae: 0.7436 - val_loss: 0.4052 - val_mae: 0.4205\n",
      "Epoch 1701/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.9376 - mae: 0.7173 - val_loss: 0.4052 - val_mae: 0.4205\n",
      "Epoch 1702/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.0766 - mae: 0.7917 - val_loss: 0.4052 - val_mae: 0.4205\n",
      "Epoch 1703/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1152 - mae: 0.8011 - val_loss: 0.4051 - val_mae: 0.4204\n",
      "Epoch 1704/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1.0878 - mae: 0.8112 - val_loss: 0.4051 - val_mae: 0.4204\n",
      "Epoch 1705/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.9033 - mae: 0.7023 - val_loss: 0.4050 - val_mae: 0.4204\n",
      "Epoch 1706/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.9707 - mae: 0.7208 - val_loss: 0.4050 - val_mae: 0.4204\n",
      "Epoch 1707/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.9610 - mae: 0.7340 - val_loss: 0.4050 - val_mae: 0.4204\n",
      "Epoch 1708/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0643 - mae: 0.7810 - val_loss: 0.4050 - val_mae: 0.4204\n",
      "Epoch 1709/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.9982 - mae: 0.7618 - val_loss: 0.4051 - val_mae: 0.4204\n",
      "Epoch 1710/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.0428 - mae: 0.7652 - val_loss: 0.4051 - val_mae: 0.4205\n",
      "Epoch 1711/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.9719 - mae: 0.7146 - val_loss: 0.4050 - val_mae: 0.4204\n",
      "Epoch 1712/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.9620 - mae: 0.7330 - val_loss: 0.4051 - val_mae: 0.4204\n",
      "Epoch 1713/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.0169 - mae: 0.7621 - val_loss: 0.4050 - val_mae: 0.4203\n",
      "Epoch 1714/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.0505 - mae: 0.7792 - val_loss: 0.4050 - val_mae: 0.4203\n",
      "Epoch 1715/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.0148 - mae: 0.7594 - val_loss: 0.4050 - val_mae: 0.4203\n",
      "Epoch 1716/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.0071 - mae: 0.7732 - val_loss: 0.4050 - val_mae: 0.4204\n",
      "Epoch 1717/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.9644 - mae: 0.7419 - val_loss: 0.4050 - val_mae: 0.4203\n",
      "Epoch 1718/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.9949 - mae: 0.7568 - val_loss: 0.4051 - val_mae: 0.4204\n",
      "Epoch 1719/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.0369 - mae: 0.7612 - val_loss: 0.4051 - val_mae: 0.4204\n",
      "Epoch 1720/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.9268 - mae: 0.7066 - val_loss: 0.4050 - val_mae: 0.4203\n",
      "Epoch 1721/2000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.0962 - mae: 0.8037 - val_loss: 0.4049 - val_mae: 0.4203\n",
      "Epoch 1721: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1661.\n"
     ]
    }
   ],
   "source": [
    "# Обучаю модель с лучшими значениями гиперпараметров \n",
    "# Использую EarlyStopping для предотвращения переобучения\n",
    "\n",
    "model = tf.keras.Sequential([tf.keras.layers.Dense(1, activation=best_activation_function)])\n",
    "\n",
    "if best_optimizer == 'sgd':\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=best_learning_rate)\n",
    "elif best_optimizer == 'adam':\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=best_learning_rate)\n",
    "elif best_optimizer == 'rmsprop':\n",
    "    optimizer = tf.keras.optimizers.RMSprop(learning_rate=best_learning_rate)\n",
    "elif best_optimizer == 'adagrad':\n",
    "    optimizer = tf.keras.optimizers.Adagrad(learning_rate=best_learning_rate)\n",
    "else:\n",
    "    raise ValueError(\"Invalid optimizer specified\")\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=['mae'])\n",
    "early_stopping = EarlyStopping(monitor='val_loss', mode='min', restore_best_weights=True, verbose=1, patience=60)\n",
    "history = model.fit(X_train_numeric_scaled, y_train_scaled, epochs=2000, batch_size=32, validation_split=0.2, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# График потерь по эпохам \n",
    "# Визуализация предела итераций, после которых модель переобучается\n",
    "\n",
    "stopped_epoch = early_stopping.stopped_epoch\n",
    "restore_epoch = early_stopping.stopped_epoch - early_stopping.patience\n",
    "\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Validation Loss', fontsize=14)\n",
    "plt.xlabel('Epoch', fontsize=14)\n",
    "plt.ylabel('Loss', fontsize=14)\n",
    "\n",
    "plt.axvline(x=stopped_epoch, color='red', linestyle='--', label=f'Stopped Epoch: {stopped_epoch}')\n",
    "plt.axvline(x=restore_epoch, color='blue', linestyle='--', label=f'Restored Epoch: {restore_epoch}')\n",
    "\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.legend(fontsize=12, loc='upper left', bbox_to_anchor=(0.09, 0.985))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n"
     ]
    }
   ],
   "source": [
    "# Оцениваю обученную модель на тестовой выборке\n",
    "# Провел обратное преобразование предсказанных и тестовых значений таргета, которые ранее были нормализованы\n",
    "\n",
    "y_pred_scaled = model.predict(X_test_numeric_scaled)\n",
    "\n",
    "y_pred_inverse = scaler_y.inverse_transform(y_pred_scaled)\n",
    "y_test_inverse = scaler_y.inverse_transform(y_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE) on test data: 3.6135610099271736\n",
      "Root Mean Squared Error (RMSE) on test data: 1.900936876891806\n",
      "R-squared on test data: -23.4195351316743\n",
      "Mean absolute error:  1.859869336648782\n"
     ]
    }
   ],
   "source": [
    "# MSE, RMSE, R^2, MAE - метрики качества\n",
    "\n",
    "mse = mean_squared_error(y_test_inverse, y_pred_inverse)\n",
    "rmse = np.sqrt(mse)\n",
    "r_squared = r2_score(y_test_inverse, y_pred_inverse)\n",
    "mae = mean_absolute_error(y_test_inverse, y_pred_inverse)\n",
    "\n",
    "print(\"Mean Squared Error (MSE) on test data:\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data:\", rmse)\n",
    "print(\"R-squared on test data:\", r_squared)\n",
    "print(\"Mean absolute error: \", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x=y_test_inverse.flatten(), y=y_pred_inverse.flatten())\n",
    "#plt.plot([y_test_inverse.min(), y_test_inverse.max()], [y_test_inverse.min(), y_test_inverse.max()], 'k--', lw=2) \n",
    "plt.xlabel('Actual Values', fontsize=14)\n",
    "plt.ylabel('Predicted Values', fontsize=14)\n",
    "plt.title('Single Layer Perceptron\\nActual LUMO vs. Predicted LUMO', fontsize=14)\n",
    "\n",
    "# plt.text(0.028, 0.80, f'- MSE: {mse:.6f}\\n- RMSE: {rmse:.6f}\\n- R-squared: {r_squared:.6f}\\n- MAE: {mae:.6f}', color='red', fontsize=14, transform=plt.gca().transAxes)\n",
    "# f'Optimizer: {best_optimizer}\\nAct. function: {best_activation_function}\\nLearning rate: {best_learning_rate}', color='green', fontsize=14, ha='left', transform=plt.gca().transAxes)\n",
    "\n",
    "plt.text(0.55, 0.1, f'- MSE: {mse:.6f}', color='red', fontsize=14, transform=plt.gca().transAxes)\n",
    "plt.text(0.55, 0.15, f'- RMSE: {rmse:.6f}', color='red', fontsize=14, transform=plt.gca().transAxes)\n",
    "plt.text(0.55, 0.2, f'- R-squared: {r_squared:.6f}', color='red', fontsize=14, transform=plt.gca().transAxes)\n",
    "plt.text(0.55, 0.25, f'- MAE: {mae:.6f}', color='red', fontsize=14, transform=plt.gca().transAxes)\n",
    "plt.text(0.57, 0.3, f'Optimizer: {best_optimizer}\\nAct. function: {best_activation_function}\\nLearning rate: {best_learning_rate}', color='green', fontsize=14, ha='left', transform=plt.gca().transAxes)\n",
    "\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m                SINGLE LAYER PERCEPTRON                \u001b[0m\n",
      "                TOP-5 Predicted Values\n",
      "                \n",
      " Actual LUMO  Predicted LUMO  Absolute Difference\n",
      "     -0.2151        0.269570             0.484670\n",
      "     -0.8343        0.259502             1.093802\n",
      "     -1.1975        0.167465             1.364965\n",
      "     -1.3353        0.136514             1.471814\n",
      "     -1.5997        0.096524             1.696224\n"
     ]
    }
   ],
   "source": [
    "# ТОП-5 лучших предсказанных значений и величина абсолютной разницы\n",
    "\n",
    "y_test_flattened = y_test_inverse.flatten()\n",
    "y_pred_flattened = y_pred_inverse.flatten()\n",
    "\n",
    "comparison_df = pd.DataFrame({'Actual LUMO': y_test_flattened, 'Predicted LUMO': y_pred_flattened})\n",
    "comparison_df['Absolute Difference'] = abs(comparison_df['Actual LUMO'] - comparison_df['Predicted LUMO'])\n",
    "\n",
    "best_results = comparison_df.sort_values(by='Absolute Difference').head(5)\n",
    "print(\"\\033[1m{:^55}\\033[0m\".format(\"SINGLE LAYER PERCEPTRON\"))\n",
    "print(\"{:^55}\".format(\"TOP-5 Predicted Values\\n\"))\n",
    "print(best_results.to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
